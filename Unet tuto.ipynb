{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a43672",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef728dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from skimage import io\n",
    "from skimage.transform import resize\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b70e19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "np.random.seed = seed\n",
    "\n",
    "IMG_WIDTH = 256\n",
    "IMG_HEIGHT = 512\n",
    "IMG_CHANNEL = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb3253f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(file_path):\n",
    "    \n",
    "    file = open(file_path, \"r\")\n",
    "\n",
    "    allText = file.read()\n",
    "\n",
    "    words = list(map(str, allText.split()))\n",
    "\n",
    "    matrice_height = int(len(words) / 30)\n",
    "    matrice = np.ones((matrice_height, 24))\n",
    "\n",
    "    emplacement = 20\n",
    "    iter1 = 0\n",
    "    for i in range(emplacement, int(len(words) / 30) + emplacement):\n",
    "        iter2 = 0\n",
    "        for j in range(emplacement + 6, emplacement + 30):\n",
    "            matrice[(iter1, iter2)] = words[j]\n",
    "            iter2 += 1\n",
    "        iter1 += 1\n",
    "        emplacement += 30\n",
    "    X_2 = np.delete(matrice, 1, 1)\n",
    "    X_final = np.delete(X_2, 10, 1)\n",
    "    \n",
    "    file.close()\n",
    "    \n",
    "    return X_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b65eb335",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_in_path = \"C_maps_in.txt\"\n",
    "file_out_path = \"C_maps_out.txt\"\n",
    "\n",
    "X = get_data(file_in_path)\n",
    "y = get_data(file_out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d428dd92",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_T = X.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7afc728f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_T = y.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "196c433b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "440eab97",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_T.shape"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f4865dc7",
   "metadata": {},
   "source": [
    "plot = plt.hist(X_T)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5f6a81ac",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "for i in range(22):\n",
    "    plot = plt.scatter(range(400198), X_T[i], s=1)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "df8b2383",
   "metadata": {},
   "source": [
    "for i in range(22):\n",
    "    plot = plt.scatter(range(400198), y_T[i])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e9feb90",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_T_R = X_T.reshape((22, 499, 802))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d95851",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_T_R.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f609151",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_t_r = y_T.reshape((22, 499, 802))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a59d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_t_r.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ae9ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_T_R\n",
    "y = y_t_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "70a5a08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model\n",
    "inputs = tf.keras.layers.Input((IMG_WIDTH, IMG_HEIGHT, IMG_CHANNEL))\n",
    "# convert to float\n",
    "# s = tf.keras.layers.Lambda(lambda x: x / 7)(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0d9bc299",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contraction path\n",
    "c1 = tf.keras.layers.Conv2D(16, (3, 3), activation=\"relu\", kernel_initializer=\"he_normal\", padding=\"same\")(inputs)\n",
    "c1 = tf.keras.layers.Dropout(0.1)(c1)\n",
    "c1 = tf.keras.layers.Conv2D(16, (3, 3), activation=\"relu\", kernel_initializer=\"he_normal\", padding=\"same\")(c1)\n",
    "p1 = tf.keras.layers.MaxPooling2D((2, 2))(c1)\n",
    "\n",
    "c2 = tf.keras.layers.Conv2D(32, (3, 3), activation=\"relu\", kernel_initializer=\"he_normal\", padding=\"same\")(p1)\n",
    "c2 = tf.keras.layers.Dropout(0.1)(c2)\n",
    "c2 = tf.keras.layers.Conv2D(32, (3, 3), activation=\"relu\", kernel_initializer=\"he_normal\", padding=\"same\")(c2)\n",
    "p2 = tf.keras.layers.MaxPooling2D((2, 2))(c2)\n",
    "\n",
    "c3 = tf.keras.layers.Conv2D(64, (3, 3), activation=\"relu\", kernel_initializer=\"he_normal\", padding=\"same\")(p2)\n",
    "c3 = tf.keras.layers.Dropout(0.2)(c3)\n",
    "c3 = tf.keras.layers.Conv2D(64, (3, 3), activation=\"relu\", kernel_initializer=\"he_normal\", padding=\"same\")(c3)\n",
    "p3 = tf.keras.layers.MaxPooling2D((2, 2))(c3)\n",
    "\n",
    "c4 = tf.keras.layers.Conv2D(128, (3, 3), activation=\"relu\", kernel_initializer=\"he_normal\", padding=\"same\")(p3)\n",
    "c4 = tf.keras.layers.Dropout(0.2)(c4)\n",
    "c4 = tf.keras.layers.Conv2D(128, (3, 3), activation=\"relu\", kernel_initializer=\"he_normal\", padding=\"same\")(c4)\n",
    "p4 = tf.keras.layers.MaxPooling2D((2, 2))(c4)\n",
    "\n",
    "c5 = tf.keras.layers.Conv2D(256, (3, 3), activation=\"relu\", kernel_initializer=\"he_normal\", padding=\"same\")(p4)\n",
    "c5 = tf.keras.layers.Dropout(0.3)(c5)\n",
    "c5 = tf.keras.layers.Conv2D(256, (3, 3), activation=\"relu\", kernel_initializer=\"he_normal\", padding=\"same\")(c5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2c9af25a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)           [(None, 256, 512, 1  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d_38 (Conv2D)             (None, 256, 512, 16  160         ['input_2[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " dropout_18 (Dropout)           (None, 256, 512, 16  0           ['conv2d_38[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_39 (Conv2D)             (None, 256, 512, 16  2320        ['dropout_18[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d_8 (MaxPooling2D)  (None, 128, 256, 16  0          ['conv2d_39[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_40 (Conv2D)             (None, 128, 256, 32  4640        ['max_pooling2d_8[0][0]']        \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " dropout_19 (Dropout)           (None, 128, 256, 32  0           ['conv2d_40[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_41 (Conv2D)             (None, 128, 256, 32  9248        ['dropout_19[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d_9 (MaxPooling2D)  (None, 64, 128, 32)  0          ['conv2d_41[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_42 (Conv2D)             (None, 64, 128, 64)  18496       ['max_pooling2d_9[0][0]']        \n",
      "                                                                                                  \n",
      " dropout_20 (Dropout)           (None, 64, 128, 64)  0           ['conv2d_42[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_43 (Conv2D)             (None, 64, 128, 64)  36928       ['dropout_20[0][0]']             \n",
      "                                                                                                  \n",
      " max_pooling2d_10 (MaxPooling2D  (None, 32, 64, 64)  0           ['conv2d_43[0][0]']              \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv2d_44 (Conv2D)             (None, 32, 64, 128)  73856       ['max_pooling2d_10[0][0]']       \n",
      "                                                                                                  \n",
      " dropout_21 (Dropout)           (None, 32, 64, 128)  0           ['conv2d_44[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_45 (Conv2D)             (None, 32, 64, 128)  147584      ['dropout_21[0][0]']             \n",
      "                                                                                                  \n",
      " max_pooling2d_11 (MaxPooling2D  (None, 16, 32, 128)  0          ['conv2d_45[0][0]']              \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " conv2d_46 (Conv2D)             (None, 16, 32, 256)  295168      ['max_pooling2d_11[0][0]']       \n",
      "                                                                                                  \n",
      " dropout_22 (Dropout)           (None, 16, 32, 256)  0           ['conv2d_46[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_47 (Conv2D)             (None, 16, 32, 256)  590080      ['dropout_22[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d_transpose_8 (Conv2DTran  (None, 32, 64, 128)  131200     ['conv2d_47[0][0]']              \n",
      " spose)                                                                                           \n",
      "                                                                                                  \n",
      " concatenate_8 (Concatenate)    (None, 32, 64, 256)  0           ['conv2d_transpose_8[0][0]',     \n",
      "                                                                  'conv2d_45[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_48 (Conv2D)             (None, 32, 64, 128)  295040      ['concatenate_8[0][0]']          \n",
      "                                                                                                  \n",
      " dropout_23 (Dropout)           (None, 32, 64, 128)  0           ['conv2d_48[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_49 (Conv2D)             (None, 32, 64, 128)  147584      ['dropout_23[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d_transpose_9 (Conv2DTran  (None, 64, 128, 64)  32832      ['conv2d_49[0][0]']              \n",
      " spose)                                                                                           \n",
      "                                                                                                  \n",
      " concatenate_9 (Concatenate)    (None, 64, 128, 128  0           ['conv2d_transpose_9[0][0]',     \n",
      "                                )                                 'conv2d_43[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_50 (Conv2D)             (None, 64, 128, 64)  73792       ['concatenate_9[0][0]']          \n",
      "                                                                                                  \n",
      " dropout_24 (Dropout)           (None, 64, 128, 64)  0           ['conv2d_50[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_51 (Conv2D)             (None, 64, 128, 64)  36928       ['dropout_24[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d_transpose_10 (Conv2DTra  (None, 128, 256, 32  8224       ['conv2d_51[0][0]']              \n",
      " nspose)                        )                                                                 \n",
      "                                                                                                  \n",
      " concatenate_10 (Concatenate)   (None, 128, 256, 64  0           ['conv2d_transpose_10[0][0]',    \n",
      "                                )                                 'conv2d_41[0][0]']              \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " conv2d_52 (Conv2D)             (None, 128, 256, 32  18464       ['concatenate_10[0][0]']         \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " dropout_25 (Dropout)           (None, 128, 256, 32  0           ['conv2d_52[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_53 (Conv2D)             (None, 128, 256, 32  9248        ['dropout_25[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_transpose_11 (Conv2DTra  (None, 256, 512, 16  2064       ['conv2d_53[0][0]']              \n",
      " nspose)                        )                                                                 \n",
      "                                                                                                  \n",
      " concatenate_11 (Concatenate)   (None, 256, 512, 32  0           ['conv2d_transpose_11[0][0]',    \n",
      "                                )                                 'conv2d_39[0][0]']              \n",
      "                                                                                                  \n",
      " conv2d_54 (Conv2D)             (None, 256, 512, 16  4624        ['concatenate_11[0][0]']         \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " dropout_26 (Dropout)           (None, 256, 512, 16  0           ['conv2d_54[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_55 (Conv2D)             (None, 256, 512, 16  2320        ['dropout_26[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_56 (Conv2D)             (None, 256, 512, 1)  17          ['conv2d_55[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,940,817\n",
      "Trainable params: 1,940,817\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Expansive path\n",
    "u6 = tf.keras.layers.Conv2DTranspose(128, (2, 2), strides=(2, 2), padding=\"same\")(c5)\n",
    "u6 = tf.keras.layers.concatenate([u6, c4])\n",
    "c6 = tf.keras.layers.Conv2D(128, (3, 3), activation=\"relu\", kernel_initializer=\"he_normal\", padding=\"same\")(u6)\n",
    "c6 = tf.keras.layers.Dropout(0.2)(c6)\n",
    "c6 = tf.keras.layers.Conv2D(128, (3, 3), activation=\"relu\", kernel_initializer=\"he_normal\", padding=\"same\")(c6)\n",
    "\n",
    "u7 = tf.keras.layers.Conv2DTranspose(64, (2, 2), strides=(2, 2), padding=\"same\")(c6)\n",
    "u7 = tf.keras.layers.concatenate([u7, c3])\n",
    "c7 = tf.keras.layers.Conv2D(64, (3, 3), activation=\"relu\", kernel_initializer=\"he_normal\", padding=\"same\")(u7)\n",
    "c7 = tf.keras.layers.Dropout(0.2)(c7)\n",
    "c7 = tf.keras.layers.Conv2D(64, (3, 3), activation=\"relu\", kernel_initializer=\"he_normal\", padding=\"same\")(c7)\n",
    "\n",
    "u8 = tf.keras.layers.Conv2DTranspose(32, (2, 2), strides=(2, 2), padding=\"same\")(c7)\n",
    "u8 = tf.keras.layers.concatenate([u8, c2])\n",
    "c8 = tf.keras.layers.Conv2D(32, (3, 3), activation=\"relu\", kernel_initializer=\"he_normal\", padding=\"same\")(u8)\n",
    "c8 = tf.keras.layers.Dropout(0.1)(c8)\n",
    "c8 = tf.keras.layers.Conv2D(32, (3, 3), activation=\"relu\", kernel_initializer=\"he_normal\", padding=\"same\")(c8)\n",
    "\n",
    "u9 = tf.keras.layers.Conv2DTranspose(16, (2, 2), strides=(2, 2), padding=\"same\")(c8)\n",
    "u9 = tf.keras.layers.concatenate([u9, c1], axis=3)\n",
    "c9 = tf.keras.layers.Conv2D(16, (3, 3), activation=\"relu\", kernel_initializer=\"he_normal\", padding=\"same\")(u9)\n",
    "c9 = tf.keras.layers.Dropout(0.1)(c9)\n",
    "c9 = tf.keras.layers.Conv2D(16, (3, 3), activation=\"relu\", kernel_initializer=\"he_normal\", padding=\"same\")(c9)\n",
    "\n",
    "outputs = tf.keras.layers.Conv2D(1, (1, 1))(c9) # activation=\"sigmoid\"\n",
    "\n",
    "model = tf.keras.Model(inputs=[inputs], outputs=[outputs])\n",
    "model.compile(optimizer=\"adam\", loss=\"mae\", metrics=[\"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "eb28aa61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22, 256, 512)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "raw",
   "id": "45db4ff6",
   "metadata": {},
   "source": [
    "y = y.reshape(22, 499, 802, 1)\n",
    "print(y.shape)\n",
    "X = X.reshape(22, 499, 802, 1)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "58148784",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X[:,:256,:512]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9317c2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y[:,:256,:512]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "efb6130b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a8b91b65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 0.4312 - accuracy: 0.0020 - val_loss: 1.9622 - val_accuracy: 0.0026\n",
      "Epoch 2/2000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 0.4386 - accuracy: 0.0019 - val_loss: 1.9570 - val_accuracy: 0.0026\n",
      "Epoch 3/2000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 0.4321 - accuracy: 0.0021 - val_loss: 1.9563 - val_accuracy: 0.0026\n",
      "Epoch 4/2000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 0.4321 - accuracy: 0.0021 - val_loss: 1.9304 - val_accuracy: 0.0026\n",
      "Epoch 5/2000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 0.4154 - accuracy: 0.0023 - val_loss: 1.9269 - val_accuracy: 0.0026\n",
      "Epoch 6/2000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 0.4402 - accuracy: 0.0022 - val_loss: 1.9471 - val_accuracy: 0.0026\n",
      "Epoch 7/2000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 0.4210 - accuracy: 0.0021 - val_loss: 1.9409 - val_accuracy: 0.0026\n",
      "Epoch 8/2000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 0.4270 - accuracy: 0.0017 - val_loss: 1.9258 - val_accuracy: 0.0026\n",
      "Epoch 9/2000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 0.4172 - accuracy: 0.0020 - val_loss: 1.9344 - val_accuracy: 0.0026\n",
      "Epoch 10/2000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 0.4606 - accuracy: 0.0014 - val_loss: 1.9236 - val_accuracy: 0.0026\n",
      "Epoch 11/2000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 0.4405 - accuracy: 0.0020 - val_loss: 1.9463 - val_accuracy: 0.0026\n",
      "Epoch 12/2000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 0.4085 - accuracy: 0.0018 - val_loss: 1.9710 - val_accuracy: 0.0026\n",
      "Epoch 13/2000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 0.4440 - accuracy: 0.0018 - val_loss: 1.9378 - val_accuracy: 0.0026\n",
      "Epoch 14/2000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 0.4738 - accuracy: 0.0021 - val_loss: 1.9222 - val_accuracy: 0.0026\n",
      "Epoch 15/2000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 0.4111 - accuracy: 0.0021 - val_loss: 1.9592 - val_accuracy: 0.0026\n",
      "Epoch 16/2000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 0.5348 - accuracy: 0.0015 - val_loss: 1.9162 - val_accuracy: 0.0026\n",
      "Epoch 17/2000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 0.4535 - accuracy: 0.0020 - val_loss: 1.9073 - val_accuracy: 0.0026\n",
      "Epoch 18/2000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 0.4622 - accuracy: 0.0022 - val_loss: 1.9534 - val_accuracy: 0.0026\n",
      "Epoch 19/2000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 0.4798 - accuracy: 0.0018 - val_loss: 1.9496 - val_accuracy: 0.0026\n",
      "Epoch 20/2000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 0.4148 - accuracy: 0.0021 - val_loss: 1.9253 - val_accuracy: 0.0026\n",
      "Epoch 21/2000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 0.4400 - accuracy: 0.0022 - val_loss: 1.9399 - val_accuracy: 0.0026\n",
      "Epoch 22/2000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 0.4160 - accuracy: 0.0018 - val_loss: 1.9823 - val_accuracy: 0.0026\n",
      "Epoch 23/2000\n",
      "1/1 [==============================] - 9s 9s/step - loss: 0.4293 - accuracy: 0.0021 - val_loss: 1.9312 - val_accuracy: 0.0026\n",
      "Epoch 24/2000\n",
      "1/1 [==============================] - 9s 9s/step - loss: 0.4236 - accuracy: 0.0022 - val_loss: 1.9230 - val_accuracy: 0.0026\n",
      "Epoch 25/2000\n",
      "1/1 [==============================] - 10s 10s/step - loss: 0.3990 - accuracy: 0.0021 - val_loss: 1.9643 - val_accuracy: 0.0026\n",
      "Epoch 26/2000\n",
      "1/1 [==============================] - 14s 14s/step - loss: 0.4429 - accuracy: 0.0017 - val_loss: 1.9379 - val_accuracy: 0.0026\n",
      "Epoch 27/2000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 0.4227 - accuracy: 0.0021 - val_loss: 1.9081 - val_accuracy: 0.0026\n",
      "Epoch 28/2000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 0.4132 - accuracy: 0.0022 - val_loss: 1.9349 - val_accuracy: 0.0026\n",
      "Epoch 29/2000\n",
      "1/1 [==============================] - 14s 14s/step - loss: 0.4130 - accuracy: 0.0015 - val_loss: 1.9490 - val_accuracy: 0.0026\n",
      "Epoch 30/2000\n",
      "1/1 [==============================] - 14s 14s/step - loss: 0.4246 - accuracy: 0.0020 - val_loss: 1.9056 - val_accuracy: 0.0026\n",
      "Epoch 31/2000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 0.3941 - accuracy: 0.0020 - val_loss: 1.9043 - val_accuracy: 0.0026\n",
      "Epoch 32/2000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 0.4268 - accuracy: 0.0018 - val_loss: 1.9301 - val_accuracy: 0.0026\n",
      "Epoch 33/2000\n",
      "1/1 [==============================] - 14s 14s/step - loss: 0.3828 - accuracy: 0.0019 - val_loss: 1.9426 - val_accuracy: 0.0026\n",
      "Epoch 34/2000\n",
      "1/1 [==============================] - 12s 12s/step - loss: 0.3931 - accuracy: 0.0017 - val_loss: 1.9265 - val_accuracy: 0.0026\n",
      "Epoch 35/2000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 0.4135 - accuracy: 0.0016 - val_loss: 1.9134 - val_accuracy: 0.0026\n",
      "Epoch 36/2000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 0.3900 - accuracy: 0.0021 - val_loss: 1.9226 - val_accuracy: 0.0026\n",
      "Epoch 37/2000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 0.3832 - accuracy: 0.0019 - val_loss: 1.9009 - val_accuracy: 0.0026\n",
      "Epoch 38/2000\n",
      "1/1 [==============================] - 9s 9s/step - loss: 0.4014 - accuracy: 0.0021 - val_loss: 1.8826 - val_accuracy: 0.0026\n",
      "Epoch 39/2000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 0.4168 - accuracy: 0.0021 - val_loss: 1.9196 - val_accuracy: 0.0026\n",
      "Epoch 40/2000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 0.3720 - accuracy: 0.0018 - val_loss: 1.9567 - val_accuracy: 0.0025\n",
      "Epoch 41/2000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 0.4070 - accuracy: 0.0019 - val_loss: 1.9190 - val_accuracy: 0.0026\n",
      "Epoch 42/2000\n",
      "1/1 [==============================] - 12s 12s/step - loss: 0.3999 - accuracy: 0.0022 - val_loss: 1.9150 - val_accuracy: 0.0026\n",
      "Epoch 43/2000\n",
      "1/1 [==============================] - 12s 12s/step - loss: 0.3772 - accuracy: 0.0020 - val_loss: 1.9428 - val_accuracy: 0.0026\n",
      "Epoch 44/2000\n",
      "1/1 [==============================] - 12s 12s/step - loss: 0.4042 - accuracy: 0.0018 - val_loss: 1.9300 - val_accuracy: 0.0026\n",
      "Epoch 45/2000\n",
      "1/1 [==============================] - 12s 12s/step - loss: 0.3783 - accuracy: 0.0022 - val_loss: 1.9155 - val_accuracy: 0.0026\n",
      "Epoch 46/2000\n",
      "1/1 [==============================] - 12s 12s/step - loss: 0.3797 - accuracy: 0.0022 - val_loss: 1.9356 - val_accuracy: 0.0026\n",
      "Epoch 47/2000\n",
      "1/1 [==============================] - 12s 12s/step - loss: 0.3659 - accuracy: 0.0018 - val_loss: 1.9473 - val_accuracy: 0.0026\n",
      "Epoch 48/2000\n",
      "1/1 [==============================] - 12s 12s/step - loss: 0.3734 - accuracy: 0.0018 - val_loss: 1.9205 - val_accuracy: 0.0026\n",
      "Epoch 49/2000\n",
      "1/1 [==============================] - 12s 12s/step - loss: 0.3641 - accuracy: 0.0021 - val_loss: 1.9059 - val_accuracy: 0.0026\n",
      "Epoch 50/2000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 0.3703 - accuracy: 0.0020 - val_loss: 1.9180 - val_accuracy: 0.0026\n",
      "Epoch 51/2000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 0.3535 - accuracy: 0.0020 - val_loss: 1.9333 - val_accuracy: 0.0026\n",
      "Epoch 52/2000\n",
      "1/1 [==============================] - 12s 12s/step - loss: 0.3721 - accuracy: 0.0020 - val_loss: 1.9133 - val_accuracy: 0.0026\n",
      "Epoch 53/2000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 0.3640 - accuracy: 0.0021 - val_loss: 1.9255 - val_accuracy: 0.0026\n",
      "Epoch 54/2000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 0.3525 - accuracy: 0.0020 - val_loss: 1.9397 - val_accuracy: 0.0026\n",
      "Epoch 55/2000\n",
      "1/1 [==============================] - 12s 12s/step - loss: 0.3698 - accuracy: 0.0023 - val_loss: 1.9238 - val_accuracy: 0.0026\n",
      "Epoch 56/2000\n",
      "1/1 [==============================] - 12s 12s/step - loss: 0.3554 - accuracy: 0.0023 - val_loss: 1.9011 - val_accuracy: 0.0026\n",
      "Epoch 57/2000\n",
      "1/1 [==============================] - 12s 12s/step - loss: 0.3575 - accuracy: 0.0018 - val_loss: 1.9199 - val_accuracy: 0.0026\n",
      "Epoch 58/2000\n",
      "1/1 [==============================] - 12s 12s/step - loss: 0.3523 - accuracy: 0.0021 - val_loss: 1.9463 - val_accuracy: 0.0024\n",
      "Epoch 59/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 13s 13s/step - loss: 0.3689 - accuracy: 0.0021 - val_loss: 1.9126 - val_accuracy: 0.0026\n",
      "Epoch 60/2000\n",
      "1/1 [==============================] - 12s 12s/step - loss: 0.3656 - accuracy: 0.0021 - val_loss: 1.9237 - val_accuracy: 0.0024\n",
      "Epoch 61/2000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 0.3532 - accuracy: 0.0021 - val_loss: 1.9464 - val_accuracy: 0.0023\n",
      "Epoch 62/2000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 0.3515 - accuracy: 0.0021 - val_loss: 1.9282 - val_accuracy: 0.0026\n",
      "Epoch 63/2000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 0.3756 - accuracy: 0.0022 - val_loss: 1.9219 - val_accuracy: 0.0023\n",
      "Epoch 64/2000\n",
      "1/1 [==============================] - 12s 12s/step - loss: 0.3510 - accuracy: 0.0020 - val_loss: 1.9272 - val_accuracy: 0.0024\n",
      "Epoch 65/2000\n",
      "1/1 [==============================] - 12s 12s/step - loss: 0.3428 - accuracy: 0.0020 - val_loss: 1.9341 - val_accuracy: 0.0026\n",
      "Epoch 66/2000\n",
      "1/1 [==============================] - 12s 12s/step - loss: 0.3704 - accuracy: 0.0021 - val_loss: 1.9445 - val_accuracy: 0.0025\n",
      "Epoch 67/2000\n",
      "1/1 [==============================] - 12s 12s/step - loss: 0.3462 - accuracy: 0.0020 - val_loss: 1.9427 - val_accuracy: 0.0026\n",
      "Epoch 68/2000\n",
      "1/1 [==============================] - 12s 12s/step - loss: 0.3352 - accuracy: 0.0021 - val_loss: 1.9247 - val_accuracy: 0.0026\n",
      "Epoch 69/2000\n",
      "1/1 [==============================] - 12s 12s/step - loss: 0.3483 - accuracy: 0.0022 - val_loss: 1.9064 - val_accuracy: 0.0026\n",
      "Epoch 70/2000\n",
      "1/1 [==============================] - 12s 12s/step - loss: 0.3529 - accuracy: 0.0022 - val_loss: 1.8741 - val_accuracy: 0.0026\n",
      "Epoch 71/2000\n",
      "1/1 [==============================] - 12s 12s/step - loss: 0.3473 - accuracy: 0.0022 - val_loss: 1.8916 - val_accuracy: 0.0026\n",
      "Epoch 72/2000\n",
      "1/1 [==============================] - 12s 12s/step - loss: 0.3321 - accuracy: 0.0020 - val_loss: 1.9140 - val_accuracy: 0.0026\n",
      "Epoch 73/2000\n",
      "1/1 [==============================] - 12s 12s/step - loss: 0.3476 - accuracy: 0.0022 - val_loss: 1.9074 - val_accuracy: 0.0026\n",
      "Epoch 74/2000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 0.3837 - accuracy: 0.0021 - val_loss: 1.9300 - val_accuracy: 0.0026\n",
      "Epoch 75/2000\n",
      "1/1 [==============================] - 12s 12s/step - loss: 0.3310 - accuracy: 0.0019 - val_loss: 1.9312 - val_accuracy: 0.0022\n",
      "Epoch 76/2000\n",
      "1/1 [==============================] - 12s 12s/step - loss: 0.3643 - accuracy: 0.0019 - val_loss: 1.8924 - val_accuracy: 0.0026\n",
      "Epoch 77/2000\n",
      "1/1 [==============================] - 12s 12s/step - loss: 0.4202 - accuracy: 0.0021 - val_loss: 1.9076 - val_accuracy: 0.0026\n",
      "Epoch 78/2000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 0.3327 - accuracy: 0.0020 - val_loss: 1.9455 - val_accuracy: 0.0026\n",
      "Epoch 79/2000\n",
      "1/1 [==============================] - 12s 12s/step - loss: 0.4040 - accuracy: 0.0018 - val_loss: 1.9361 - val_accuracy: 0.0026\n",
      "Epoch 80/2000\n",
      "1/1 [==============================] - 12s 12s/step - loss: 0.3737 - accuracy: 0.0023 - val_loss: 1.9384 - val_accuracy: 0.0026\n",
      "Epoch 81/2000\n",
      "1/1 [==============================] - 12s 12s/step - loss: 0.3464 - accuracy: 0.0022 - val_loss: 1.9389 - val_accuracy: 0.0026\n",
      "Epoch 82/2000\n",
      "1/1 [==============================] - 12s 12s/step - loss: 0.4434 - accuracy: 0.0021 - val_loss: 1.8790 - val_accuracy: 0.0026\n",
      "Epoch 83/2000\n",
      "1/1 [==============================] - 12s 12s/step - loss: 0.3482 - accuracy: 0.0022 - val_loss: 1.8928 - val_accuracy: 0.0026\n",
      "Epoch 84/2000\n",
      "1/1 [==============================] - 12s 12s/step - loss: 0.3567 - accuracy: 0.0022 - val_loss: 1.9375 - val_accuracy: 0.0023\n",
      "Epoch 85/2000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 0.3798 - accuracy: 0.0017 - val_loss: 1.9124 - val_accuracy: 0.0026\n",
      "Epoch 86/2000\n",
      "1/1 [==============================] - 12s 12s/step - loss: 0.3398 - accuracy: 0.0022 - val_loss: 1.9263 - val_accuracy: 0.0025\n",
      "Epoch 87/2000\n",
      "1/1 [==============================] - 12s 12s/step - loss: 0.3363 - accuracy: 0.0021 - val_loss: 1.9502 - val_accuracy: 0.0017\n",
      "Epoch 88/2000\n",
      "1/1 [==============================] - 12s 12s/step - loss: 0.3711 - accuracy: 0.0019 - val_loss: 1.8968 - val_accuracy: 0.0022\n",
      "Epoch 89/2000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 0.3485 - accuracy: 0.0021 - val_loss: 1.9074 - val_accuracy: 0.0021\n",
      "Epoch 90/2000\n",
      "1/1 [==============================] - 12s 12s/step - loss: 0.3192 - accuracy: 0.0019 - val_loss: 1.9326 - val_accuracy: 0.0018\n",
      "Epoch 91/2000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 0.3619 - accuracy: 0.0018 - val_loss: 1.8875 - val_accuracy: 0.0025\n",
      "Epoch 92/2000\n",
      "1/1 [==============================] - 12s 12s/step - loss: 0.3597 - accuracy: 0.0021 - val_loss: 1.8970 - val_accuracy: 0.0023\n",
      "Epoch 93/2000\n",
      "1/1 [==============================] - 12s 12s/step - loss: 0.3222 - accuracy: 0.0021 - val_loss: 1.9490 - val_accuracy: 0.0018\n",
      "Epoch 94/2000\n",
      "1/1 [==============================] - 12s 12s/step - loss: 0.3997 - accuracy: 0.0018 - val_loss: 1.9112 - val_accuracy: 0.0026\n",
      "Epoch 95/2000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 0.3392 - accuracy: 0.0021 - val_loss: 1.8987 - val_accuracy: 0.0026\n",
      "Epoch 96/2000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 0.3482 - accuracy: 0.0020 - val_loss: 1.9340 - val_accuracy: 0.0019\n",
      "Epoch 97/2000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 0.3839 - accuracy: 0.0021 - val_loss: 1.9266 - val_accuracy: 0.0026\n",
      "Epoch 98/2000\n",
      "1/1 [==============================] - 12s 12s/step - loss: 0.3191 - accuracy: 0.0022 - val_loss: 1.8924 - val_accuracy: 0.0026\n",
      "Epoch 99/2000\n",
      "1/1 [==============================] - 12s 12s/step - loss: 0.3675 - accuracy: 0.0022 - val_loss: 1.9144 - val_accuracy: 0.0024\n",
      "Epoch 100/2000\n",
      "1/1 [==============================] - 12s 12s/step - loss: 0.3203 - accuracy: 0.0020 - val_loss: 1.9461 - val_accuracy: 0.0025\n",
      "Epoch 101/2000\n",
      "1/1 [==============================] - 12s 12s/step - loss: 0.3376 - accuracy: 0.0019 - val_loss: 1.9105 - val_accuracy: 0.0026\n",
      "Epoch 102/2000\n",
      "1/1 [==============================] - 12s 12s/step - loss: 0.3388 - accuracy: 0.0020 - val_loss: 1.9054 - val_accuracy: 0.0026\n",
      "Epoch 103/2000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 0.3212 - accuracy: 0.0021 - val_loss: 1.9344 - val_accuracy: 0.0025\n",
      "Epoch 104/2000\n",
      "1/1 [==============================] - 12s 12s/step - loss: 0.3226 - accuracy: 0.0018 - val_loss: 1.9141 - val_accuracy: 0.0026\n",
      "Epoch 105/2000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 0.3181 - accuracy: 0.0023 - val_loss: 1.9063 - val_accuracy: 0.0025\n",
      "Epoch 106/2000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 0.3069 - accuracy: 0.0021 - val_loss: 1.9224 - val_accuracy: 0.0023\n",
      "Epoch 107/2000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 0.3128 - accuracy: 0.0020 - val_loss: 1.9137 - val_accuracy: 0.0024\n",
      "Epoch 108/2000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 0.3030 - accuracy: 0.0022 - val_loss: 1.9052 - val_accuracy: 0.0023\n",
      "Epoch 109/2000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 0.2994 - accuracy: 0.0021 - val_loss: 1.9153 - val_accuracy: 0.0024\n",
      "Epoch 110/2000\n",
      "1/1 [==============================] - 12s 12s/step - loss: 0.2990 - accuracy: 0.0021 - val_loss: 1.9110 - val_accuracy: 0.0023\n",
      "Epoch 111/2000\n",
      "1/1 [==============================] - 12s 12s/step - loss: 0.3006 - accuracy: 0.0020 - val_loss: 1.9068 - val_accuracy: 0.0025\n",
      "Epoch 112/2000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 0.2995 - accuracy: 0.0019 - val_loss: 1.9131 - val_accuracy: 0.0024\n",
      "Epoch 113/2000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 0.2985 - accuracy: 0.0019 - val_loss: 1.9256 - val_accuracy: 0.0023\n",
      "Epoch 114/2000\n",
      "1/1 [==============================] - 12s 12s/step - loss: 0.3002 - accuracy: 0.0020 - val_loss: 1.9216 - val_accuracy: 0.0026\n",
      "Epoch 115/2000\n",
      "1/1 [==============================] - 12s 12s/step - loss: 0.2935 - accuracy: 0.0022 - val_loss: 1.9279 - val_accuracy: 0.0025\n",
      "Epoch 116/2000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 0.2982 - accuracy: 0.0018 - val_loss: 1.9408 - val_accuracy: 0.0022\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 117/2000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 0.3035 - accuracy: 0.0018 - val_loss: 1.9204 - val_accuracy: 0.0026\n",
      "Epoch 118/2000\n",
      "1/1 [==============================] - 12s 12s/step - loss: 0.3111 - accuracy: 0.0017 - val_loss: 1.9059 - val_accuracy: 0.0025\n",
      "Epoch 119/2000\n",
      "1/1 [==============================] - 12s 12s/step - loss: 0.3062 - accuracy: 0.0019 - val_loss: 1.9239 - val_accuracy: 0.0023\n",
      "Epoch 120/2000\n",
      "1/1 [==============================] - 12s 12s/step - loss: 0.3138 - accuracy: 0.0018 - val_loss: 1.9050 - val_accuracy: 0.0026\n",
      "Epoch 121/2000\n",
      "1/1 [==============================] - 12s 12s/step - loss: 0.3178 - accuracy: 0.0019 - val_loss: 1.8959 - val_accuracy: 0.0026\n",
      "Epoch 122/2000\n",
      "1/1 [==============================] - 12s 12s/step - loss: 0.3010 - accuracy: 0.0018 - val_loss: 1.9169 - val_accuracy: 0.0026\n",
      "Epoch 123/2000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 0.3078 - accuracy: 0.0018 - val_loss: 1.9084 - val_accuracy: 0.0026\n",
      "Epoch 124/2000\n",
      "1/1 [==============================] - 12s 12s/step - loss: 0.3084 - accuracy: 0.0020 - val_loss: 1.9126 - val_accuracy: 0.0026\n",
      "Epoch 125/2000\n",
      "1/1 [==============================] - 12s 12s/step - loss: 0.2907 - accuracy: 0.0021 - val_loss: 1.9360 - val_accuracy: 0.0026\n",
      "Epoch 126/2000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 0.3062 - accuracy: 0.0021 - val_loss: 1.9174 - val_accuracy: 0.0026\n",
      "Epoch 127/2000\n",
      "1/1 [==============================] - 12s 12s/step - loss: 0.3111 - accuracy: 0.0021 - val_loss: 1.9016 - val_accuracy: 0.0026\n",
      "Epoch 128/2000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 0.2931 - accuracy: 0.0020 - val_loss: 1.9164 - val_accuracy: 0.0026\n",
      "Epoch 129/2000\n",
      "1/1 [==============================] - 12s 12s/step - loss: 0.3078 - accuracy: 0.0020 - val_loss: 1.9101 - val_accuracy: 0.0026\n",
      "Epoch 130/2000\n",
      "1/1 [==============================] - 12s 12s/step - loss: 0.3130 - accuracy: 0.0023 - val_loss: 1.9040 - val_accuracy: 0.0026\n",
      "Epoch 131/2000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 0.2987 - accuracy: 0.0020 - val_loss: 1.9392 - val_accuracy: 0.0022\n",
      "Epoch 132/2000\n",
      "1/1 [==============================] - 12s 12s/step - loss: 0.3180 - accuracy: 0.0018 - val_loss: 1.9155 - val_accuracy: 0.0026\n",
      "Epoch 133/2000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 0.3153 - accuracy: 0.0022 - val_loss: 1.8915 - val_accuracy: 0.0026\n",
      "Epoch 134/2000\n",
      "1/1 [==============================] - 12s 12s/step - loss: 0.2974 - accuracy: 0.0019 - val_loss: 1.9223 - val_accuracy: 0.0024\n",
      "Epoch 135/2000\n",
      "1/1 [==============================] - 12s 12s/step - loss: 0.3289 - accuracy: 0.0019 - val_loss: 1.9027 - val_accuracy: 0.0026\n",
      "Epoch 136/2000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 0.3092 - accuracy: 0.0022 - val_loss: 1.8866 - val_accuracy: 0.0026\n",
      "Epoch 137/2000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 0.2963 - accuracy: 0.0020 - val_loss: 1.9143 - val_accuracy: 0.0020\n",
      "Epoch 138/2000\n",
      "1/1 [==============================] - 12s 12s/step - loss: 0.3297 - accuracy: 0.0018 - val_loss: 1.8964 - val_accuracy: 0.0026\n",
      "Epoch 139/2000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 0.3066 - accuracy: 0.0020 - val_loss: 1.8853 - val_accuracy: 0.0026\n",
      "Epoch 140/2000\n",
      "1/1 [==============================] - 12s 12s/step - loss: 0.2975 - accuracy: 0.0020 - val_loss: 1.9145 - val_accuracy: 0.0017\n",
      "Epoch 141/2000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 0.3402 - accuracy: 0.0018 - val_loss: 1.9039 - val_accuracy: 0.0026\n",
      "Epoch 142/2000\n",
      "1/1 [==============================] - 14s 14s/step - loss: 0.2798 - accuracy: 0.0021 - val_loss: 1.9044 - val_accuracy: 0.0026\n",
      "Epoch 143/2000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 0.3069 - accuracy: 0.0023 - val_loss: 1.9386 - val_accuracy: 0.0021\n",
      "Epoch 144/2000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 0.2997 - accuracy: 0.0019 - val_loss: 1.9350 - val_accuracy: 0.0025\n",
      "Epoch 145/2000\n",
      "1/1 [==============================] - 12s 12s/step - loss: 0.2794 - accuracy: 0.0019 - val_loss: 1.9097 - val_accuracy: 0.0026\n",
      "Epoch 146/2000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 0.3139 - accuracy: 0.0022 - val_loss: 1.9237 - val_accuracy: 0.0026\n",
      "Epoch 147/2000\n",
      "1/1 [==============================] - 12s 12s/step - loss: 0.2789 - accuracy: 0.0020 - val_loss: 1.9240 - val_accuracy: 0.0025\n",
      "Epoch 148/2000\n",
      "1/1 [==============================] - 12s 12s/step - loss: 0.2800 - accuracy: 0.0018 - val_loss: 1.9045 - val_accuracy: 0.0026\n",
      "Epoch 149/2000\n",
      "1/1 [==============================] - 12s 12s/step - loss: 0.3038 - accuracy: 0.0021 - val_loss: 1.9339 - val_accuracy: 0.0023\n",
      "Epoch 150/2000\n",
      "1/1 [==============================] - 12s 12s/step - loss: 0.2754 - accuracy: 0.0020 - val_loss: 1.9397 - val_accuracy: 0.0023\n",
      "Epoch 151/2000\n",
      "1/1 [==============================] - 12s 12s/step - loss: 0.2834 - accuracy: 0.0021 - val_loss: 1.9102 - val_accuracy: 0.0026\n",
      "Epoch 152/2000\n",
      "1/1 [==============================] - 12s 12s/step - loss: 0.3089 - accuracy: 0.0021 - val_loss: 1.9229 - val_accuracy: 0.0026\n",
      "Epoch 153/2000\n",
      "1/1 [==============================] - 12s 12s/step - loss: 0.2688 - accuracy: 0.0020 - val_loss: 1.9273 - val_accuracy: 0.0026\n",
      "Epoch 154/2000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 0.2956 - accuracy: 0.0019 - val_loss: 1.8967 - val_accuracy: 0.0026\n",
      "Epoch 155/2000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 0.3033 - accuracy: 0.0022 - val_loss: 1.9217 - val_accuracy: 0.0026\n",
      "Epoch 156/2000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 0.2843 - accuracy: 0.0022 - val_loss: 1.9211 - val_accuracy: 0.0026\n",
      "Epoch 157/2000\n",
      "1/1 [==============================] - 12s 12s/step - loss: 0.3259 - accuracy: 0.0020 - val_loss: 1.8901 - val_accuracy: 0.0026\n",
      "Epoch 158/2000\n",
      "1/1 [==============================] - 12s 12s/step - loss: 0.2863 - accuracy: 0.0022 - val_loss: 1.8997 - val_accuracy: 0.0026\n",
      "Epoch 159/2000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 0.2753 - accuracy: 0.0018 - val_loss: 1.8947 - val_accuracy: 0.0026\n",
      "Epoch 160/2000\n",
      "1/1 [==============================] - 12s 12s/step - loss: 0.2895 - accuracy: 0.0022 - val_loss: 1.8902 - val_accuracy: 0.0026\n",
      "Epoch 161/2000\n",
      "1/1 [==============================] - 12s 12s/step - loss: 0.2673 - accuracy: 0.0023 - val_loss: 1.9111 - val_accuracy: 0.0026\n",
      "Epoch 162/2000\n",
      "1/1 [==============================] - 12s 12s/step - loss: 0.2840 - accuracy: 0.0023 - val_loss: 1.9140 - val_accuracy: 0.0026\n",
      "Epoch 163/2000\n",
      "1/1 [==============================] - 12s 12s/step - loss: 0.3144 - accuracy: 0.0020 - val_loss: 1.9078 - val_accuracy: 0.0026\n",
      "Epoch 164/2000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 0.2712 - accuracy: 0.0022 - val_loss: 1.9061 - val_accuracy: 0.0026\n",
      "Epoch 165/2000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 0.2798 - accuracy: 0.0021 - val_loss: 1.9122 - val_accuracy: 0.0026\n",
      "Epoch 166/2000\n",
      "1/1 [==============================] - 12s 12s/step - loss: 0.2895 - accuracy: 0.0021 - val_loss: 1.9015 - val_accuracy: 0.0026\n",
      "Epoch 167/2000\n",
      "1/1 [==============================] - 12s 12s/step - loss: 0.2652 - accuracy: 0.0021 - val_loss: 1.8831 - val_accuracy: 0.0026\n",
      "Epoch 168/2000\n",
      "1/1 [==============================] - 12s 12s/step - loss: 0.2781 - accuracy: 0.0023 - val_loss: 1.9025 - val_accuracy: 0.0025\n",
      "Epoch 169/2000\n",
      "1/1 [==============================] - 12s 12s/step - loss: 0.2686 - accuracy: 0.0018 - val_loss: 1.8920 - val_accuracy: 0.0026\n",
      "Epoch 170/2000\n",
      "1/1 [==============================] - 12s 12s/step - loss: 0.2563 - accuracy: 0.0021 - val_loss: 1.8968 - val_accuracy: 0.0026\n",
      "Epoch 171/2000\n",
      "1/1 [==============================] - 12s 12s/step - loss: 0.2677 - accuracy: 0.0018 - val_loss: 1.9029 - val_accuracy: 0.0022\n",
      "Epoch 172/2000\n",
      "1/1 [==============================] - 12s 12s/step - loss: 0.2795 - accuracy: 0.0019 - val_loss: 1.8948 - val_accuracy: 0.0025\n",
      "Epoch 173/2000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 0.2633 - accuracy: 0.0021 - val_loss: 1.9053 - val_accuracy: 0.0025\n",
      "Epoch 174/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 12s 12s/step - loss: 0.2609 - accuracy: 0.0021 - val_loss: 1.9136 - val_accuracy: 0.0022\n",
      "Epoch 175/2000\n",
      "1/1 [==============================] - 12s 12s/step - loss: 0.2766 - accuracy: 0.0018 - val_loss: 1.9087 - val_accuracy: 0.0026\n",
      "Epoch 176/2000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 0.2747 - accuracy: 0.0022 - val_loss: 1.8833 - val_accuracy: 0.0026\n",
      "Epoch 177/2000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 0.2625 - accuracy: 0.0019 - val_loss: 1.8927 - val_accuracy: 0.0026\n",
      "Epoch 178/2000\n",
      "1/1 [==============================] - 12s 12s/step - loss: 0.2629 - accuracy: 0.0021 - val_loss: 1.8790 - val_accuracy: 0.0026\n",
      "Epoch 179/2000\n",
      "1/1 [==============================] - 12s 12s/step - loss: 0.2684 - accuracy: 0.0020 - val_loss: 1.8847 - val_accuracy: 0.0026\n",
      "Epoch 180/2000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 0.2599 - accuracy: 0.0018 - val_loss: 1.9198 - val_accuracy: 0.0023\n",
      "Epoch 181/2000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 0.2829 - accuracy: 0.0019 - val_loss: 1.8983 - val_accuracy: 0.0026\n",
      "Epoch 182/2000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 0.2824 - accuracy: 0.0020 - val_loss: 1.9152 - val_accuracy: 0.0026\n",
      "Epoch 183/2000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 0.2526 - accuracy: 0.0020 - val_loss: 1.9211 - val_accuracy: 0.0026\n",
      "Epoch 184/2000\n",
      "1/1 [==============================] - 12s 12s/step - loss: 0.2708 - accuracy: 0.0018 - val_loss: 1.8788 - val_accuracy: 0.0026\n",
      "Epoch 185/2000\n",
      "1/1 [==============================] - 12s 12s/step - loss: 0.2881 - accuracy: 0.0020 - val_loss: 1.9034 - val_accuracy: 0.0026\n",
      "Epoch 186/2000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 0.2600 - accuracy: 0.0022 - val_loss: 1.9276 - val_accuracy: 0.0026\n",
      "Epoch 187/2000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 0.2885 - accuracy: 0.0022 - val_loss: 1.8834 - val_accuracy: 0.0026\n",
      "Epoch 188/2000\n",
      "1/1 [==============================] - 12s 12s/step - loss: 0.3093 - accuracy: 0.0021 - val_loss: 1.8937 - val_accuracy: 0.0026\n",
      "Epoch 189/2000\n",
      "1/1 [==============================] - 12s 12s/step - loss: 0.2596 - accuracy: 0.0020 - val_loss: 1.9339 - val_accuracy: 0.0026\n",
      "Epoch 190/2000\n",
      "1/1 [==============================] - 12s 12s/step - loss: 0.3463 - accuracy: 0.0022 - val_loss: 1.8708 - val_accuracy: 0.0026\n",
      "Epoch 191/2000\n",
      "1/1 [==============================] - 12s 12s/step - loss: 0.2897 - accuracy: 0.0021 - val_loss: 1.8768 - val_accuracy: 0.0026\n",
      "Epoch 192/2000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 0.2741 - accuracy: 0.0021 - val_loss: 1.9363 - val_accuracy: 0.0026\n",
      "Epoch 193/2000\n",
      "1/1 [==============================] - 12s 12s/step - loss: 0.3055 - accuracy: 0.0020 - val_loss: 1.9031 - val_accuracy: 0.0026\n",
      "Epoch 194/2000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 0.2498 - accuracy: 0.0021 - val_loss: 1.8855 - val_accuracy: 0.0026\n",
      "Epoch 195/2000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 0.2720 - accuracy: 0.0019 - val_loss: 1.9207 - val_accuracy: 0.0026\n",
      "Epoch 196/2000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 0.2630 - accuracy: 0.0018 - val_loss: 1.9197 - val_accuracy: 0.0026\n",
      "Epoch 197/2000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 0.2513 - accuracy: 0.0022 - val_loss: 1.8947 - val_accuracy: 0.0026\n",
      "Epoch 198/2000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 0.2577 - accuracy: 0.0022 - val_loss: 1.8956 - val_accuracy: 0.0026\n",
      "Epoch 199/2000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 0.2505 - accuracy: 0.0022 - val_loss: 1.9067 - val_accuracy: 0.0026\n",
      "Epoch 200/2000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 0.2727 - accuracy: 0.0021 - val_loss: 1.8873 - val_accuracy: 0.0026\n",
      "Epoch 201/2000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 0.2618 - accuracy: 0.0020 - val_loss: 1.8975 - val_accuracy: 0.0026\n",
      "Epoch 202/2000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 0.2529 - accuracy: 0.0018 - val_loss: 1.9284 - val_accuracy: 0.0026\n",
      "Epoch 203/2000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 0.2679 - accuracy: 0.0021 - val_loss: 1.9008 - val_accuracy: 0.0026\n",
      "Epoch 204/2000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 0.2636 - accuracy: 0.0020 - val_loss: 1.8644 - val_accuracy: 0.0026\n",
      "Epoch 205/2000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 0.2773 - accuracy: 0.0021 - val_loss: 1.8860 - val_accuracy: 0.0026\n",
      "Epoch 206/2000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 0.2517 - accuracy: 0.0020 - val_loss: 1.8989 - val_accuracy: 0.0026\n",
      "Epoch 207/2000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 0.2530 - accuracy: 0.0021 - val_loss: 1.8848 - val_accuracy: 0.0026\n",
      "Epoch 208/2000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 0.2729 - accuracy: 0.0022 - val_loss: 1.9144 - val_accuracy: 0.0026\n",
      "Epoch 209/2000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 0.2478 - accuracy: 0.0022 - val_loss: 1.9306 - val_accuracy: 0.0026\n",
      "Epoch 210/2000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 0.2506 - accuracy: 0.0022 - val_loss: 1.9053 - val_accuracy: 0.0025\n",
      "Epoch 211/2000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 0.2444 - accuracy: 0.0021 - val_loss: 1.9025 - val_accuracy: 0.0023\n",
      "Epoch 212/2000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 0.2427 - accuracy: 0.0018 - val_loss: 1.9020 - val_accuracy: 0.0025\n",
      "Epoch 213/2000\n",
      "1/1 [==============================] - 12s 12s/step - loss: 0.2515 - accuracy: 0.0022 - val_loss: 1.8808 - val_accuracy: 0.0026\n",
      "Epoch 214/2000\n",
      "1/1 [==============================] - 12s 12s/step - loss: 0.2501 - accuracy: 0.0021 - val_loss: 1.8927 - val_accuracy: 0.0025\n",
      "Epoch 215/2000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 0.2531 - accuracy: 0.0022 - val_loss: 1.9070 - val_accuracy: 0.0026\n",
      "Epoch 216/2000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 0.2547 - accuracy: 0.0023 - val_loss: 1.8967 - val_accuracy: 0.0026\n",
      "Epoch 217/2000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 0.2384 - accuracy: 0.0023 - val_loss: 1.8888 - val_accuracy: 0.0026\n",
      "Epoch 218/2000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 0.2392 - accuracy: 0.0020 - val_loss: 1.8968 - val_accuracy: 0.0026\n",
      "Epoch 219/2000\n",
      "1/1 [==============================] - 12s 12s/step - loss: 0.2380 - accuracy: 0.0021 - val_loss: 1.9016 - val_accuracy: 0.0026\n",
      "Epoch 220/2000\n",
      "1/1 [==============================] - 12s 12s/step - loss: 0.2371 - accuracy: 0.0020 - val_loss: 1.8978 - val_accuracy: 0.0026\n",
      "Epoch 221/2000\n",
      "1/1 [==============================] - 12s 12s/step - loss: 0.2470 - accuracy: 0.0021 - val_loss: 1.9106 - val_accuracy: 0.0026\n",
      "Epoch 222/2000\n",
      "1/1 [==============================] - 12s 12s/step - loss: 0.2382 - accuracy: 0.0022 - val_loss: 1.9004 - val_accuracy: 0.0026\n",
      "Epoch 223/2000\n",
      "1/1 [==============================] - 12s 12s/step - loss: 0.2357 - accuracy: 0.0021 - val_loss: 1.8849 - val_accuracy: 0.0026\n",
      "Epoch 224/2000\n",
      "1/1 [==============================] - 12s 12s/step - loss: 0.2517 - accuracy: 0.0021 - val_loss: 1.8993 - val_accuracy: 0.0026\n",
      "Epoch 225/2000\n",
      "1/1 [==============================] - 12s 12s/step - loss: 0.2434 - accuracy: 0.0021 - val_loss: 1.8880 - val_accuracy: 0.0026\n",
      "Epoch 226/2000\n",
      "1/1 [==============================] - 12s 12s/step - loss: 0.2369 - accuracy: 0.0022 - val_loss: 1.8938 - val_accuracy: 0.0026\n",
      "Epoch 227/2000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 0.2329 - accuracy: 0.0022 - val_loss: 1.9092 - val_accuracy: 0.0026\n",
      "Epoch 228/2000\n",
      "1/1 [==============================] - 12s 12s/step - loss: 0.2345 - accuracy: 0.0021 - val_loss: 1.8991 - val_accuracy: 0.0026\n",
      "Epoch 229/2000\n",
      "1/1 [==============================] - 12s 12s/step - loss: 0.2359 - accuracy: 0.0022 - val_loss: 1.9079 - val_accuracy: 0.0026\n",
      "Epoch 230/2000\n",
      "1/1 [==============================] - 12s 12s/step - loss: 0.2345 - accuracy: 0.0020 - val_loss: 1.9174 - val_accuracy: 0.0026\n",
      "Epoch 231/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 13s 13s/step - loss: 0.2470 - accuracy: 0.0021 - val_loss: 1.8971 - val_accuracy: 0.0026\n",
      "Epoch 232/2000\n",
      "1/1 [==============================] - 12s 12s/step - loss: 0.2419 - accuracy: 0.0021 - val_loss: 1.9127 - val_accuracy: 0.0026\n",
      "Epoch 233/2000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 0.2333 - accuracy: 0.0022 - val_loss: 1.9109 - val_accuracy: 0.0026\n",
      "Epoch 234/2000\n",
      "1/1 [==============================] - 12s 12s/step - loss: 0.2344 - accuracy: 0.0022 - val_loss: 1.8951 - val_accuracy: 0.0026\n",
      "Epoch 235/2000\n",
      "1/1 [==============================] - 12s 12s/step - loss: 0.2431 - accuracy: 0.0022 - val_loss: 1.9131 - val_accuracy: 0.0026\n",
      "Epoch 236/2000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 0.2372 - accuracy: 0.0021 - val_loss: 1.8946 - val_accuracy: 0.0026\n",
      "Epoch 237/2000\n",
      "1/1 [==============================] - 12s 12s/step - loss: 0.2303 - accuracy: 0.0021 - val_loss: 1.8785 - val_accuracy: 0.0026\n",
      "Epoch 238/2000\n",
      "1/1 [==============================] - 12s 12s/step - loss: 0.2303 - accuracy: 0.0022 - val_loss: 1.8927 - val_accuracy: 0.0026\n",
      "Epoch 239/2000\n",
      "1/1 [==============================] - 12s 12s/step - loss: 0.2289 - accuracy: 0.0019 - val_loss: 1.8967 - val_accuracy: 0.0026\n",
      "Epoch 240/2000\n",
      "1/1 [==============================] - 12s 12s/step - loss: 0.2365 - accuracy: 0.0022 - val_loss: 1.9007 - val_accuracy: 0.0026\n",
      "Epoch 241/2000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 0.2382 - accuracy: 0.0022 - val_loss: 1.9092 - val_accuracy: 0.0026\n",
      "Epoch 242/2000\n",
      "1/1 [==============================] - 12s 12s/step - loss: 0.2294 - accuracy: 0.0022 - val_loss: 1.9119 - val_accuracy: 0.0026\n",
      "Epoch 243/2000\n",
      "1/1 [==============================] - 12s 12s/step - loss: 0.2299 - accuracy: 0.0022 - val_loss: 1.8966 - val_accuracy: 0.0026\n",
      "Epoch 244/2000\n",
      "1/1 [==============================] - 12s 12s/step - loss: 0.2474 - accuracy: 0.0019 - val_loss: 1.8923 - val_accuracy: 0.0026\n",
      "Epoch 245/2000\n",
      "1/1 [==============================] - 12s 12s/step - loss: 0.2416 - accuracy: 0.0020 - val_loss: 1.8940 - val_accuracy: 0.0026\n",
      "Epoch 246/2000\n",
      "1/1 [==============================] - 12s 12s/step - loss: 0.2309 - accuracy: 0.0020 - val_loss: 1.8778 - val_accuracy: 0.0026\n",
      "Epoch 247/2000\n",
      "1/1 [==============================] - 12s 12s/step - loss: 0.2414 - accuracy: 0.0022 - val_loss: 1.9093 - val_accuracy: 0.0026\n",
      "Epoch 248/2000\n",
      "1/1 [==============================] - 12s 12s/step - loss: 0.2320 - accuracy: 0.0020 - val_loss: 1.9109 - val_accuracy: 0.0026\n",
      "Epoch 249/2000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 0.2329 - accuracy: 0.0022 - val_loss: 1.8867 - val_accuracy: 0.0026\n",
      "Epoch 250/2000\n",
      "1/1 [==============================] - 12s 12s/step - loss: 0.2445 - accuracy: 0.0020 - val_loss: 1.8942 - val_accuracy: 0.0026\n",
      "Epoch 251/2000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 0.2235 - accuracy: 0.0019 - val_loss: 1.9024 - val_accuracy: 0.0026\n",
      "Epoch 252/2000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 0.2493 - accuracy: 0.0022 - val_loss: 1.8829 - val_accuracy: 0.0026\n",
      "Epoch 253/2000\n",
      "1/1 [==============================] - 12s 12s/step - loss: 0.2538 - accuracy: 0.0022 - val_loss: 1.8886 - val_accuracy: 0.0026\n",
      "Epoch 254/2000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 0.2279 - accuracy: 0.0022 - val_loss: 1.9215 - val_accuracy: 0.0026\n",
      "Epoch 255/2000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 0.2516 - accuracy: 0.0022 - val_loss: 1.8881 - val_accuracy: 0.0026\n",
      "Epoch 256/2000\n",
      "1/1 [==============================] - 12s 12s/step - loss: 0.2363 - accuracy: 0.0022 - val_loss: 1.8973 - val_accuracy: 0.0026\n",
      "Epoch 257/2000\n",
      "1/1 [==============================] - 12s 12s/step - loss: 0.2349 - accuracy: 0.0022 - val_loss: 1.9177 - val_accuracy: 0.0026\n",
      "Epoch 258/2000\n",
      "1/1 [==============================] - 12s 12s/step - loss: 0.2522 - accuracy: 0.0022 - val_loss: 1.9022 - val_accuracy: 0.0026\n",
      "Epoch 259/2000\n",
      "1/1 [==============================] - 12s 12s/step - loss: 0.2248 - accuracy: 0.0021 - val_loss: 1.8808 - val_accuracy: 0.0026\n",
      "Epoch 260/2000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 0.2399 - accuracy: 0.0021 - val_loss: 1.9016 - val_accuracy: 0.0026\n",
      "Epoch 261/2000\n",
      "1/1 [==============================] - 12s 12s/step - loss: 0.2309 - accuracy: 0.0021 - val_loss: 1.9115 - val_accuracy: 0.0026\n",
      "Epoch 262/2000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 0.2715 - accuracy: 0.0018 - val_loss: 1.8684 - val_accuracy: 0.0026\n",
      "Epoch 263/2000\n",
      "1/1 [==============================] - 12s 12s/step - loss: 0.2712 - accuracy: 0.0023 - val_loss: 1.8870 - val_accuracy: 0.0026\n",
      "Epoch 264/2000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 0.2211 - accuracy: 0.0021 - val_loss: 1.9200 - val_accuracy: 0.0026\n",
      "Epoch 265/2000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 0.2948 - accuracy: 0.0019 - val_loss: 1.8812 - val_accuracy: 0.0026\n",
      "Epoch 266/2000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 0.2846 - accuracy: 0.0023 - val_loss: 1.8903 - val_accuracy: 0.0026\n",
      "Epoch 267/2000\n",
      "1/1 [==============================] - 12s 12s/step - loss: 0.2291 - accuracy: 0.0022 - val_loss: 1.9265 - val_accuracy: 0.0026\n",
      "Epoch 268/2000\n",
      "1/1 [==============================] - 12s 12s/step - loss: 0.3321 - accuracy: 0.0021 - val_loss: 1.8779 - val_accuracy: 0.0026\n",
      "Epoch 269/2000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 0.2594 - accuracy: 0.0021 - val_loss: 1.8865 - val_accuracy: 0.0026\n",
      "Epoch 270/2000\n",
      "1/1 [==============================] - 12s 12s/step - loss: 0.2349 - accuracy: 0.0022 - val_loss: 1.9251 - val_accuracy: 0.0026\n",
      "Epoch 271/2000\n",
      "1/1 [==============================] - 12s 12s/step - loss: 0.3144 - accuracy: 0.0019 - val_loss: 1.8769 - val_accuracy: 0.0026\n",
      "Epoch 272/2000\n",
      "1/1 [==============================] - 12s 12s/step - loss: 0.2300 - accuracy: 0.0022 - val_loss: 1.8786 - val_accuracy: 0.0026\n",
      "Epoch 273/2000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 0.2499 - accuracy: 0.0022 - val_loss: 1.9149 - val_accuracy: 0.0026\n",
      "Epoch 274/2000\n",
      "1/1 [==============================] - 12s 12s/step - loss: 0.2592 - accuracy: 0.0020 - val_loss: 1.8904 - val_accuracy: 0.0026\n",
      "Epoch 275/2000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 0.2153 - accuracy: 0.0021 - val_loss: 1.8790 - val_accuracy: 0.0026\n",
      "Epoch 276/2000\n",
      "1/1 [==============================] - 12s 12s/step - loss: 0.2477 - accuracy: 0.0022 - val_loss: 1.9070 - val_accuracy: 0.0026\n",
      "Epoch 277/2000\n",
      "1/1 [==============================] - 12s 12s/step - loss: 0.2394 - accuracy: 0.0021 - val_loss: 1.8901 - val_accuracy: 0.0026\n",
      "Epoch 278/2000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 0.2168 - accuracy: 0.0022 - val_loss: 1.8796 - val_accuracy: 0.0026\n",
      "Epoch 279/2000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 0.2255 - accuracy: 0.0022 - val_loss: 1.8983 - val_accuracy: 0.0026\n",
      "Epoch 280/2000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 0.2357 - accuracy: 0.0020 - val_loss: 1.8785 - val_accuracy: 0.0026\n",
      "Epoch 281/2000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 0.2222 - accuracy: 0.0022 - val_loss: 1.8830 - val_accuracy: 0.0026\n",
      "Epoch 282/2000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 0.2269 - accuracy: 0.0021 - val_loss: 1.9123 - val_accuracy: 0.0026\n",
      "Epoch 283/2000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 0.2344 - accuracy: 0.0021 - val_loss: 1.9139 - val_accuracy: 0.0026\n",
      "Epoch 284/2000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 0.2186 - accuracy: 0.0022 - val_loss: 1.9128 - val_accuracy: 0.0026\n",
      "Epoch 285/2000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 0.2149 - accuracy: 0.0022 - val_loss: 1.9263 - val_accuracy: 0.0026\n",
      "Epoch 286/2000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 0.2253 - accuracy: 0.0021 - val_loss: 1.9158 - val_accuracy: 0.0026\n",
      "Epoch 287/2000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 0.2167 - accuracy: 0.0023 - val_loss: 1.9133 - val_accuracy: 0.0026\n",
      "Epoch 288/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 13s 13s/step - loss: 0.2146 - accuracy: 0.0022 - val_loss: 1.9101 - val_accuracy: 0.0026\n",
      "Epoch 289/2000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 0.2130 - accuracy: 0.0022 - val_loss: 1.8995 - val_accuracy: 0.0026\n",
      "Epoch 290/2000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 0.2223 - accuracy: 0.0023 - val_loss: 1.8939 - val_accuracy: 0.0026\n",
      "Epoch 291/2000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 0.2172 - accuracy: 0.0021 - val_loss: 1.8894 - val_accuracy: 0.0026\n",
      "Epoch 292/2000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 0.2144 - accuracy: 0.0020 - val_loss: 1.8940 - val_accuracy: 0.0026\n",
      "Epoch 293/2000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 0.2116 - accuracy: 0.0021 - val_loss: 1.8989 - val_accuracy: 0.0026\n",
      "Epoch 294/2000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 0.2133 - accuracy: 0.0020 - val_loss: 1.9041 - val_accuracy: 0.0026\n",
      "Epoch 295/2000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 0.2099 - accuracy: 0.0022 - val_loss: 1.9162 - val_accuracy: 0.0026\n",
      "Epoch 296/2000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 0.2132 - accuracy: 0.0022 - val_loss: 1.9067 - val_accuracy: 0.0026\n",
      "Epoch 297/2000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 0.2171 - accuracy: 0.0021 - val_loss: 1.9105 - val_accuracy: 0.0026\n",
      "Epoch 298/2000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 0.2120 - accuracy: 0.0021 - val_loss: 1.9062 - val_accuracy: 0.0026\n",
      "Epoch 299/2000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 0.2155 - accuracy: 0.0022 - val_loss: 1.8844 - val_accuracy: 0.0026\n",
      "Epoch 300/2000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 0.2128 - accuracy: 0.0022 - val_loss: 1.8989 - val_accuracy: 0.0026\n",
      "Epoch 301/2000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 0.2087 - accuracy: 0.0022 - val_loss: 1.9024 - val_accuracy: 0.0026\n",
      "Epoch 302/2000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 0.2103 - accuracy: 0.0021 - val_loss: 1.8807 - val_accuracy: 0.0026\n",
      "Epoch 303/2000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 0.2211 - accuracy: 0.0021 - val_loss: 1.9022 - val_accuracy: 0.0026\n",
      "Epoch 304/2000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 0.2195 - accuracy: 0.0019 - val_loss: 1.8758 - val_accuracy: 0.0026\n",
      "Epoch 305/2000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 0.2213 - accuracy: 0.0022 - val_loss: 1.8791 - val_accuracy: 0.0026\n",
      "Epoch 306/2000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 0.2107 - accuracy: 0.0022 - val_loss: 1.8855 - val_accuracy: 0.0026\n",
      "Epoch 307/2000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 0.2144 - accuracy: 0.0022 - val_loss: 1.8664 - val_accuracy: 0.0026\n",
      "Epoch 308/2000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 0.2330 - accuracy: 0.0022 - val_loss: 1.8888 - val_accuracy: 0.0026\n",
      "Epoch 309/2000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 0.2156 - accuracy: 0.0022 - val_loss: 1.8863 - val_accuracy: 0.0026\n",
      "Epoch 310/2000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 0.2037 - accuracy: 0.0021 - val_loss: 1.8920 - val_accuracy: 0.0026\n",
      "Epoch 311/2000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 0.2058 - accuracy: 0.0021 - val_loss: 1.8864 - val_accuracy: 0.0026\n",
      "Epoch 312/2000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 0.2088 - accuracy: 0.0022 - val_loss: 1.8802 - val_accuracy: 0.0026\n",
      "Epoch 313/2000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 0.2061 - accuracy: 0.0019 - val_loss: 1.8777 - val_accuracy: 0.0026\n",
      "Epoch 314/2000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 0.2191 - accuracy: 0.0022 - val_loss: 1.8924 - val_accuracy: 0.0026\n",
      "Epoch 315/2000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 0.2244 - accuracy: 0.0021 - val_loss: 1.8819 - val_accuracy: 0.0026\n",
      "Epoch 316/2000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 0.2229 - accuracy: 0.0022 - val_loss: 1.8928 - val_accuracy: 0.0026\n",
      "Epoch 317/2000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 0.2121 - accuracy: 0.0022 - val_loss: 1.8829 - val_accuracy: 0.0026\n",
      "Epoch 318/2000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 0.2183 - accuracy: 0.0019 - val_loss: 1.8758 - val_accuracy: 0.0026\n",
      "Epoch 319/2000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 0.2206 - accuracy: 0.0022 - val_loss: 1.8885 - val_accuracy: 0.0026\n",
      "Epoch 320/2000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 0.2127 - accuracy: 0.0021 - val_loss: 1.8926 - val_accuracy: 0.0026\n",
      "Epoch 321/2000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 0.2444 - accuracy: 0.0022 - val_loss: 1.8839 - val_accuracy: 0.0026\n",
      "Epoch 322/2000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 0.2394 - accuracy: 0.0022 - val_loss: 1.8979 - val_accuracy: 0.0026\n",
      "Epoch 323/2000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 0.2149 - accuracy: 0.0022 - val_loss: 1.8983 - val_accuracy: 0.0026\n",
      "Epoch 324/2000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 0.2664 - accuracy: 0.0021 - val_loss: 1.8815 - val_accuracy: 0.0026\n",
      "Epoch 325/2000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 0.2428 - accuracy: 0.0022 - val_loss: 1.9099 - val_accuracy: 0.0026\n",
      "Epoch 326/2000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 0.2256 - accuracy: 0.0022 - val_loss: 1.9145 - val_accuracy: 0.0017\n",
      "Epoch 327/2000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 0.2962 - accuracy: 0.0020 - val_loss: 1.8930 - val_accuracy: 0.0026\n",
      "Epoch 328/2000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 0.2229 - accuracy: 0.0022 - val_loss: 1.9199 - val_accuracy: 0.0026\n",
      "Epoch 329/2000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 0.2571 - accuracy: 0.0022 - val_loss: 1.9090 - val_accuracy: 0.0025\n",
      "Epoch 330/2000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 0.2655 - accuracy: 0.0021 - val_loss: 1.8861 - val_accuracy: 0.0026\n",
      "Epoch 331/2000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 0.2183 - accuracy: 0.0020 - val_loss: 1.9079 - val_accuracy: 0.0026\n",
      "Epoch 332/2000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 0.2334 - accuracy: 0.0023 - val_loss: 1.8973 - val_accuracy: 0.0025\n",
      "Epoch 333/2000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 0.2233 - accuracy: 0.0022 - val_loss: 1.8846 - val_accuracy: 0.0026\n",
      "Epoch 334/2000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 0.2202 - accuracy: 0.0022 - val_loss: 1.9276 - val_accuracy: 0.0026\n",
      "Epoch 335/2000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 0.2187 - accuracy: 0.0021 - val_loss: 1.9186 - val_accuracy: 0.0026\n",
      "Epoch 336/2000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 0.2012 - accuracy: 0.0022 - val_loss: 1.9068 - val_accuracy: 0.0026\n",
      "Epoch 337/2000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 0.2214 - accuracy: 0.0022 - val_loss: 1.9208 - val_accuracy: 0.0024\n",
      "Epoch 338/2000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 0.2094 - accuracy: 0.0021 - val_loss: 1.9076 - val_accuracy: 0.0024\n",
      "Epoch 339/2000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 0.2059 - accuracy: 0.0022 - val_loss: 1.8979 - val_accuracy: 0.0021\n",
      "Epoch 340/2000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 0.2080 - accuracy: 0.0021 - val_loss: 1.9077 - val_accuracy: 0.0023\n",
      "Epoch 341/2000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 0.1977 - accuracy: 0.0021 - val_loss: 1.9189 - val_accuracy: 0.0021\n",
      "Epoch 342/2000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 0.2052 - accuracy: 0.0022 - val_loss: 1.8962 - val_accuracy: 0.0022\n",
      "Epoch 343/2000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 0.2038 - accuracy: 0.0022 - val_loss: 1.8985 - val_accuracy: 0.0020\n",
      "Epoch 344/2000\n",
      "1/1 [==============================] - 13s 13s/step - loss: 0.2037 - accuracy: 0.0021 - val_loss: 1.8955 - val_accuracy: 0.0025\n",
      "Epoch 345/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 13s 13s/step - loss: 0.2051 - accuracy: 0.0022 - val_loss: 1.8746 - val_accuracy: 0.0026\n",
      "Epoch 346/2000\n",
      "1/1 [==============================] - 14s 14s/step - loss: 0.2030 - accuracy: 0.0022 - val_loss: 1.8862 - val_accuracy: 0.0026\n",
      "Epoch 347/2000\n",
      "1/1 [==============================] - 14s 14s/step - loss: 0.2017 - accuracy: 0.0021 - val_loss: 1.8911 - val_accuracy: 0.0026\n",
      "Epoch 348/2000\n",
      "1/1 [==============================] - 10s 10s/step - loss: 0.2008 - accuracy: 0.0022 - val_loss: 1.8859 - val_accuracy: 0.0026\n",
      "Epoch 349/2000\n",
      "1/1 [==============================] - 9s 9s/step - loss: 0.1969 - accuracy: 0.0022 - val_loss: 1.8956 - val_accuracy: 0.0026\n",
      "Epoch 350/2000\n",
      "1/1 [==============================] - 9s 9s/step - loss: 0.1992 - accuracy: 0.0022 - val_loss: 1.8969 - val_accuracy: 0.0026\n",
      "Epoch 351/2000\n",
      "1/1 [==============================] - 9s 9s/step - loss: 0.1992 - accuracy: 0.0022 - val_loss: 1.8911 - val_accuracy: 0.0026\n",
      "Epoch 352/2000\n",
      "1/1 [==============================] - 10s 10s/step - loss: 0.2027 - accuracy: 0.0022 - val_loss: 1.9069 - val_accuracy: 0.0026\n",
      "Epoch 353/2000\n",
      "1/1 [==============================] - 10s 10s/step - loss: 0.2007 - accuracy: 0.0022 - val_loss: 1.9119 - val_accuracy: 0.0023\n",
      "Epoch 354/2000\n",
      "1/1 [==============================] - 9s 9s/step - loss: 0.1987 - accuracy: 0.0022 - val_loss: 1.9115 - val_accuracy: 0.0025\n",
      "Epoch 355/2000\n",
      "1/1 [==============================] - 9s 9s/step - loss: 0.2066 - accuracy: 0.0022 - val_loss: 1.9425 - val_accuracy: 0.0018\n",
      "Epoch 356/2000\n",
      "1/1 [==============================] - 9s 9s/step - loss: 0.2198 - accuracy: 0.0021 - val_loss: 1.9114 - val_accuracy: 0.0026\n",
      "Epoch 357/2000\n",
      "1/1 [==============================] - 8s 8s/step - loss: 0.2156 - accuracy: 0.0022 - val_loss: 1.9101 - val_accuracy: 0.0022\n",
      "Epoch 358/2000\n",
      "1/1 [==============================] - 9s 9s/step - loss: 0.1989 - accuracy: 0.0021 - val_loss: 1.9163 - val_accuracy: 0.0016\n",
      "Epoch 359/2000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\BASBUN~1\\AppData\\Local\\Temp/ipykernel_21392/3810146843.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m ]\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m results = model.fit(\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1382\u001b[0m                 _r=1):\n\u001b[0;32m   1383\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1384\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1385\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1386\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    913\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    914\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 915\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    945\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    946\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 947\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    948\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    949\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2954\u001b[0m       (graph_function,\n\u001b[0;32m   2955\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2956\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   2957\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   2958\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1851\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1852\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1853\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1854\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1855\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    497\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    498\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 499\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    500\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    501\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     55\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     56\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Model checkpoint\n",
    "checkpointer = tf.keras.callbacks.ModelCheckpoint(\"Unet.h5\", verbose=1, save_best_only=True)\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(patience=1000, monitor=\"val_loss\"),\n",
    "    tf.keras.callbacks.TensorBoard(log_dir=\"logs\")\n",
    "]\n",
    "\n",
    "results = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    validation_split=0.1,\n",
    "    batch_size=16,\n",
    "    epochs=2000,\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "f4936f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "3ad0942e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = y_pred.reshape(5, 256, 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "16d958c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 256, 512)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "49b2bc96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 256, 512)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "51a424ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 256, 512)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "3d11c3d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5,)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[:, 1, 1].shape"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8bfa1c87",
   "metadata": {},
   "source": [
    "for a in range(y_pred.shape[0]):    \n",
    "    for i in range(y_pred.shape[1]):\n",
    "        for j in range(y_pred.shape[2]):\n",
    "            y_pred[a, i, j][0] = round(y_pred[a, i, j][0], 3)\n",
    "            \n",
    "for b in range(y_test.shape[0]):    \n",
    "    for c in range(y_test.shape[1]):\n",
    "        for d in range(y_test.shape[2]):\n",
    "            y_test[b, c, d] = round(y_test[b, c, d], 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "99f5188a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_test : \n",
      " -3.57637788665607\n",
      "=====================================\n",
      "y_pred : \n",
      " -2.1122952\n"
     ]
    }
   ],
   "source": [
    "print(\"y_test : \\n\", y_test[0,0,1])\n",
    "print(\"=====================================\")\n",
    "print(\"y_pred : \\n\", y_pred[0,0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "e8c2d00a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAEfCAYAAACjwKoqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAus0lEQVR4nO3deVxU9f4/8NcAMyCoKAYooGYoIKKBgFtS7re8imlopWVqeS2XRMvMpXKpa665ZN2+eU0tJdTM5X6tn+kX8eEWQpooi4kboCyKoCAwLPP7A5jrEcQZnJlz5pzX8/Hw8YYzZ3nPEebN5/M553NUOp1OByIiUjQbsRMgIiLxsRgQERGLARERsRgQERFYDIiICCwGREQEFgOyEoWFhdi4cSNGjBiB4OBgBAYGIiIiAtHR0aisrDTbcXU6HZYvX47u3bsjMDAQW7duRWZmJl5//XV06dIF3bt3R2JiInx9fbFu3Tqj9u3r64sPP/zQTJlXSU9PN+v+ST5UvM+ApO7SpUt45513kJmZiaFDhyIgIAClpaU4dOgQ4uPjMXToUCxfvhwqlcrkx46JicHbb7+NPn36YMCAAQgODsbq1avx22+/YerUqXB1dcWQIUPw22+/wdfXF35+fgbve8+ePWjTpg2CgoJMnjcA/PTTT1i4cCHOnj1rlv2TvNiJnQBRfUpLSzF58mTk5+dj586dgg/bCRMmYOHChdi2bRu6dOmCsWPHmvz4qampAICZM2fC19dXv6xjx46YMmWKfr1hw4YZve+GbGOMU6dOobS01KzHIPlgNxFJ2rZt23D58mXMmTOnzr+6Z8+eDWdnZ/z4449mOX5ZWRkAwMnJSbDs/u+J5IDdRCRpERERSEtLQ1xcHNRqdZ3rXLlyBR4eHtBoNACA+Ph4fPnll/jzzz8BAJ07d8a0adMQGhoq2O706dNYu3Ytzpw5AwAICgpCZGQkunTpAgDo168fMjMz9et7enoKvgeAqVOnYvjw4ejfvz+mTp2KadOm6V/bs2cPtmzZgrS0NDRt2hR9+vRBZGQkXFxcAFSNGQwfPhyff/65fpuYmBh88803SE5OhkajQY8ePTBz5ky0a9dOv46vry/ee+89qNVqbN26FVlZWWjXrh0mT56MF154AQDw+uuvIy4uTr9NzXEKCgqwZMkSnDx5Ejdv3kTLli3xwgsvYOrUqbC3tzfgf4Tkit1EJFk6nQ7Jycno2rXrQwsBADz55JP6rw8dOoSpU6eiTZs2eOeddwAAO3bswLhx47B27Vr0798fAHDs2DFMmjQJfn5+mD59OrRaLXbt2oUxY8bgu+++Q0hICObOnYvdu3fjt99+w5w5c+Dm5oaysjIsWbIEzZs3x9tvv63vOnrQt99+ixUrViA4OBgzZ87ErVu3sHnzZiQnJyMqKgp2drV/9Xbt2oW5c+eiZ8+emDVrFgoKChAVFYVRo0Zh+/btgoIQFRWFyspKjBkzBg4ODti8eTNmzJgBb29v+Pj44O2330ZlZSXi4+OxbNkytGnTBgAQGRmJpKQkjB07Fm5ubjh9+jT+53/+B/n5+Vi8eLHR/0ckIzoiibp165bOx8dHN2PGDIPWLysr0z377LO65557Tnf37l398oKCAl1YWJguLCxMp9VqdRUVFbr+/fvrXnnlFV15ebl+vaKiIt3AgQN1w4YN0y9bu3atzsfHR5eenq5f1rdvX91rr72m/z49PV3n4+OjW7t2rU6n0+ny8/N1nTt31r355puC/W/fvl3n4+OjO3z4sE6n0+l8fHx0s2fP1ul0Ot3du3d1Xbt2rfVec3JydKGhobrJkyfrl/n4+OgCAwN1OTk5+mVnzpzR+fj46FatWqVfNnv2bJ2Pj4/++5s3b+p8fHx0GzZsEBzjww8/1L3xxhv1nFlSArYMSLJsbKqGtCoqKgxaPykpCVlZWXj//ffRuHFj/fKmTZvitddew8qVK3Hu3Dmo1Wqkp6fj1VdfRUFBgWAfffv2xaZNm5CVlYWWLVs2KO/jx4+jtLQUY8aMga2trX55eHg4/P398dRTT9Xa5tixYygsLMSAAQOQl5enX25ra4sePXogNjYW5eXl+hZFcHAwXF1d9et17NgRAJCbm/vQvJo0aQJHR0ds27YNXl5eCAsLg6OjI5YsWdKg90nywmJAkuXs7Ay1Wi34cKxPRkYGAAi6U2rUfABfv35dfwnqsmXLsGzZsjr3dePGjQYXg5pxhbZt2wqW29vbo1OnTnVuc+3aNQDAjBkzHrrfvLw8uLm5AYB+3KFGzXhJffdcaDQaLFq0CB999BHeffddaDQadOvWDYMGDcKLL77IMQOFYzEgyVKpVAgKCsK5c+cEfxU/6IsvvkB6erp+PKAuuurrJNRqNbRaLQBg+vTpCAwMrHP9uv56N1TNB3JNy8aYbRYvXgwvL68613F2dtZ/bcy+7zd06FCEhYXh4MGDiI2NxfHjx3H06FFs27YNO3bs0BcVUh5eWkqSNnDgQNy7dw/79++v8/WSkhLs3LkTx48fh7u7O4Cqm9QedPnyZQBAy5Yt4enpCQBwdHREr169BP8aN26MiooKODg4NDjnVq1aAQCuXr0qWK7VajF9+nQcPHiw1jY1Obm4uNTKydbWFiqV6rE/qIuKihAfHw+VSoWIiAisW7cOJ06cwNixY5GSkoKjR48+1v7JurEYkKS9/PLL8PT0xNKlS3HhwgXBaxUVFViwYAFu3ryJiRMn4umnn4arqyuioqJQWFioX6+wsBDbtm2Dq6srAgICEBAQAFdXV3z//fcoKioSrBcZGYk5c+YI+vqN1atXL6jVamzfvl3fIgGAX3/9Fb/++utDt7G3t8eGDRv09zYAQHZ2NiZPnowVK1YYfYd1TeuhptXx119/YcyYMdi5c6d+HY1GA39/fwB4rPdM1o/dRCRp9vb2+PLLLzFhwgRERERg6NCh6Ny5M/Lz8/Hrr78iOTkZzz//PMaPHw8bGxt89NFHiIyMxEsvvYSIiAgAwM6dO5GTk4O1a9fCxsZGsN6IESMQEREBe3t77NixA9evX8eKFSse2iVliBYtWmDKlClYvXo1JkyYgAEDBiArKws//PADunfvjr59+9baxsXFBTNnzsSSJUvw8ssvIzw8HOXl5di2bRtKS0sxe/Zso/OoGVdYu3Ytunfvjh49eiAkJARffPEFbty4AV9fX9y4cQM//PADnnrqKfTs2bPB75msH4sBSZ6/vz/27NmDTZs24ciRI9i/fz90Oh18fX3xz3/+EyNGjND/1fy3v/0NGzduxFdffYX169fDzs4OTz/9ND777DOEhITo91mz3tdff42vvvoKNjY26NChA77++us6P6yN9c4778DV1RVbtmzB559/DldXV4waNQrTpk176F/g48aNg7u7O7777jt88cUXcHBwQKdOnbB8+XIEBwcbncOrr76KkydPYsOGDUhMTETPnj2xfv16fPnll4iJiUF0dDScnZ0xaNAgTJ8+neMFCsc7kImIiGMGRETEYkBERGAxICIisBgQERFYDIiICFZ8aWlCQoLYKRARWaW6LlW22mIA1P2G5C45OVk/QyVZBs+55fGcm8/D/pBmNxEREbEYEBERiwEREYHFgIiIwGJARERgMSAiIrAYEBERWAyIiMzqcEoOui4+gMMpOWKnUi8WAyIiM5oW9QfyisowLeoPsVOpl6SLwccff4x58+aJnQYRUYNpyyoEUaokWQx0Oh3WrFmD6OhosVMhInospZXCKFWSm5soPT0dc+fOxV9//QUPDw+x0yEiUgTJtQxOnz6N1q1bY9++ffDy8hI7HSIiRZBcyyA8PBzh4eFip0FEpCiSKwbGSE5OFjsFiyspKVHk+xYTz7nlyemch3o2wqnMYoR6NpL0e7LqYqDE+c45z7vl8ZxbnpzOedAl4FTmJQQ91UoS74nPMyAiEoXugShNLAZERGZUUlYpiFLFYkBEZEZpuYWCKFUsBkREZvTeIF94uzrhvUG+YqdSL0kPIH///fdip0AkGXlFWuyIT8fIkNZwcdKInQ4ZKPZCLtJyixB7IRdd2zYXO52HYsuALCavSItvYtOQV6QVOxWrtPn4FSz5JQWbj18ROxUyCgeQiQTe334GS35Jwfvbz4idisHScgvx8cEbkujvLdZWCCJZh/BAT/T1dUV4oKfYqdSLxYAs5v9ScwXRGrzzfTxOZRbjne/jxU4F+fe0gkimZ47W68GkbMSk5uJgUrbJ9mkOLAZE9biQUySIYjqYnC2IZHo74tOx5JcU7IhPN9k+B/i7o6+vKwb4u5tsn+bAYkBkJW4XlwkimZ6vexO4OKnh697EZPtky4BIBhzUNoIoJp1OGMn0pkTFI6+oDFOiTNctyJYBkQz8zd9NEMVkoxJGucor0mLnuXxRrjorKtUJoinsPZOJmNRc7D2TabJ9mgOLAVE9nBvZC6KYVDphlKsd8en4d0KeSfvtDdXC0U4QTaG4ehqKYk5HQWS9pDSVgHtTe0GUK1/3JnC2tzFpv72hyqv74MpN2BfXqLqLsZEEuhrrI+3siES26MUAhHo2wqIXA8ROBbeKygRRrj7acw4FpZX4aM85ix+7oLhCEE3hjV7tMOcFP7zRq53J9mkOLAZE9fB2bYxFA1rB27Wx2Kng+QB3QZQrjZ1KEMkyJD03EZHYagYzp7TRij4f0CfhAfD3cMbIkNai5mFu1/LuCaIlNbG3wd3SSjSxN93fyZuPX8GaQ3/hnrYCMwb6mGy/psaWAVE9xBzMVKqyCmG0pJLSSkE0DeuYm4gtA6J6jAxpjZycHEn8NV5zdywATHrOW+Rs5KnsgWgKb/RqB0eNnSR+hurDYkBUDxcnDSICmoneRQRU3bx08tItyd+8ZM3UtiqUVeigtjXdeIWLk8Yqije7iYishLVMa2DNnDQ2gqgkbBmQxTS2BwpLqyIZr6abQerdDdastLxSEE3BWh5KpLzyR6IpLVMJIhmnprtByh8o1q60TCeIpmCOmVDNgS0Dshg7lQ5l1dFaSOnSUqVwsAVKKqqipVU+EE3BWlp0bBmQxbRzbSKI1oCXllpeeKCXIFo7a2nRsRiQxfT2cRVEazAypDXeDHaRxF91SnmGdDNHjSBakr+7kyAqCYsBWczznVrC29UJz3dqKXYqBpPSpaXW0vf8uErKKwTRkpo42guikrAYkMUs2HseablFWLD3vNipWKWRIa0x5wU/SbRSzOlcZr4gWtLTXs6CqCQcQCaLScu9K4hEdVM9EC3n7T7t0aKxvewLbl3YMiCLadvCSRDJOJuPX8GSX1Kw+fgVsVMxq5C2zQXRkswx2GstYz2SKwYVFRVYuXIlevfujaCgILz77ru4efOm2GmRCYS0dRFEMk6xtkIQ5aqX9xNwtrdBL+8nxE7FJKxlrEdyxWDdunX4+eefsXTpUvzwww/IysrCtGnTxE6LTKCkehrKEjGmo5QF65j98nGJ+XAbc7CWsR5JFQOtVostW7Zg5syZeOaZZ9CpUyesWrUKf/zxB/744w+x06PHFHclTxDJOPnFZYIoVxWVOkG0drzPoAFSUlJQVFSEbt266Zd5eXnB09MT8fHxImZGprBqVCC8XZ2walSg2KlYpbjLeYIoV9cLSgSRLENSxSArKwsA4O4unKLXzc1N/xpZL2dHNdq4OMLZUS12KlaJxdQ6WcsAsqQuLS0uLoaNjQ3UauGHhUajQWlpaa31k5OTLZWaZJSUlFjt+/744A2cyixGYWEcFg1oJXY6BpPKOdeWVKBPG3to8zKRfE++fxw10ahwV6tDE43K4ue9oKQCv128i4Htm8DZRJMj7TyXj38n5CEnJwcRAc1Msk9zkFQxcHBwQGVlJcrLy2Fn99/UtFotGjVqVGv9jh07WjI9SUhOTrba9/35E63x6X+SMH+IvyQeMG8oqZzzb2LT8O+Eq3Bzc8OkIOk/LKWhWrtkIymrCK1dHC1+3s1xjkc/UYhLhUkY3UcaP/cJCQl1LpdUMWjVquqvxdzcXP3XAJCTk1Or64isj7drY3w3vtujV6Q6KeVJZw4atSBakjlmGN17JhMxqbno4pWJGQN9TbZfU5PUmIGfnx+cnJwQFxenX5aRkYHMzEyEhoaKmBkpVc0U1lLo71XKk87kdtOZmHdUG0NSLQONRoPRo0dj2bJlaN68OVq0aIGFCxeiW7duCAwMFDs9UqCaKazd3NJFf46tUloGL3drg9OXsvBytzZip2ISb/R6Eo4aW95nYKzIyEgMHToUs2bNwtixY+Hh4YE1a9aInRZZsbTcQoz/Lg5puYVGbyulKayjT6UjJjUX0aekfSfr49p75jpOZRZj75nrYqdiEtZyn4GkWgYAYGdnhw8//BAffvih2KmQTMzdlYjfL+fhnjYR0ZN6GrWtlKaw/jP9tiDKVbG2XBDJMiTXMiAytdtFpYJordq6OAmibKlUwkgWwWJAspd1p1QQrdXF6qm/L8p8CvBGahtBJMvg2SbZe76TuyBaK7WtrSDKVXigJ0I9GyE80FPsVBSFxYBkb1Kf9ujr64pJfdqLncpj+eeIzujr64p/jugsdipmdTApG6cyi2V/Ca3UsBiQ7O09cx0xqblWf3VKzU17UriL1ZwG+Lsj1LOR7C+hlRoWA5I9Xp1iXaJPpeNUZrHsL6GVGhYDkr1GGjtBJGk7dfmWIJJl8LeDZM9a7gClKho7W0Eky2DLgGTv9j0tTl66hdv3xJ9fiB5t9vN+8Gpqh9nP+1n82Nby7AFzYDEg2ft49znEpObi493GP1NXShPVKUXshRxk3ClH7IUcix/bWh5ebw7sJiLZ83ZrjGNpt+DtZvxVOFKaqE45xJvl0xxTWFsLFgOSPYfqvmeHBvRBjwxpjZycHEV+OIjlOR9X/HTqMp7zcbX4sWsmlVMidhOR7F3LKxJEY0hpojqlWHkgFRl3yrHyQKrYqSgKiwHJ3qGUHEEkafNs3kgQLYkDyEQy1sTeThBJ2jJvFwuiJXEAmUjGWjo7IO9eGVo6O4idChngvUG+uLo1Du8NsvzzgpU8gMyWAcmeQ/VUyA6cEtkqxF7Irb60NNfix7aWp5KZA387SPZCnmwhiCRtcnkYkbVhMSDZezm0Nfr6uuLlUOU1/a3RmYwCQbQkDiATyVh0XPWD5OOMHxRcezAVgzdfwtqDvMzRUrILSgTRkpQ8gMxiQLKXdKNAEI2x6uBF6KojWUZjBztBtKSRIa0x5wU/DiATydHMgb7wdnXCzIGWvzqFjJd9p0QQLckaBpDN1ZXFYkCy9+v5LKTlFuHX81lip0IGeKKxvSCSkLm6snifAcnemWu3BZGkLfduiSBaUl6RFjvi0zEypLVkWwfmuheCLQOSPb+WTQXRGE3sbQSRzE9tqxJES/pXbBqW/JKCf8WmWfzYhjJXV5Ykf8K1Wi3Cw8OxZ88esVMhGWjupBZEY1TqhJHMr6SsUhAt6XxmgSAqieSKQWFhIaZMmYLUVF7KR6YRHuiJvr6uCA/0NHrbmiksOJWF5ZSU6wTRkiaGPQUXJzUmhj1l8WOLTVLF4Pjx43jxxRdx6xYfhE2mczApGzGpuTiYlG30toUlFYJI8vZ17EXkFZXh61jpXkqsiKuJYmNj8dJLL+HHH38UOxWSkQH+7ujr64oB/u5Gb9uiumupRQO6mKhhmjnYCqIl3S0pF0QpEuVqon79+kGlMmwQ59ChQ4+dzJw5cx57H0QP2nsmEzGpuejilYkZRt5rYGdrI4hkftqKSkG0JGsoBgP83XHy0q0G/XFTn3qLwciRI/Vf3759G1u3bsXAgQMRGBgItVqNxMRE/PLLLxg/fvwjD5SRkYH+/fvX+ZpGo0FiYqKRqQPJyclGb2PtSkpKFPm+H0fS1ZzqmIXkZOM+YO6VlOgjz7tllFePFZSX6yx+zt/q2hSrjpbira5NJfv//cOZPMSk5sPD4U+8Fuhisv3WWwzeeecd/df/+Mc/MGvWLIwbN06wTmBgIPbt2/fIA7m7u2P//v11vmZj07C/ujp27Nig7axZcnKyIt/340jZe6Mq3qow+tw5HrwJQAtHBweed0tRXQJ0AFSW/x3/+VIyCkqzkal1kuz/t9OlZAD5cGrq0qAcExIS6lxu8KdwXFwc+vbtW2t5jx49cO7cuUdur1ar4e3tXee/du3aGZoGkdE6eTQRRGOUV3dVlIvQZaFUK0cFwsFWhZWjAi1+7KN/5QiiFOXf0wqiqRhcDDw8PPDbb7/VWv7zzz/zw5wk7Uz6HUE0Rkb+PUEk8xsa6ImfX2uHoQ24FPhxpVc/ajNdhEduGuroxZuCaCoGT0cxdepUvPfeezh27Bg6deoEnU6H06dP4+zZs/jXv/5l0qSITElbXi6IxrhTUimIJG/tnnDC2cw7aPeEk9ipPFRje1tBNBWDWwaDBw/Gli1b0KxZMxw+fBhHjhyBp6cnfvzxR/Tu3dukSRGZUmn1gGSpCDcxkXVZEB4Ab1cnLAgPEDuVh7qWVySIpmLURHWhoaEIDQ01aQIPwzuQyVS8XR1xNvMuvF0djd5WBf1YJinAr+duVM1we+4GurZtLnY6daq56tXUV78adRnPqVOn8NZbb6Ffv37IzMzEunXrsHv3btNmRGRiX7zSFX19XfHFK12N3raDe2NBJHmLv3pbEJXE4GIQGxuLt956C61atcLNmzdRWVkJlUqFefPm4aeffjJnjkSPxdu1Mb4b3w3ersZ/oAe2biaIJG/lFTpBVBKDi8GXX36JDz74AIsXL4atbdXAxdSpUzF79mxs3LjRbAkSieliTqEgkrwVlZYJohTZPBBNvd9HunjxIp599tlay/v27Yv0dOU9PJqI5Oda9SWl1yR8aemgTu6CaCoGDyA3b94c6enpaN1a+HSdc+fO4YknnjBpUkRSEeDpjD+u5SPA01nsVMgC1CoVyqCD2sA52cTwzxFdENQmXbwnnY0aNQoLFy5EbGwsAODatWvYuXMnFi9ejOHDh5s0KSLJ0D0QSdZ6eLcQRCky15PODG4ZTJo0CXfv3sW0adOg1Wrx5ptvws7ODuPHj8eUKVNMmhSRVFy6WSSIJG9JN+4IohSZ6znNBheD2NhYTJkyBVOmTEFaWhrUajWefPJJODjwCVAkXy+HeCH+8i28HOIldipkAdryCkGUoprnGQDApOe8TbZfg7uJZs+ejfT0dDg6OqJz587w8/NjISDZW3HgAkoqdFhx4ILYqZAF3CurEEQpGhnSGnNe8BNvzMDT0xPXrl0z6cGJpC6wtbMgkryVlekEUYpEHzMICAhAZGQkOnfujNatW9dqFSxevNikiRFJweWbhYJI8lbxQFQSg4vB5cuX0bVr1e38WVlZgtcMfTQmkbXJulMqiERyZXAx+P77782Zh8WYaySe5Km4uu+4WMJ9yESmYNSspYWFhdi/fz8uXLgAlUqFTp064fnnn7eqgWRzjcSTPN0tqRBEIrkyuBhcuHAB48ePR3FxMby9vVFRUYGdO3di3bp12LJlCzw9Lf9UooaoGYE39Ug8yROnsCalMPhqosWLFyMwMBBHjhzBjh07sGvXLhw+fBjt27e3qsFjc43Ekzy1a9FIEEneNLbCqCQGF4PExETMnDkTjRv/dxpgZ2dnvPfee/j999/NkhyR2ELatRBEkjdnB40gKonBxcDDwwOXL1+utTw3Nxdubm4mTYpIKq7nlwgiydsLnVsKopIYPGYwefJkLFiwANnZ2QgNDYWdnR3Onz+PVatWYdSoUfjjjz/069Zcgkpk7WYO9MGVnHzMHOgjdipkAZEDfeHZ3FGRY4oGF4P3338fQN03l61Zs0b/tUqlQnJysglSIxJf7IUcZNwpR+yFHMk+E5dMp2ZMUYkMLgaHDh0yaL3KysoGJ0MkPaoHIpE8GVwMDL10tGvXrtizZ0+th+AQWaOg1s3gbG+DID4DmWTO1I/RhE4n3QmeiIy1+H+TUFBaicX/myR2KkRmZfJiQCQnr4a2hk11JJIzSRWD8+fPY9y4cQgJCUHv3r0xb9485Ofni50WKdhXsWmorI5EciaZYpCdnY3x48fDy8sL0dHRWLNmDc6ePYvIyEiTHievSItvYtOQV6Q16X5JniY/5w2b6kgkZ5IpBr/88gs0Gg0WLlwIb29vBAcH45NPPsGJEydw/fp1kx2nZqK6HfHpJtsnydfmE1dRWR2J5MyoWUvNqV+/fggICICt7X8nBal5TsKdO3fg4eFhkuNwojoyRiO1jSASyZXBP+GpqanmzANt2rRBSEiIYNm3334Ld3d3dOjQwWTH4UR1ZIyC4nJBJJIrg1sGw4YNQ8eOHTFixAj8/e9/h4uLS53rde/evc7nG2RkZKB///51bqPRaJCYmChYtmLFChw+fBjr168XtBaILKlFY3tk3y1Fi8b2YqdCZFYqnYE3Bly7dg179+7Fvn37kJmZieeeew7Dhw9Hnz59YGf36JpSVlaGa9eu1fmajY0N2rVrBwCoqKjAokWLEB0djQULFuCVV16pc5uEhAQ4OjoakrqslJSUWNXDhKzdzP0ZSM7VoqOrBqsGe4mdjmLw59x87t27h+Dg4FrLDS4G9zt9+jT27duHQ4cOQavVYsiQIXjppZfg5+f3WEmWlpZi+vTpOHr0KJYsWYKhQ4c+dN2EhIQ635DcJScno2PHjmKnoRjTo/7Anj9vYNjTrbDmVU7AaCn8OTefh312NmhULCgoCIMGDUL//v1RXFyMvXv3YuTIkRg9enSd01wborKyEtOnT8fJkyfx9ddf11sIHgcvLSVj/HEtXxCJ5MqoYpCSkoKlS5fi2WefxcSJE5GdnY0VK1bg2LFjOHLkCJo1a4Z33323QYlERUUhJiYG8+bNg5+fH3Jzc/X/ysrKGrTPuvDS0iosiobp6+sqiERyZfAA8pAhQ5CWlgZfX19MmDAB4eHhgkHk5s2bY9iwYZg/f36DEtm3bx8A1Ln91q1ba11p1FC8tLRKTVEEoNgpew0R+qQLtp9KR+iTdV8wQSQXBheDnj17Yvny5fX243Xv3h379+9vUCI//vhjg7YzlpLnK78fi6JhPtl3HiUVOnyy7zyGBho2cy+RNTK4m2jevHmPHNBp1qwZXF3ZnLYGvN/CMKtGBsLZ3garRgaKnQqRWfG2SqJ63C0pQ2m5DndLTDduRSRFLAZE9Xh/51mUVOjw/s6zYqdCZFYsBkT1cNTYCCKRXCnuJ5yXVJIxKit1gkgkV4orBrzPgIxRXFYpiERyJZkprC2Fl1SSMcLaP4FDqbkIa/+E2KkQmZXiigHvMyBjlJRXCiKRXCmum4jIGIteDECoZyMsejFA7FSIzEpxxYADyGQMb9fGWDSgFbxdG4udCpFZKa4YcACZiKg2xY0ZcACZiKg2xRUDDiATEdWmuG4ijhlU4XkgovsprhhwzKAKzwMR3U9x3UQD/N1x8tItDPB3FzsVUfE8ENH9FNcyOJiUjZjUXBxMyhY7FVHxPBDR/RTXMuDVRFV4HojofoorBlSFV1UR0f0U1020+fgVLPklBZuPXxE7FSIiyVBcMQB0D0QiIlJcMXijVzvMecEPb/RqJ3YqokrLLcT47+KQllsodipEJAGKKwa372lx8tIt3L6n7JutPv1PEmJSc/Hpf5LEToWIJEBxA8g1H4JAEr4b303sdEQzf4g/gKTqSERKp7hiwA/BKs0dNejxVAs0d9SInQoRSYCkuokSEhLw6quvIjAwEGFhYVi+fDm0WmV355jL5uOXq6+quix2KkQkAZIpBpmZmXjrrbfQpUsX7N27F0uXLsWePXuwcuVKkx6HfeU1VA9EIlIyyXQTZWZmYtCgQZgzZw4AoE2bNhg8eDBOnDhh0uO80fNJ/JmRjzd6PmnS/Vqb8EAPnM3IR3igh9ipEJEESKZl0K1bNyxdulT//fnz53Hw4EE888wzJj3OhqOXkVdUhg1Hld09svdMJmJSc7H3TKbYqRCRBEimZXC/kJAQ3L17F/7+/pgyZYpJ9/3UE444erEqKlmxtlIQiUjZLFYMMjIy0L9//zpf02g0SExMBABUVlZi48aNKCgowGeffYaJEydi27ZtUKlq920nJycbnUdF8R19bMj2YispKTFJ3kV38vTRGs+DJZnqnJPheM4tz2LFwN3dHfv376/zNRsbG8HXXbp0AQAsXboUo0aNwunTp9G1a9da23Xs2NHoPF5yvI2T1//ES7380bFtc6O3F1tycnKD3veDJjxRiOslSZgwwB/ero1NkJl8meqck+F4zs0nISGhzuUWKwZqtRre3g+fJfPixYvIzs4WjBH4+PgAALKzTTfn/rr/+wtpuUVY939/Kfqms5oxgy5emZgx0FfsdIhIZJIZQI6JicHMmTNRWlqqX3b27FkAQPv27U12nGn9OsDb1QnT+nUw2T6tEccMiOh+kikGL774IgBg7ty5SEtLw7FjxzBv3jwMHjwYHTqY7oP713NZSMstwq/nsky2T2uUfadYEIlI2SRzNZGrqys2b96Mzz//HBEREXB0dER4eDhmzJhh0uMk3SgQRKU6mJItiESkbJIpBgDg5+eHTZs2mfUYMwf64kbBn5ip8H5ye1tbFKES9ra2YqdCRBIgmW4iSzl1JQ9puUU4dSVP7FREZWerEkQiUjZJtQwsgQ+Cr9LE3g45d7VoYq+4HwEiqoPiPgn4IPgqOXdLBZGIlE1x3URUpXXzRoJIRMqmuGLAZ/9WcXGyF0QiUjbFFYNP9pxDTGouPtlzTuxURHXycp4gEpGyKa4YPFU9D89TCp+PJ7hNM0EkImVTXDGgKtcLSgSRiJRNccUgMSNfEJWqr6+bIBKRsinu0tIKnTAq1RvPPIn02/fwxjNPip0KEUmA4loGJdpyQVSq6FPpiEnNRfSpdLFTISIJUFwxSL9dLIhKdT6zQBCJSNkUVwy0ZZWCqFSvhLZGI7UNXglV9rQcRFRFccXAQW0jiEq17P+lorisEsv+X6rYqRCRBCjuE7GoukVQpPCWQXNHtSASkbIprhhQlcDWzQWRiJRNccXAwU4YlcpBYyuIRKRsiisGlTqVICoVL7Elovsprhh0b+ciiEqVml0oiESkbIorBmm5RYKoVE97NRNEIlI2xfWc1zzyV+mP/n27jzdaNNYo/vGfRFRFccXgxp1SQVQqPv6TiO6nuG6id/t5Q1UdiYioiuKKwcHkHOiqIxERVVFcMUi+cUcQiYhIwsVgw4YN8PX1Nfl+a2ahUPhsFEREApIsBqmpqVizZo1Z9s07kImIapNcMdBqtZg1axYCAwPNsv+ycmEkIiIJFoPVq1fD3d0dERERZtl/5QORiIgkVgzi4+Oxa9cufPrpp2Y7hp1KGImIyII3nWVkZKB///51vqbRaHDixAl88MEHmD9/Ptzd3Q3aZ3JystF5lOv+GxuyvdhKSkqsMm9rxnNueTznlmexYuDu7o79+/fX+ZqNjQ0+++wzBAQEYMiQIQbvs2PHjkbnocOl6tiw7cWWnJxslXlbM55zy+M5N5+EhIQ6l1usGKjVanh7P/yu3127dsHe3h5BQUEAgPLyqhHeoKAgLFy4EOHh4RbJk4hIiSRzgeWBAwcE3x86dAhLly7F7t270aJFC5GyIiJSBskUg7Zt2wq+rykADy4nIiLTk9TVREREJA7JFoNhw4YhNTVV7DSIiBRBssWAiIgsR3HFYP5gP9ioqiIREVWRzACypbz1rDfeepYPtiEiup/iWgZERFQbiwEREbEYEBERiwEREYHFgIiIwGJARERgMSAiIgAqnU6nEzuJhnjYnNxERFS/4ODgWsusthgQEZHpsJuIiIhYDIiIiMXA6m3YsAG+vr5ipyF758+fx7hx4xASEoLevXtj3rx5yM/PFzst2amoqMDKlSvRu3dvBAUF4d1338XNmzfFTksRWAysWGpqKtasWSN2GrKXnZ2N8ePHw8vLC9HR0VizZg3Onj2LyMhIsVOTnXXr1uHnn3/G0qVL8cMPPyArKwvTpk0TOy1F4ACyldJqtYiIiICzszPi4uL4ICAz2rRpEzZs2IDY2FjY2toCAOLj4zFmzBjExMTAw8ND5AzlQavVokePHpg/fz5GjBgBAMjIyED//v0RFRWFrl27ipyhvLFlYKVWr14Nd3d3REREiJ2K7PXr1w+rV6/WFwIAUKlUAIA7d+6IlZbspKSkoKioCN26ddMv8/LygqenJ+Lj40XMTBkU9zwDOYiPj8euXbuwZ88enDx5Uux0ZK9NmzZo06aNYNm3334Ld3d3dOjQQaSs5CcrKwsA4O7uLlju5uamf43Mh8VAYmqaxXXRaDQ4ceIEPvjgA8yfP7/WLw01zKPOeWJiomDZihUrcPjwYaxfv17QWqDHU1xcDBsbG6jVasFyjUaD0tJSkbJSDhYDiXF3d8f+/fvrfM3GxgafffYZAgICMGTIEAtnJl+POuc1KioqsGjRIkRHR2PBggUPLSDUMA4ODqisrER5eTns7P770aTVatGoUSMRM1MGFgOJUavV8PZ++GM5d+3aBXt7ewQFBQEAysvLAQBBQUFYuHAhwsPDLZKnnDzqnANAaWkppk+fjqNHj2L58uUYOnSohbJTjlatWgEAcnNz9V8DQE5ODlvBFsBiYGUOHDgg+P7QoUNYunQpdu/ejRYtWoiUlbxVVlZi+vTpOHnyJL7++muEhYWJnZIs+fn5wcnJCXFxcRg2bBiAqi68zMxMhIaGipyd/LEYWJm2bdsKvq8pAA8uJ9OJiopCTEwMPv30U/j5+SE3N1f/WrNmzWr1cVPDaDQajB49GsuWLUPz5s3RokULLFy4EN26dUNgYKDY6ckeiwHRI+zbtw8AMH/+/Fqvbd26FSEhIZZOSbYiIyNRXl6OWbNmoby8HGFhYfj444/FTksReNMZERHxpjMiImIxICIisBgQERFYDIiICCwGREQEFgMiIgKLAZFJnD59GgkJCZLdH9GjsBgQmcBrr72Gq1evSnZ/RI/CYkBkAqa+d5P3gpKlsRgQAfj000/x97//XbDs2rVr8PX1RUpKSr3b9uvXDxUVFZgzZw5ef/11AEBBQQHmzJmD7t27o1u3bpg4cSIuXbqk3+bSpUuYMGECunbtiuDgYEyePBkZGRkP3R+RubEYEAEYMWIELl68iKSkJP2yvXv3ws/PD35+fvVuu3PnTtja2mLu3LlYt24ddDod/vGPfyAnJwcbNmzAtm3b4OHhgdGjR+P27dsAgPfffx8eHh74+eefsXXrVty+fRtz586tc39ElsCJ6ogA+Pv7w8/PD3v37oW/vz+AqmIwevToR27r4uICAGjSpAmaNWuG48ePIzExEXFxcWjcuDEAYOHChTh58iS2b9+OSZMm4erVq3jmmWfg6ekJOzs7LF++HDdv3qxzf0SWwJYBUbXhw4fjP//5DyorK3H69GlkZmY26CE2SUlJqKioQFhYGIKCgvT/0tPTkZaWBgCYPn06Nm7ciO7du2PKlCk4ceLEI1sgRObElgFRtfDwcKxYsQK///47Dhw4gGeffbZBDwxSq9Vo1qwZtm/fXus1R0dHAMDYsWMxePBgxMTE4Pjx41iyZAm2bduG6OhoaDSax34vRMZiy4ComouLC8LCwnDgwAEcOnQIw4cPN3hblUql/7pDhw7Iz88HUPXQobZt28LLywurV6/GqVOncPv2bSxevBjl5eUYOXIkvvjiC2zatAlJSUn6wer790dkCSwGRPcZMWIEdu3ahdLSUvTp08fg7ZycnHDx4kXcunULPXv2RGBgICIjIxEfH4/Lly9j/vz5iImJgY+PD5ydnXHkyBF8/PHHSElJwdWrV7Fr1y40bdoU7dq1q7U/IktgMSC6T58+feDg4IAhQ4YY1V0zceJEREVF4c0334RKpcL69evRvn17TJ48GcOHD8eVK1ewYcMGtG/fHjY2Nvjmm28AAK+//jrCw8Nx8eJF/Pvf/0aTJk1q7Y/IEvikM6L73L59G2FhYYiOjkanTp3ETofIYjiATISqIhAXF4fdu3cjICCAhYAUh8WACEBZWRnmzZsHNzc3wY1eb7/9Nn7//fd6t42Pj4etra25UyQyK3YTEdUjOzsbJSUl9a7Ttm1bC2VDZD4sBkRExKuJiIiIxYCIiMBiQEREYDEgIiKwGBAREYD/D513UDe7qoL6AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "axe = plt.axes()\n",
    "plt.rcParams.update({'font.size':15})\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "plt.scatter(y_test[:,:,1], y_pred[:,:,1], s=1)\n",
    "plt.title('Coefficients')\n",
    "axe.set(xlabel=\"y_test\", ylabel=\"y_pred\")\n",
    "plt.show()\n",
    "# plt.scatter(X_test, y_test, label=\"Donnes d'valuation\", color=\"b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee8a71d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085a6517",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c81bcb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = random.randint(0, len(X_train))\n",
    "preds_train = model.predict(X_train[:int(X_train.shape[0]*0.9)], verbose=1)\n",
    "preds_val = model.predict(X_train[int(X_train.shape[0]*0.9):], verbose=1)\n",
    "preds_test = model.predict(X_test, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76759582",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_train_t = (preds_train > 0.5).astype(np.uint8)\n",
    "preds_val_t = (preds_val > 0.5).astype(np.uint8)\n",
    "preds_test_t = (preds_test > 0.5).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa37eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "ix = random.randint(0, len(preds_train_t))\n",
    "imshow(X_train[ix])\n",
    "plt.show()\n",
    "imshow(np.squeeze(y_train[ix]))\n",
    "plt.show()\n",
    "imshow(np.squeeze(preds_train_t[ix]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f10c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ix = random.randint(0, len(preds_val_t))\n",
    "imshow(X_train[int(X_train.shape[0]*0.9):][ix])\n",
    "plt.show()\n",
    "imshow(np.squeeze(y_train[int(y_train.shape[0]*0.9):][ix]))\n",
    "plt.show()\n",
    "imshow(np.squeeze(preds_val_t[ix]))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ee3da764",
   "metadata": {},
   "source": [
    "TRAIN_PATH = \"stage1_train/\"\n",
    "TEST_PATH = \"stage1_test/\"\n",
    "\n",
    "# [0] is the folder name\n",
    "train_ids = next(os.walk(TRAIN_PATH))[1]\n",
    "test_ids = next(os.walk(TEST_PATH))[1]\n",
    "\n",
    "X_train = np.zeros((len(train_ids), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNEL), dtype=np.uint8)\n",
    "y_train = np.zeros((len(train_ids), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNEL), dtype=bool)\n",
    "# or np.bool or ... , 1), dtype....\n",
    "\n",
    "print(\"\\nResizing training images and masks\\n\")\n",
    "for n, id_ in tqdm(enumerate(train_ids), total=len(train_ids)):\n",
    "    path = TRAIN_PATH + id_\n",
    "    img = io.imread(path + \"/images/\" + id_ + \".png\")[:, :, :IMG_CHANNEL]\n",
    "    img = resize(img, (IMG_HEIGHT, IMG_WIDTH), mode=\"constant\", preserve_range=True)\n",
    "    X_train[n] = img\n",
    "    mask = np.zeros((IMG_HEIGHT, IMG_WIDTH, 1), dtype=bool)\n",
    "    for mask_file in next(os.walk(path + \"/masks/\"))[2]:\n",
    "        mask_ = plt.imread(path + \"/masks/\" + mask_file)\n",
    "        mask_ = np.expand_dims(resize(mask_, (IMG_HEIGHT, IMG_WIDTH), mode=\"constant\", preserve_range=True), axis=-1)\n",
    "        mask = np.maximum(mask, mask_)\n",
    "    y_train[n] = mask\n",
    "\n",
    "# test images\n",
    "X_test = np.zeros((len(test_ids), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNEL), dtype=np.uint8)\n",
    "sizes_test = []\n",
    "print(\"\\nResizing test images\\n\")\n",
    "for n, id_ in tqdm(enumerate(test_ids), total=len(test_ids)):\n",
    "    path = TEST_PATH + id_\n",
    "    img = io.imread(path + \"/images/\" + id_ + \".png\")[:, :, :IMG_CHANNEL]\n",
    "    sizes_test.append([img.shape[0], img.shape[1]])\n",
    "    img = resize(img, (IMG_HEIGHT, IMG_WIDTH), mode=\"constant\", preserve_range=True)\n",
    "    X_test[n] = img\n",
    "\n",
    "print(\"Done !\")\n",
    "\n",
    "image_x = random.randint(0, len(train_ids))\n",
    "imshow(X_train[image_x])\n",
    "plt.show()\n",
    "imshow(np.squeeze(y_train[image_x]))  # or imshow(np.squeeze(y_train[image_x]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef5a019",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30346d16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f92f921b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7fed28a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb0286f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ce005f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74eb6f53",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
