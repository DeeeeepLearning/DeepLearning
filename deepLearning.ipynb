{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "d3156ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error, r2_score, mean_squared_error, accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, Input\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01a934eb",
   "metadata": {},
   "source": [
    "Pour être sûr d'utiliser Tensorflow 2.0 :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "aafd28a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert hasattr(tf, \"function\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa92689",
   "metadata": {},
   "source": [
    "Cette fonction ouvre un fichier C_maps.txt en lecture et récupère les 22 coefficients et les retourne sous forme d'une matrice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "38624196",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(file_path):\n",
    "    \n",
    "    file = open(file_path, \"r\")\n",
    "\n",
    "    allText = file.read()\n",
    "\n",
    "    words = list(map(str, allText.split()))\n",
    "\n",
    "    matrice_height = int(len(words) / 30)\n",
    "    matrice = np.ones((matrice_height, 24))\n",
    "\n",
    "    emplacement = 20\n",
    "    iter1 = 0\n",
    "    for i in range(emplacement, int(len(words) / 30) + emplacement):\n",
    "        iter2 = 0\n",
    "        for j in range(emplacement + 6, emplacement + 30):\n",
    "            matrice[(iter1, iter2)] = words[j]\n",
    "            iter2 += 1\n",
    "        iter1 += 1\n",
    "        emplacement += 30\n",
    "    X_2 = np.delete(matrice, 1, 1)\n",
    "    X_final = np.delete(X_2, 10, 1)\n",
    "    \n",
    "    file.close()\n",
    "    \n",
    "    return X_final"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b8c3f7c",
   "metadata": {},
   "source": [
    "Cette fonction ouvre un fichier ctf en lecture et récupère les 3 coefficients d'Euler pour les retourner sous forme de matrice (x, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "6b71016c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_ctf(file_path):\n",
    "    \n",
    "    file2 = open(file_path, \"r\")\n",
    "    \n",
    "    allText2 = file2.read()\n",
    "    words2 = list(map(str, allText2.split()))\n",
    "    \n",
    "    nb_debut_donnees = 88\n",
    "    nb_mots = len(words2) - nb_debut_donnees\n",
    "    nb_mots_par_ligne = 11\n",
    "    \n",
    "    nb_ligne_matrice = int(nb_mots / nb_mots_par_ligne)\n",
    "    print(\"nb_ligne_matrice = \" + str(nb_ligne_matrice))\n",
    "    nb_colonne_matrice = 3\n",
    "    matrice = np.empty((nb_ligne_matrice, nb_colonne_matrice))\n",
    "    emplacement = 0\n",
    "    \n",
    "    print(\"Extraction des données à partir du fichier ....\")\n",
    "    for i in range(nb_debut_donnees, nb_mots + nb_debut_donnees, nb_mots_par_ligne):\n",
    "        matrice[(emplacement, 0)] = words2[i + 5]\n",
    "        matrice[(emplacement, 1)] = words2[i + 6]\n",
    "        matrice[(emplacement, 2)] = words2[i + 7]\n",
    "        emplacement += 1\n",
    "    print(\"ok !\")    \n",
    "    file2.close()\n",
    "    \n",
    "    return matrice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63455c9e",
   "metadata": {},
   "source": [
    "Cette fonction fait faire des prédiction au modèle et renvoie le score, mae, rmse, r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "3b06d8ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(model):\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(\"R^2 : \", r2_score(y_test, y_pred))\n",
    "    print(\"MAE :\", mean_absolute_error(y_test,y_pred))\n",
    "    print(\"RMSE:\",np.sqrt(mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b36e27d2",
   "metadata": {},
   "source": [
    "cette fonction renvoie le nombre d'erreur de 1 degré ou plus de la prédiction par rapport aux valeurs réelles\n",
    "et renvoie les valeurs X d'entrée et y de sortie pour lesquels le modèle prédit mal, sous forme de matrices erreur_x, erreur_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "db3ac6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pourcentage_erreur(y_pred, y_test, x_test):\n",
    "   \n",
    "    err = 0\n",
    "    marge_derreur = 1 # 1 degre\n",
    "    erreur_y = np.empty((1, 3), dtype=float)\n",
    "    erreur_x = np.empty((1, 22), dtype=float)\n",
    "   \n",
    "    for i in range(y_pred.shape[0]):\n",
    "       \n",
    "        for j in range(y_pred.shape[1]):\n",
    "           \n",
    "            error = abs(y_pred[i][j] - y_test[i][j])\n",
    "            if error >= marge_derreur:\n",
    "               \n",
    "                # print(error)\n",
    "                err += 1\n",
    "               \n",
    "                erreur_y = np.append(erreur_y, [y_test[i]], axis=0)\n",
    "                erreur_x = np.append(erreur_x, [x_test[i]], axis=0)\n",
    "               \n",
    "                break\n",
    "               \n",
    "    erreur_y = np.delete(erreur_y, 0, axis=0)\n",
    "    erreur_x = np.delete(erreur_x, 0, axis=0)\n",
    "    \n",
    "    for y in erreur_y:\n",
    "        for i in range(len(y)):\n",
    "            y[i] = round(y[i], 3)\n",
    "    for x in erreur_x:\n",
    "        for j in range(len(x)):\n",
    "            x[j] = round(x[j], 3)\n",
    "    \n",
    "    message = \"le pourcentage d'erreur est de \"+str((err / y_pred.shape[0]) * 100)+\", \"+str(err)+\" / \"+str(y_pred.shape[0])\n",
    "    return message, erreur_y, erreur_x, err"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "9823429d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_error(y_pred, y_test, x_test):\n",
    "   \n",
    "    err = 0\n",
    "    marge_derreur = 1 # 1 degre\n",
    "   \n",
    "    for i in range(y_pred.shape[0]):\n",
    "       \n",
    "        for j in range(y_pred.shape[1]):\n",
    "           \n",
    "            error = abs(y_pred[i][j] - y_test[i][j])\n",
    "            \n",
    "            if error >= marge_derreur:\n",
    "                \n",
    "                err += 1\n",
    "                break\n",
    "    \n",
    "    message = \"le pourcentage d'erreur est de \"+str((err / y_pred.shape[0]) * 100)+\", \"+str(err)+\" / \"+str(y_pred.shape[0])\n",
    "    return message"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb28339f",
   "metadata": {},
   "source": [
    "X matrice d'entrée de dimension (250000, 22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "8d2b6949",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_in_path = \"datas/C_maps_3.txt\"\n",
    "X = get_data(file_in_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b778f849",
   "metadata": {},
   "source": [
    "Y matrice de dimension (250000, 3) correspondant aux valeurs de sortie q'on attend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "a2878d34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_ligne_matrice = 250000\n",
      "Extraction des données à partir du fichier ....\n",
      "ok !\n"
     ]
    }
   ],
   "source": [
    "file_out_path = \"datas/exercise3.ctf\"\n",
    "y = read_ctf(file_out_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc26ce9a",
   "metadata": {},
   "source": [
    "Nous divisons notre jeu de données en jeu d'entraînement, X_train, y_train et en jeu de test, X_test, y_test\n",
    "le pourcentage de données de test est précisé avec le paramètre test_size, ici de 20%. random_state permet d'avoir le même mélange de données pour pouvoir comparer des modèles entre eux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "1bda942c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "cb09f207",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[255.345,  55.944,  46.056],\n",
       "       [ 18.18 ,  55.417,  44.979],\n",
       "       [113.271,  56.696,  48.033],\n",
       "       ...,\n",
       "       [201.353,  56.417,  44.685],\n",
       "       [ 46.988,  57.272,  41.112],\n",
       "       [155.91 ,  56.922,  46.054]])"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "7815ad87",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in X_train:\n",
    "    for i in range(X_train.shape[1]):\n",
    "        x[i] = round(x[i], 3)\n",
    "\n",
    "for y in X_test:\n",
    "    for j in range(X_test.shape[1]):\n",
    "        y[j] = round(y[j], 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "7dfe4317",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avant normalisation x_train : Minimum = -8.145, Maximum = 5.469\n",
      "Avant normalisation x_test : Minimum = -8.145, Maximum = 5.468\n",
      "Après normalisation x_train : Minimum = -1.489303346132748, Maximum = 1.0\n",
      "Après normalisation x_test : Minimum = -1.489303346132748, Maximum = 0.9998171512159444\n"
     ]
    }
   ],
   "source": [
    "print('Avant normalisation x_train : Minimum = '+str(X_train.min())+', Maximum = '+str(X_train.max()))\n",
    "print('Avant normalisation x_test : Minimum = '+str(X_test.min())+', Maximum = '+str(X_test.max()))\n",
    "\n",
    "X_max = (X_train.max())\n",
    "X_train  = X_train / X_max\n",
    "X_test = X_test / X_max\n",
    "\n",
    "print('Après normalisation x_train : Minimum = '+str(X_train.min())+', Maximum = '+str(X_train.max()))\n",
    "print('Après normalisation x_test : Minimum = '+str(X_test.min())+', Maximum = '+str(X_test.max()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73ccbb7c",
   "metadata": {},
   "source": [
    "Importer un modèle qu'on a sauvegardé auparavant dans un fichier h5"
   ]
  },
  {
   "cell_type": "raw",
   "id": "623bc892",
   "metadata": {},
   "source": [
    "model = keras.models.load_model('nouveau_hasan.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c29fde",
   "metadata": {},
   "source": [
    "Ou on définit notre modèle, entrée de de taille 22 avec quatres couches intermédiaire composés de 256, 128, 64 et 32 neurones avec fonction d'activation Relu et dernière couche, de sortie, de taille 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "e7f16782",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "\n",
    "model.add(Input(shape=(22,)))\n",
    "\n",
    "model.add(layers.Dense(256, activation=\"relu\")),\n",
    "\n",
    "model.add(layers.Dense(128, activation=\"relu\")),\n",
    "\n",
    "model.add(layers.Dense(64, activation=\"relu\")),\n",
    "\n",
    "model.add(layers.Dense(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a33dee0",
   "metadata": {},
   "source": [
    "On définit notre optimiseur et la vitesse d'apprentissage"
   ]
  },
  {
   "cell_type": "raw",
   "id": "bffff040",
   "metadata": {},
   "source": [
    "# opt = SGD(learning_rate=0.01, momentum=0.9)\n",
    "opti = tf.keras.optimizers.Adam(learning_rate=0.1)  # sgd(0.01, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d714edbe",
   "metadata": {},
   "source": [
    "on précise à notre modèle notre fonction de perte mae, mean absolute error, l'optimiseur et le métrique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "8fb44e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss=\"mae\",\n",
    "    metrics=[tf.keras.metrics.MeanAbsoluteError()]\n",
    ")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "bc4851cc",
   "metadata": {},
   "source": [
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss=\"mse\",\n",
    "    metrics=[\"mae\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7169a9c1",
   "metadata": {},
   "source": [
    "On entraîne le modèle en précisant nos données d'entraînement, X_train et y_train, le batch_size qui est le nombre de fois qu'on montre nos données au modèle avant qu'il ajuste ses paramètres, le nombre d'epochs qui est le nombre d'entraînement et nos données de valisation, X_test et y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "66d2c3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(patience=50, verbose=1),\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(factor=0.1, patience=10, min_lr=0.00001, verbose=1),\n",
    "    tf.keras.callbacks.ModelCheckpoint('model_dl.h5', verbose=1, save_best_only=True, save_weights_only=True)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "8d686949",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "6184/6250 [============================>.] - ETA: 0s - loss: 13.9921 - mean_absolute_error: 13.9921\n",
      "Epoch 00001: val_loss improved from inf to 6.96989, saving model to model_dl.h5\n",
      "6250/6250 [==============================] - 5s 741us/step - loss: 13.9198 - mean_absolute_error: 13.9198 - val_loss: 6.9699 - val_mean_absolute_error: 6.9699\n",
      "Epoch 2/1000\n",
      "6239/6250 [============================>.] - ETA: 0s - loss: 4.4119 - mean_absolute_error: 4.4119\n",
      "Epoch 00002: val_loss improved from 6.96989 to 3.54734, saving model to model_dl.h5\n",
      "6250/6250 [==============================] - 4s 649us/step - loss: 4.4094 - mean_absolute_error: 4.4094 - val_loss: 3.5473 - val_mean_absolute_error: 3.5473\n",
      "Epoch 3/1000\n",
      "6167/6250 [============================>.] - ETA: 0s - loss: 2.9005 - mean_absolute_error: 2.9005\n",
      "Epoch 00003: val_loss improved from 3.54734 to 2.53787, saving model to model_dl.h5\n",
      "6250/6250 [==============================] - 4s 645us/step - loss: 2.8979 - mean_absolute_error: 2.8979 - val_loss: 2.5379 - val_mean_absolute_error: 2.5379\n",
      "Epoch 4/1000\n",
      "6181/6250 [============================>.] - ETA: 0s - loss: 2.4464 - mean_absolute_error: 2.4464\n",
      "Epoch 00004: val_loss improved from 2.53787 to 2.45673, saving model to model_dl.h5\n",
      "6250/6250 [==============================] - 4s 695us/step - loss: 2.4432 - mean_absolute_error: 2.4432 - val_loss: 2.4567 - val_mean_absolute_error: 2.4567\n",
      "Epoch 5/1000\n",
      "6230/6250 [============================>.] - ETA: 0s - loss: 2.1943 - mean_absolute_error: 2.1943\n",
      "Epoch 00005: val_loss improved from 2.45673 to 2.03523, saving model to model_dl.h5\n",
      "6250/6250 [==============================] - 5s 831us/step - loss: 2.1938 - mean_absolute_error: 2.1938 - val_loss: 2.0352 - val_mean_absolute_error: 2.0352\n",
      "Epoch 6/1000\n",
      "6200/6250 [============================>.] - ETA: 0s - loss: 2.0679 - mean_absolute_error: 2.0679\n",
      "Epoch 00006: val_loss did not improve from 2.03523\n",
      "6250/6250 [==============================] - 5s 727us/step - loss: 2.0695 - mean_absolute_error: 2.0695 - val_loss: 2.0797 - val_mean_absolute_error: 2.0797\n",
      "Epoch 7/1000\n",
      "6226/6250 [============================>.] - ETA: 0s - loss: 1.9302 - mean_absolute_error: 1.9302\n",
      "Epoch 00007: val_loss improved from 2.03523 to 1.58247, saving model to model_dl.h5\n",
      "6250/6250 [==============================] - 4s 698us/step - loss: 1.9294 - mean_absolute_error: 1.9294 - val_loss: 1.5825 - val_mean_absolute_error: 1.5825\n",
      "Epoch 8/1000\n",
      "6248/6250 [============================>.] - ETA: 0s - loss: 1.8485 - mean_absolute_error: 1.8485\n",
      "Epoch 00008: val_loss did not improve from 1.58247\n",
      "6250/6250 [==============================] - 4s 693us/step - loss: 1.8484 - mean_absolute_error: 1.8484 - val_loss: 1.7183 - val_mean_absolute_error: 1.7183\n",
      "Epoch 9/1000\n",
      "6175/6250 [============================>.] - ETA: 0s - loss: 1.8365 - mean_absolute_error: 1.8365\n",
      "Epoch 00009: val_loss did not improve from 1.58247\n",
      "6250/6250 [==============================] - 4s 676us/step - loss: 1.8336 - mean_absolute_error: 1.8336 - val_loss: 1.8581 - val_mean_absolute_error: 1.8581\n",
      "Epoch 10/1000\n",
      "6229/6250 [============================>.] - ETA: 0s - loss: 1.7288 - mean_absolute_error: 1.7288\n",
      "Epoch 00010: val_loss did not improve from 1.58247\n",
      "6250/6250 [==============================] - 4s 686us/step - loss: 1.7284 - mean_absolute_error: 1.7284 - val_loss: 1.6376 - val_mean_absolute_error: 1.6376\n",
      "Epoch 11/1000\n",
      "6191/6250 [============================>.] - ETA: 0s - loss: 1.6983 - mean_absolute_error: 1.6983\n",
      "Epoch 00011: val_loss did not improve from 1.58247\n",
      "6250/6250 [==============================] - 5s 799us/step - loss: 1.7026 - mean_absolute_error: 1.7026 - val_loss: 1.9085 - val_mean_absolute_error: 1.9085\n",
      "Epoch 12/1000\n",
      "6198/6250 [============================>.] - ETA: 0s - loss: 1.6642 - mean_absolute_error: 1.6642\n",
      "Epoch 00012: val_loss did not improve from 1.58247\n",
      "6250/6250 [==============================] - 6s 882us/step - loss: 1.6639 - mean_absolute_error: 1.6639 - val_loss: 1.6712 - val_mean_absolute_error: 1.6712\n",
      "Epoch 13/1000\n",
      "6198/6250 [============================>.] - ETA: 0s - loss: 1.6176 - mean_absolute_error: 1.6176\n",
      "Epoch 00013: val_loss improved from 1.58247 to 1.42238, saving model to model_dl.h5\n",
      "6250/6250 [==============================] - 5s 880us/step - loss: 1.6164 - mean_absolute_error: 1.6164 - val_loss: 1.4224 - val_mean_absolute_error: 1.4224\n",
      "Epoch 14/1000\n",
      "6244/6250 [============================>.] - ETA: 0s - loss: 1.5291 - mean_absolute_error: 1.5291\n",
      "Epoch 00014: val_loss did not improve from 1.42238\n",
      "6250/6250 [==============================] - 5s 792us/step - loss: 1.5288 - mean_absolute_error: 1.5288 - val_loss: 1.6130 - val_mean_absolute_error: 1.6130\n",
      "Epoch 15/1000\n",
      "6217/6250 [============================>.] - ETA: 0s - loss: 1.5237 - mean_absolute_error: 1.5237\n",
      "Epoch 00015: val_loss improved from 1.42238 to 1.33868, saving model to model_dl.h5\n",
      "6250/6250 [==============================] - 6s 1ms/step - loss: 1.5241 - mean_absolute_error: 1.5241 - val_loss: 1.3387 - val_mean_absolute_error: 1.3387\n",
      "Epoch 16/1000\n",
      "6191/6250 [============================>.] - ETA: 0s - loss: 1.5097 - mean_absolute_error: 1.5097\n",
      "Epoch 00016: val_loss did not improve from 1.33868\n",
      "6250/6250 [==============================] - 5s 833us/step - loss: 1.5078 - mean_absolute_error: 1.5078 - val_loss: 1.4653 - val_mean_absolute_error: 1.4653\n",
      "Epoch 17/1000\n",
      "6207/6250 [============================>.] - ETA: 0s - loss: 1.4979 - mean_absolute_error: 1.4979- ETA:\n",
      "Epoch 00017: val_loss did not improve from 1.33868\n",
      "6250/6250 [==============================] - 5s 759us/step - loss: 1.4957 - mean_absolute_error: 1.4957 - val_loss: 1.4608 - val_mean_absolute_error: 1.4608\n",
      "Epoch 18/1000\n",
      "6226/6250 [============================>.] - ETA: 0s - loss: 1.4715 - mean_absolute_error: 1.4715\n",
      "Epoch 00018: val_loss improved from 1.33868 to 1.22600, saving model to model_dl.h5\n",
      "6250/6250 [==============================] - 5s 810us/step - loss: 1.4707 - mean_absolute_error: 1.4707 - val_loss: 1.2260 - val_mean_absolute_error: 1.2260\n",
      "Epoch 19/1000\n",
      "6172/6250 [============================>.] - ETA: 0s - loss: 1.4415 - mean_absolute_error: 1.4415\n",
      "Epoch 00019: val_loss did not improve from 1.22600\n",
      "6250/6250 [==============================] - 5s 806us/step - loss: 1.4455 - mean_absolute_error: 1.4455 - val_loss: 1.6275 - val_mean_absolute_error: 1.6275\n",
      "Epoch 20/1000\n",
      "6169/6250 [============================>.] - ETA: 0s - loss: 1.4289 - mean_absolute_error: 1.4289\n",
      "Epoch 00020: val_loss did not improve from 1.22600\n",
      "6250/6250 [==============================] - 5s 722us/step - loss: 1.4258 - mean_absolute_error: 1.4258 - val_loss: 1.6372 - val_mean_absolute_error: 1.6372\n",
      "Epoch 21/1000\n",
      "6222/6250 [============================>.] - ETA: 0s - loss: 1.3814 - mean_absolute_error: 1.3814\n",
      "Epoch 00021: val_loss did not improve from 1.22600\n",
      "6250/6250 [==============================] - 5s 773us/step - loss: 1.3800 - mean_absolute_error: 1.3800 - val_loss: 1.3435 - val_mean_absolute_error: 1.3435\n",
      "Epoch 22/1000\n",
      "6218/6250 [============================>.] - ETA: 0s - loss: 1.3757 - mean_absolute_error: 1.3757\n",
      "Epoch 00022: val_loss did not improve from 1.22600\n",
      "6250/6250 [==============================] - 4s 710us/step - loss: 1.3757 - mean_absolute_error: 1.3757 - val_loss: 1.7415 - val_mean_absolute_error: 1.7415\n",
      "Epoch 23/1000\n",
      "6193/6250 [============================>.] - ETA: 0s - loss: 1.3799 - mean_absolute_error: 1.3799\n",
      "Epoch 00023: val_loss did not improve from 1.22600\n",
      "6250/6250 [==============================] - 5s 739us/step - loss: 1.3812 - mean_absolute_error: 1.3812 - val_loss: 1.5930 - val_mean_absolute_error: 1.5930\n",
      "Epoch 24/1000\n",
      "6246/6250 [============================>.] - ETA: 0s - loss: 1.3574 - mean_absolute_error: 1.3574\n",
      "Epoch 00024: val_loss improved from 1.22600 to 1.06968, saving model to model_dl.h5\n",
      "6250/6250 [==============================] - 5s 863us/step - loss: 1.3574 - mean_absolute_error: 1.3574 - val_loss: 1.0697 - val_mean_absolute_error: 1.0697\n",
      "Epoch 25/1000\n",
      "6186/6250 [============================>.] - ETA: 0s - loss: 1.3070 - mean_absolute_error: 1.3070\n",
      "Epoch 00025: val_loss did not improve from 1.06968\n",
      "6250/6250 [==============================] - 5s 784us/step - loss: 1.3056 - mean_absolute_error: 1.3056 - val_loss: 1.2981 - val_mean_absolute_error: 1.2981\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/1000\n",
      "6218/6250 [============================>.] - ETA: 0s - loss: 1.3608 - mean_absolute_error: 1.3608\n",
      "Epoch 00026: val_loss did not improve from 1.06968\n",
      "6250/6250 [==============================] - 5s 750us/step - loss: 1.3600 - mean_absolute_error: 1.3600 - val_loss: 1.3466 - val_mean_absolute_error: 1.3466\n",
      "Epoch 27/1000\n",
      "6189/6250 [============================>.] - ETA: 0s - loss: 1.2912 - mean_absolute_error: 1.2912\n",
      "Epoch 00027: val_loss did not improve from 1.06968\n",
      "6250/6250 [==============================] - 4s 694us/step - loss: 1.2915 - mean_absolute_error: 1.2915 - val_loss: 1.2033 - val_mean_absolute_error: 1.2033\n",
      "Epoch 28/1000\n",
      "6247/6250 [============================>.] - ETA: 0s - loss: 1.2832 - mean_absolute_error: 1.2832\n",
      "Epoch 00028: val_loss did not improve from 1.06968\n",
      "6250/6250 [==============================] - 8s 1ms/step - loss: 1.2831 - mean_absolute_error: 1.2831 - val_loss: 1.4622 - val_mean_absolute_error: 1.4622\n",
      "Epoch 29/1000\n",
      "6250/6250 [==============================] - ETA: 0s - loss: 1.2689 - mean_absolute_error: 1.2689\n",
      "Epoch 00029: val_loss did not improve from 1.06968\n",
      "6250/6250 [==============================] - 23s 4ms/step - loss: 1.2689 - mean_absolute_error: 1.2689 - val_loss: 1.5507 - val_mean_absolute_error: 1.5507\n",
      "Epoch 30/1000\n",
      "6250/6250 [==============================] - ETA: 0s - loss: 1.2489 - mean_absolute_error: 1.2489\n",
      "Epoch 00030: val_loss did not improve from 1.06968\n",
      "6250/6250 [==============================] - 26s 4ms/step - loss: 1.2489 - mean_absolute_error: 1.2489 - val_loss: 1.1050 - val_mean_absolute_error: 1.1050\n",
      "Epoch 31/1000\n",
      "6217/6250 [============================>.] - ETA: 0s - loss: 1.2083 - mean_absolute_error: 1.2083\n",
      "Epoch 00031: val_loss did not improve from 1.06968\n",
      "6250/6250 [==============================] - 26s 4ms/step - loss: 1.2078 - mean_absolute_error: 1.2078 - val_loss: 1.2443 - val_mean_absolute_error: 1.2443\n",
      "Epoch 32/1000\n",
      "6250/6250 [==============================] - ETA: 0s - loss: 1.1835 - mean_absolute_error: 1.1835- ETA: 2s - l\n",
      "Epoch 00032: val_loss did not improve from 1.06968\n",
      "6250/6250 [==============================] - 25s 4ms/step - loss: 1.1835 - mean_absolute_error: 1.1835 - val_loss: 1.1779 - val_mean_absolute_error: 1.1779\n",
      "Epoch 33/1000\n",
      "6250/6250 [==============================] - ETA: 0s - loss: 1.1858 - mean_absolute_error: 1.1858\n",
      "Epoch 00033: val_loss did not improve from 1.06968\n",
      "6250/6250 [==============================] - 25s 4ms/step - loss: 1.1858 - mean_absolute_error: 1.1858 - val_loss: 1.6166 - val_mean_absolute_error: 1.6166\n",
      "Epoch 34/1000\n",
      "6249/6250 [============================>.] - ETA: 0s - loss: 1.2209 - mean_absolute_error: 1.2209\n",
      "Epoch 00034: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 1.06968\n",
      "6250/6250 [==============================] - 26s 4ms/step - loss: 1.2208 - mean_absolute_error: 1.2208 - val_loss: 1.2240 - val_mean_absolute_error: 1.2240\n",
      "Epoch 35/1000\n",
      "6243/6250 [============================>.] - ETA: 0s - loss: 0.4953 - mean_absolute_error: 0.4953\n",
      "Epoch 00035: val_loss improved from 1.06968 to 0.49911, saving model to model_dl.h5\n",
      "6250/6250 [==============================] - 25s 4ms/step - loss: 0.4952 - mean_absolute_error: 0.4952 - val_loss: 0.4991 - val_mean_absolute_error: 0.4991\n",
      "Epoch 36/1000\n",
      "6215/6250 [============================>.] - ETA: 0s - loss: 0.4293 - mean_absolute_error: 0.4293- ETA: - ETA: 2s -\n",
      "Epoch 00036: val_loss improved from 0.49911 to 0.44313, saving model to model_dl.h5\n",
      "6250/6250 [==============================] - 26s 4ms/step - loss: 0.4292 - mean_absolute_error: 0.4292 - val_loss: 0.4431 - val_mean_absolute_error: 0.4431\n",
      "Epoch 37/1000\n",
      "6238/6250 [============================>.] - ETA: 0s - loss: 0.4066 - mean_absolute_error: 0.4066\n",
      "Epoch 00037: val_loss did not improve from 0.44313\n",
      "6250/6250 [==============================] - 25s 4ms/step - loss: 0.4065 - mean_absolute_error: 0.4065 - val_loss: 0.4485 - val_mean_absolute_error: 0.4485\n",
      "Epoch 38/1000\n",
      "6241/6250 [============================>.] - ETA: 0s - loss: 0.3980 - mean_absolute_error: 0.3980\n",
      "Epoch 00038: val_loss improved from 0.44313 to 0.42720, saving model to model_dl.h5\n",
      "6250/6250 [==============================] - 26s 4ms/step - loss: 0.3984 - mean_absolute_error: 0.3984 - val_loss: 0.4272 - val_mean_absolute_error: 0.4272\n",
      "Epoch 39/1000\n",
      "6229/6250 [============================>.] - ETA: 0s - loss: 0.3889 - mean_absolute_error: 0.3889\n",
      "Epoch 00039: val_loss did not improve from 0.42720\n",
      "6250/6250 [==============================] - 26s 4ms/step - loss: 0.3885 - mean_absolute_error: 0.3885 - val_loss: 0.4318 - val_mean_absolute_error: 0.4318\n",
      "Epoch 40/1000\n",
      "6237/6250 [============================>.] - ETA: 0s - loss: 0.3823 - mean_absolute_error: 0.3823\n",
      "Epoch 00040: val_loss improved from 0.42720 to 0.41189, saving model to model_dl.h5\n",
      "6250/6250 [==============================] - 24s 4ms/step - loss: 0.3822 - mean_absolute_error: 0.3822 - val_loss: 0.4119 - val_mean_absolute_error: 0.4119\n",
      "Epoch 41/1000\n",
      "6249/6250 [============================>.] - ETA: 0s - loss: 0.3843 - mean_absolute_error: 0.3843- ETA: 3s - ETA: 1s - l\n",
      "Epoch 00041: val_loss improved from 0.41189 to 0.39894, saving model to model_dl.h5\n",
      "6250/6250 [==============================] - 28s 4ms/step - loss: 0.3842 - mean_absolute_error: 0.3842 - val_loss: 0.3989 - val_mean_absolute_error: 0.3989\n",
      "Epoch 42/1000\n",
      "6238/6250 [============================>.] - ETA: 0s - loss: 0.3750 - mean_absolute_error: 0.3750- ETA: 1s - loss: 0.3757 - mean_absolute_e - ETA: 0s - loss: 0.3759 - mean_absolute_er\n",
      "Epoch 00042: val_loss did not improve from 0.39894\n",
      "6250/6250 [==============================] - 29s 5ms/step - loss: 0.3751 - mean_absolute_error: 0.3751 - val_loss: 0.4223 - val_mean_absolute_error: 0.4223\n",
      "Epoch 43/1000\n",
      "6246/6250 [============================>.] - ETA: 0s - loss: 0.3731 - mean_absolute_error: 0.3731- ETA: 0s - loss: 0.3717 - mean_absolute_error: 0.3\n",
      "Epoch 00043: val_loss did not improve from 0.39894\n",
      "6250/6250 [==============================] - 30s 5ms/step - loss: 0.3737 - mean_absolute_error: 0.3737 - val_loss: 0.3999 - val_mean_absolute_error: 0.3999\n",
      "Epoch 44/1000\n",
      "6241/6250 [============================>.] - ETA: 0s - loss: 0.3711 - mean_absolute_error: 0.3711- ETA: 3s - loss: 0.3731 - mean_absolute_error: 0 - ETA: 3s - loss: 0.37 - ETA: 1s - loss: 0.3724 - mea\n",
      "Epoch 00044: val_loss did not improve from 0.39894\n",
      "6250/6250 [==============================] - 31s 5ms/step - loss: 0.3709 - mean_absolute_error: 0.3709 - val_loss: 0.4147 - val_mean_absolute_error: 0.4147\n",
      "Epoch 45/1000\n",
      "6250/6250 [==============================] - ETA: 0s - loss: 0.3622 - mean_absolute_error: 0.3622\n",
      "Epoch 00045: val_loss did not improve from 0.39894\n",
      "6250/6250 [==============================] - 29s 5ms/step - loss: 0.3622 - mean_absolute_error: 0.3622 - val_loss: 0.4330 - val_mean_absolute_error: 0.4330\n",
      "Epoch 46/1000\n",
      "6245/6250 [============================>.] - ETA: 0s - loss: 0.3631 - mean_absolute_error: 0.3631- ETA: \n",
      "Epoch 00046: val_loss did not improve from 0.39894\n",
      "6250/6250 [==============================] - 33s 5ms/step - loss: 0.3630 - mean_absolute_error: 0.3630 - val_loss: 0.4108 - val_mean_absolute_error: 0.4108\n",
      "Epoch 47/1000\n",
      "6242/6250 [============================>.] - ETA: 0s - loss: 0.3604 - mean_absolute_error: 0.3604\n",
      "Epoch 00047: val_loss did not improve from 0.39894\n",
      "6250/6250 [==============================] - 26s 4ms/step - loss: 0.3602 - mean_absolute_error: 0.3602 - val_loss: 0.4313 - val_mean_absolute_error: 0.4313\n",
      "Epoch 48/1000\n",
      "6234/6250 [============================>.] - ETA: 0s - loss: 0.3579 - mean_absolute_error: 0.3579- ETA: 3s - loss: 0.357 - ETA: 2s - loss: 0.3576 - m\n",
      "Epoch 00048: val_loss improved from 0.39894 to 0.38912, saving model to model_dl.h5\n",
      "6250/6250 [==============================] - 37s 6ms/step - loss: 0.3579 - mean_absolute_error: 0.3579 - val_loss: 0.3891 - val_mean_absolute_error: 0.3891\n",
      "Epoch 49/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6245/6250 [============================>.] - ETA: 0s - loss: 0.3547 - mean_absolute_error: 0.3547  ETA - ETA: 7s - loss: 0.3572 - mean_absolut - ETA: 6s - loss: 0.3588 - mean_absolute_error: 0 - ETA: 6s - loss: 0.3594 -  - ETA: 5s - loss: 0.3578 - mean_absolute_error:  - ETA: 5s - loss: 0.3576 - mean_absolute_error:  \n",
      "Epoch 00049: val_loss improved from 0.38912 to 0.38491, saving model to model_dl.h5\n",
      "6250/6250 [==============================] - 37s 6ms/step - loss: 0.3552 - mean_absolute_error: 0.3552 - val_loss: 0.3849 - val_mean_absolute_error: 0.3849\n",
      "Epoch 50/1000\n",
      "6241/6250 [============================>.] - ETA: 0s - loss: 0.3543 - mean_absolute_error: 0.3543- ETA: 1s - loss: 0.3574 - mea\n",
      "Epoch 00050: val_loss did not improve from 0.38491\n",
      "6250/6250 [==============================] - 32s 5ms/step - loss: 0.3543 - mean_absolute_error: 0.3543 - val_loss: 0.4102 - val_mean_absolute_error: 0.4102\n",
      "Epoch 51/1000\n",
      "6250/6250 [==============================] - ETA: 0s - loss: 0.3507 - mean_absolute_error: 0.3507- ETA: 0s - loss: 0.3510 - mean_absolute_error: 0.35\n",
      "Epoch 00051: val_loss improved from 0.38491 to 0.36472, saving model to model_dl.h5\n",
      "6250/6250 [==============================] - 29s 5ms/step - loss: 0.3507 - mean_absolute_error: 0.3507 - val_loss: 0.3647 - val_mean_absolute_error: 0.3647\n",
      "Epoch 52/1000\n",
      "6246/6250 [============================>.] - ETA: 0s - loss: 0.3427 - mean_absolute_error: 0.3427\n",
      "Epoch 00052: val_loss did not improve from 0.36472\n",
      "6250/6250 [==============================] - 37s 6ms/step - loss: 0.3427 - mean_absolute_error: 0.3427 - val_loss: 0.4709 - val_mean_absolute_error: 0.4709\n",
      "Epoch 53/1000\n",
      "6236/6250 [============================>.] - ETA: 0s - loss: 0.3446 - mean_absolute_error: 0.3446- ETA:  - ETA: 1s \n",
      "Epoch 00053: val_loss did not improve from 0.36472\n",
      "6250/6250 [==============================] - 34s 5ms/step - loss: 0.3448 - mean_absolute_error: 0.3448 - val_loss: 0.3723 - val_mean_absolute_error: 0.3723\n",
      "Epoch 54/1000\n",
      "6249/6250 [============================>.] - ETA: 0s - loss: 0.3437 - mean_absolute_error: 0.3437\n",
      "Epoch 00054: val_loss did not improve from 0.36472\n",
      "6250/6250 [==============================] - 39s 6ms/step - loss: 0.3437 - mean_absolute_error: 0.3437 - val_loss: 0.3881 - val_mean_absolute_error: 0.3881\n",
      "Epoch 55/1000\n",
      "6247/6250 [============================>.] - ETA: 0s - loss: 0.3443 - mean_absolute_error: 0.3443- ETA: 5s - loss: 0.3424 - m\n",
      "Epoch 00055: val_loss did not improve from 0.36472\n",
      "6250/6250 [==============================] - 34s 5ms/step - loss: 0.3445 - mean_absolute_error: 0.3445 - val_loss: 0.3875 - val_mean_absolute_error: 0.3875\n",
      "Epoch 56/1000\n",
      "6249/6250 [============================>.] - ETA: 0s - loss: 0.3391 - mean_absolute_error: 0.3391\n",
      "Epoch 00056: val_loss did not improve from 0.36472\n",
      "6250/6250 [==============================] - 35s 6ms/step - loss: 0.3391 - mean_absolute_error: 0.3391 - val_loss: 0.3809 - val_mean_absolute_error: 0.3809\n",
      "Epoch 57/1000\n",
      "6249/6250 [============================>.] - ETA: 0s - loss: 0.3297 - mean_absolute_error: 0.3297- ETA: 0s - loss: 0.3290 - mean_ab\n",
      "Epoch 00057: val_loss improved from 0.36472 to 0.35887, saving model to model_dl.h5\n",
      "6250/6250 [==============================] - 27s 4ms/step - loss: 0.3297 - mean_absolute_error: 0.3297 - val_loss: 0.3589 - val_mean_absolute_error: 0.3589\n",
      "Epoch 58/1000\n",
      "6244/6250 [============================>.] - ETA: 0s - loss: 0.3347 - mean_absolute_error: 0.3347\n",
      "Epoch 00058: val_loss did not improve from 0.35887\n",
      "6250/6250 [==============================] - 27s 4ms/step - loss: 0.3349 - mean_absolute_error: 0.3349 - val_loss: 0.4393 - val_mean_absolute_error: 0.4393\n",
      "Epoch 59/1000\n",
      "6235/6250 [============================>.] - ETA: 0s - loss: 0.3363 - mean_absolute_error: 0.3363\n",
      "Epoch 00059: val_loss did not improve from 0.35887\n",
      "6250/6250 [==============================] - 27s 4ms/step - loss: 0.3359 - mean_absolute_error: 0.3359 - val_loss: 0.3645 - val_mean_absolute_error: 0.3645\n",
      "Epoch 60/1000\n",
      "6244/6250 [============================>.] - ETA: 0s - loss: 0.3325 - mean_absolute_error: 0.3325\n",
      "Epoch 00060: val_loss did not improve from 0.35887\n",
      "6250/6250 [==============================] - 28s 5ms/step - loss: 0.3325 - mean_absolute_error: 0.3325 - val_loss: 0.3777 - val_mean_absolute_error: 0.3777\n",
      "Epoch 61/1000\n",
      "6242/6250 [============================>.] - ETA: 0s - loss: 0.3278 - mean_absolute_error: 0.3278\n",
      "Epoch 00061: val_loss improved from 0.35887 to 0.35211, saving model to model_dl.h5\n",
      "6250/6250 [==============================] - 27s 4ms/step - loss: 0.3276 - mean_absolute_error: 0.3276 - val_loss: 0.3521 - val_mean_absolute_error: 0.3521\n",
      "Epoch 62/1000\n",
      "6250/6250 [==============================] - ETA: 0s - loss: 0.3280 - mean_absolute_error: 0.3280\n",
      "Epoch 00062: val_loss did not improve from 0.35211\n",
      "6250/6250 [==============================] - 25s 4ms/step - loss: 0.3280 - mean_absolute_error: 0.3280 - val_loss: 0.3886 - val_mean_absolute_error: 0.3886\n",
      "Epoch 63/1000\n",
      "6244/6250 [============================>.] - ETA: 0s - loss: 0.3261 - mean_absolute_error: 0.3261\n",
      "Epoch 00063: val_loss did not improve from 0.35211\n",
      "6250/6250 [==============================] - 26s 4ms/step - loss: 0.3260 - mean_absolute_error: 0.3260 - val_loss: 0.3691 - val_mean_absolute_error: 0.3691\n",
      "Epoch 64/1000\n",
      "6231/6250 [============================>.] - ETA: 0s - loss: 0.3234 - mean_absolute_error: 0.3234\n",
      "Epoch 00064: val_loss did not improve from 0.35211\n",
      "6250/6250 [==============================] - 25s 4ms/step - loss: 0.3241 - mean_absolute_error: 0.3241 - val_loss: 0.4151 - val_mean_absolute_error: 0.4151\n",
      "Epoch 65/1000\n",
      "6248/6250 [============================>.] - ETA: 0s - loss: 0.3246 - mean_absolute_error: 0.3246\n",
      "Epoch 00065: val_loss did not improve from 0.35211\n",
      "6250/6250 [==============================] - 27s 4ms/step - loss: 0.3246 - mean_absolute_error: 0.3246 - val_loss: 0.3825 - val_mean_absolute_error: 0.3825\n",
      "Epoch 66/1000\n",
      "6241/6250 [============================>.] - ETA: 0s - loss: 0.3263 - mean_absolute_error: 0.3263- ETA: 0s - loss: 0.3261 - mean_absolute\n",
      "Epoch 00066: val_loss did not improve from 0.35211\n",
      "6250/6250 [==============================] - 28s 5ms/step - loss: 0.3263 - mean_absolute_error: 0.3263 - val_loss: 0.3970 - val_mean_absolute_error: 0.3970\n",
      "Epoch 67/1000\n",
      "6244/6250 [============================>.] - ETA: 0s - loss: 0.3212 - mean_absolute_error: 0.3212- ETA: 6s - loss: 0.3220 - mean_abso - ETA: 5s - loss: 0.32\n",
      "Epoch 00067: val_loss improved from 0.35211 to 0.35141, saving model to model_dl.h5\n",
      "6250/6250 [==============================] - 27s 4ms/step - loss: 0.3210 - mean_absolute_error: 0.3210 - val_loss: 0.3514 - val_mean_absolute_error: 0.3514\n",
      "Epoch 68/1000\n",
      "6203/6250 [============================>.] - ETA: 0s - loss: 0.3188 - mean_absolute_error: 0.3188\n",
      "Epoch 00068: val_loss improved from 0.35141 to 0.34329, saving model to model_dl.h5\n",
      "6250/6250 [==============================] - 13s 2ms/step - loss: 0.3190 - mean_absolute_error: 0.3190 - val_loss: 0.3433 - val_mean_absolute_error: 0.3433\n",
      "Epoch 69/1000\n",
      "6209/6250 [============================>.] - ETA: 0s - loss: 0.3167 - mean_absolute_error: 0.3167\n",
      "Epoch 00069: val_loss did not improve from 0.34329\n",
      "6250/6250 [==============================] - 5s 740us/step - loss: 0.3172 - mean_absolute_error: 0.3172 - val_loss: 0.3585 - val_mean_absolute_error: 0.3585\n",
      "Epoch 70/1000\n",
      "6250/6250 [==============================] - ETA: 0s - loss: 0.3186 - mean_absolute_error: 0.3186\n",
      "Epoch 00070: val_loss improved from 0.34329 to 0.33966, saving model to model_dl.h5\n",
      "6250/6250 [==============================] - 4s 695us/step - loss: 0.3186 - mean_absolute_error: 0.3186 - val_loss: 0.3397 - val_mean_absolute_error: 0.3397\n",
      "Epoch 71/1000\n",
      "6224/6250 [============================>.] - ETA: 0s - loss: 0.3150 - mean_absolute_error: 0.3150\n",
      "Epoch 00071: val_loss did not improve from 0.33966\n",
      "6250/6250 [==============================] - 5s 727us/step - loss: 0.3153 - mean_absolute_error: 0.3153 - val_loss: 0.3625 - val_mean_absolute_error: 0.3625\n",
      "Epoch 72/1000\n",
      "6216/6250 [============================>.] - ETA: 0s - loss: 0.3165 - mean_absolute_error: 0.3165\n",
      "Epoch 00072: val_loss improved from 0.33966 to 0.33501, saving model to model_dl.h5\n",
      "6250/6250 [==============================] - 4s 701us/step - loss: 0.3161 - mean_absolute_error: 0.3161 - val_loss: 0.3350 - val_mean_absolute_error: 0.3350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73/1000\n",
      "6178/6250 [============================>.] - ETA: 0s - loss: 0.3164 - mean_absolute_error: 0.3164\n",
      "Epoch 00073: val_loss did not improve from 0.33501\n",
      "6250/6250 [==============================] - 4s 697us/step - loss: 0.3157 - mean_absolute_error: 0.3157 - val_loss: 0.3773 - val_mean_absolute_error: 0.3773\n",
      "Epoch 74/1000\n",
      "6249/6250 [============================>.] - ETA: 0s - loss: 0.3111 - mean_absolute_error: 0.3111\n",
      "Epoch 00074: val_loss did not improve from 0.33501\n",
      "6250/6250 [==============================] - 4s 697us/step - loss: 0.3111 - mean_absolute_error: 0.3111 - val_loss: 0.4309 - val_mean_absolute_error: 0.4309\n",
      "Epoch 75/1000\n",
      "6202/6250 [============================>.] - ETA: 0s - loss: 0.3116 - mean_absolute_error: 0.3116\n",
      "Epoch 00075: val_loss did not improve from 0.33501\n",
      "6250/6250 [==============================] - 5s 752us/step - loss: 0.3123 - mean_absolute_error: 0.3123 - val_loss: 0.3755 - val_mean_absolute_error: 0.3755\n",
      "Epoch 76/1000\n",
      "6212/6250 [============================>.] - ETA: 0s - loss: 0.3111 - mean_absolute_error: 0.3111\n",
      "Epoch 00076: val_loss did not improve from 0.33501\n",
      "6250/6250 [==============================] - 4s 706us/step - loss: 0.3123 - mean_absolute_error: 0.3123 - val_loss: 0.3517 - val_mean_absolute_error: 0.3517\n",
      "Epoch 77/1000\n",
      "6203/6250 [============================>.] - ETA: 0s - loss: 0.3082 - mean_absolute_error: 0.3082\n",
      "Epoch 00077: val_loss did not improve from 0.33501\n",
      "6250/6250 [==============================] - 5s 741us/step - loss: 0.3086 - mean_absolute_error: 0.3086 - val_loss: 0.3937 - val_mean_absolute_error: 0.3937\n",
      "Epoch 78/1000\n",
      "6235/6250 [============================>.] - ETA: 0s - loss: 0.3057 - mean_absolute_error: 0.3057\n",
      "Epoch 00078: val_loss did not improve from 0.33501\n",
      "6250/6250 [==============================] - 5s 756us/step - loss: 0.3058 - mean_absolute_error: 0.3058 - val_loss: 0.3438 - val_mean_absolute_error: 0.3438\n",
      "Epoch 79/1000\n",
      "6176/6250 [============================>.] - ETA: 0s - loss: 0.3111 - mean_absolute_error: 0.3111\n",
      "Epoch 00079: val_loss did not improve from 0.33501\n",
      "6250/6250 [==============================] - 4s 711us/step - loss: 0.3119 - mean_absolute_error: 0.3119 - val_loss: 0.3607 - val_mean_absolute_error: 0.3607\n",
      "Epoch 80/1000\n",
      "6169/6250 [============================>.] - ETA: 0s - loss: 0.3067 - mean_absolute_error: 0.3067\n",
      "Epoch 00080: val_loss did not improve from 0.33501\n",
      "6250/6250 [==============================] - 5s 750us/step - loss: 0.3061 - mean_absolute_error: 0.3061 - val_loss: 0.4009 - val_mean_absolute_error: 0.4009\n",
      "Epoch 81/1000\n",
      "6203/6250 [============================>.] - ETA: 0s - loss: 0.3070 - mean_absolute_error: 0.3070\n",
      "Epoch 00081: val_loss did not improve from 0.33501\n",
      "6250/6250 [==============================] - 4s 693us/step - loss: 0.3081 - mean_absolute_error: 0.3081 - val_loss: 0.3487 - val_mean_absolute_error: 0.3487\n",
      "Epoch 82/1000\n",
      "6226/6250 [============================>.] - ETA: 0s - loss: 0.3021 - mean_absolute_error: 0.3021\n",
      "Epoch 00082: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.33501\n",
      "6250/6250 [==============================] - 5s 743us/step - loss: 0.3026 - mean_absolute_error: 0.3026 - val_loss: 0.3729 - val_mean_absolute_error: 0.3729\n",
      "Epoch 83/1000\n",
      "6228/6250 [============================>.] - ETA: 0s - loss: 0.2381 - mean_absolute_error: 0.2381\n",
      "Epoch 00083: val_loss improved from 0.33501 to 0.28792, saving model to model_dl.h5\n",
      "6250/6250 [==============================] - 4s 694us/step - loss: 0.2387 - mean_absolute_error: 0.2387 - val_loss: 0.2879 - val_mean_absolute_error: 0.2879\n",
      "Epoch 84/1000\n",
      "6220/6250 [============================>.] - ETA: 0s - loss: 0.2343 - mean_absolute_error: 0.2343\n",
      "Epoch 00084: val_loss improved from 0.28792 to 0.28780, saving model to model_dl.h5\n",
      "6250/6250 [==============================] - 4s 697us/step - loss: 0.2342 - mean_absolute_error: 0.2342 - val_loss: 0.2878 - val_mean_absolute_error: 0.2878\n",
      "Epoch 85/1000\n",
      "6230/6250 [============================>.] - ETA: 0s - loss: 0.2326 - mean_absolute_error: 0.2326\n",
      "Epoch 00085: val_loss improved from 0.28780 to 0.28775, saving model to model_dl.h5\n",
      "6250/6250 [==============================] - 4s 705us/step - loss: 0.2323 - mean_absolute_error: 0.2323 - val_loss: 0.2878 - val_mean_absolute_error: 0.2878\n",
      "Epoch 86/1000\n",
      "6193/6250 [============================>.] - ETA: 0s - loss: 0.2334 - mean_absolute_error: 0.2334\n",
      "Epoch 00086: val_loss improved from 0.28775 to 0.28732, saving model to model_dl.h5\n",
      "6250/6250 [==============================] - 5s 741us/step - loss: 0.2330 - mean_absolute_error: 0.2330 - val_loss: 0.2873 - val_mean_absolute_error: 0.2873\n",
      "Epoch 87/1000\n",
      "6236/6250 [============================>.] - ETA: 0s - loss: 0.2327 - mean_absolute_error: 0.2327\n",
      "Epoch 00087: val_loss improved from 0.28732 to 0.28687, saving model to model_dl.h5\n",
      "6250/6250 [==============================] - 4s 692us/step - loss: 0.2328 - mean_absolute_error: 0.2328 - val_loss: 0.2869 - val_mean_absolute_error: 0.2869\n",
      "Epoch 88/1000\n",
      "6188/6250 [============================>.] - ETA: 0s - loss: 0.2309 - mean_absolute_error: 0.2309\n",
      "Epoch 00088: val_loss improved from 0.28687 to 0.28610, saving model to model_dl.h5\n",
      "6250/6250 [==============================] - 4s 697us/step - loss: 0.2313 - mean_absolute_error: 0.2313 - val_loss: 0.2861 - val_mean_absolute_error: 0.2861\n",
      "Epoch 89/1000\n",
      "6219/6250 [============================>.] - ETA: 0s - loss: 0.2314 - mean_absolute_error: 0.2314\n",
      "Epoch 00089: val_loss did not improve from 0.28610\n",
      "6250/6250 [==============================] - 5s 734us/step - loss: 0.2310 - mean_absolute_error: 0.2310 - val_loss: 0.2867 - val_mean_absolute_error: 0.2867\n",
      "Epoch 90/1000\n",
      "6223/6250 [============================>.] - ETA: 0s - loss: 0.2316 - mean_absolute_error: 0.2316\n",
      "Epoch 00090: val_loss did not improve from 0.28610\n",
      "6250/6250 [==============================] - 4s 695us/step - loss: 0.2318 - mean_absolute_error: 0.2318 - val_loss: 0.2872 - val_mean_absolute_error: 0.2872\n",
      "Epoch 91/1000\n",
      "6175/6250 [============================>.] - ETA: 0s - loss: 0.2321 - mean_absolute_error: 0.2321\n",
      "Epoch 00091: val_loss improved from 0.28610 to 0.28257, saving model to model_dl.h5\n",
      "6250/6250 [==============================] - 4s 689us/step - loss: 0.2312 - mean_absolute_error: 0.2312 - val_loss: 0.2826 - val_mean_absolute_error: 0.2826\n",
      "Epoch 92/1000\n",
      "6239/6250 [============================>.] - ETA: 0s - loss: 0.2315 - mean_absolute_error: 0.2315\n",
      "Epoch 00092: val_loss did not improve from 0.28257\n",
      "6250/6250 [==============================] - 4s 690us/step - loss: 0.2317 - mean_absolute_error: 0.2317 - val_loss: 0.2832 - val_mean_absolute_error: 0.2832\n",
      "Epoch 93/1000\n",
      "6248/6250 [============================>.] - ETA: 0s - loss: 0.2311 - mean_absolute_error: 0.2311\n",
      "Epoch 00093: val_loss did not improve from 0.28257\n",
      "6250/6250 [==============================] - 5s 741us/step - loss: 0.2310 - mean_absolute_error: 0.2310 - val_loss: 0.2887 - val_mean_absolute_error: 0.2887\n",
      "Epoch 94/1000\n",
      "6170/6250 [============================>.] - ETA: 0s - loss: 0.2313 - mean_absolute_error: 0.2313\n",
      "Epoch 00094: val_loss did not improve from 0.28257\n",
      "6250/6250 [==============================] - 4s 689us/step - loss: 0.2308 - mean_absolute_error: 0.2308 - val_loss: 0.2850 - val_mean_absolute_error: 0.2850\n",
      "Epoch 95/1000\n",
      "6205/6250 [============================>.] - ETA: 0s - loss: 0.2298 - mean_absolute_error: 0.2298\n",
      "Epoch 00095: val_loss did not improve from 0.28257\n",
      "6250/6250 [==============================] - 5s 749us/step - loss: 0.2300 - mean_absolute_error: 0.2300 - val_loss: 0.2834 - val_mean_absolute_error: 0.2834\n",
      "Epoch 96/1000\n",
      "6203/6250 [============================>.] - ETA: 0s - loss: 0.2305 - mean_absolute_error: 0.2305\n",
      "Epoch 00096: val_loss did not improve from 0.28257\n",
      "6250/6250 [==============================] - 5s 743us/step - loss: 0.2305 - mean_absolute_error: 0.2305 - val_loss: 0.2841 - val_mean_absolute_error: 0.2841\n",
      "Epoch 97/1000\n",
      "6190/6250 [============================>.] - ETA: 0s - loss: 0.2300 - mean_absolute_error: 0.2300\n",
      "Epoch 00097: val_loss did not improve from 0.28257\n",
      "6250/6250 [==============================] - 4s 700us/step - loss: 0.2295 - mean_absolute_error: 0.2295 - val_loss: 0.2838 - val_mean_absolute_error: 0.2838\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 98/1000\n",
      "6173/6250 [============================>.] - ETA: 0s - loss: 0.2294 - mean_absolute_error: 0.2294\n",
      "Epoch 00098: val_loss did not improve from 0.28257\n",
      "6250/6250 [==============================] - 4s 686us/step - loss: 0.2297 - mean_absolute_error: 0.2297 - val_loss: 0.2845 - val_mean_absolute_error: 0.2845\n",
      "Epoch 99/1000\n",
      "6168/6250 [============================>.] - ETA: 0s - loss: 0.2290 - mean_absolute_error: 0.2290\n",
      "Epoch 00099: val_loss improved from 0.28257 to 0.27940, saving model to model_dl.h5\n",
      "6250/6250 [==============================] - 4s 692us/step - loss: 0.2292 - mean_absolute_error: 0.2292 - val_loss: 0.2794 - val_mean_absolute_error: 0.2794\n",
      "Epoch 100/1000\n",
      "6235/6250 [============================>.] - ETA: 0s - loss: 0.2288 - mean_absolute_error: 0.2288\n",
      "Epoch 00100: val_loss did not improve from 0.27940\n",
      "6250/6250 [==============================] - 5s 737us/step - loss: 0.2289 - mean_absolute_error: 0.2289 - val_loss: 0.2859 - val_mean_absolute_error: 0.2859\n",
      "Epoch 101/1000\n",
      "6221/6250 [============================>.] - ETA: 0s - loss: 0.2292 - mean_absolute_error: 0.2292\n",
      "Epoch 00101: val_loss did not improve from 0.27940\n",
      "6250/6250 [==============================] - 4s 690us/step - loss: 0.2295 - mean_absolute_error: 0.2295 - val_loss: 0.2854 - val_mean_absolute_error: 0.2854\n",
      "Epoch 102/1000\n",
      "6165/6250 [============================>.] - ETA: 0s - loss: 0.2282 - mean_absolute_error: 0.2282\n",
      "Epoch 00102: val_loss did not improve from 0.27940\n",
      "6250/6250 [==============================] - 4s 689us/step - loss: 0.2286 - mean_absolute_error: 0.2286 - val_loss: 0.2813 - val_mean_absolute_error: 0.2813\n",
      "Epoch 103/1000\n",
      "6240/6250 [============================>.] - ETA: 0s - loss: 0.2286 - mean_absolute_error: 0.2286\n",
      "Epoch 00103: val_loss did not improve from 0.27940\n",
      "6250/6250 [==============================] - 4s 689us/step - loss: 0.2288 - mean_absolute_error: 0.2288 - val_loss: 0.2827 - val_mean_absolute_error: 0.2827\n",
      "Epoch 104/1000\n",
      "6204/6250 [============================>.] - ETA: 0s - loss: 0.2288 - mean_absolute_error: 0.2288\n",
      "Epoch 00104: val_loss did not improve from 0.27940\n",
      "6250/6250 [==============================] - 5s 750us/step - loss: 0.2286 - mean_absolute_error: 0.2286 - val_loss: 0.2821 - val_mean_absolute_error: 0.2821\n",
      "Epoch 105/1000\n",
      "6173/6250 [============================>.] - ETA: 0s - loss: 0.2281 - mean_absolute_error: 0.2281\n",
      "Epoch 00105: val_loss did not improve from 0.27940\n",
      "6250/6250 [==============================] - 4s 687us/step - loss: 0.2280 - mean_absolute_error: 0.2280 - val_loss: 0.2823 - val_mean_absolute_error: 0.2823\n",
      "Epoch 106/1000\n",
      "6169/6250 [============================>.] - ETA: 0s - loss: 0.2293 - mean_absolute_error: 0.2293\n",
      "Epoch 00106: val_loss did not improve from 0.27940\n",
      "6250/6250 [==============================] - 4s 687us/step - loss: 0.2282 - mean_absolute_error: 0.2282 - val_loss: 0.2879 - val_mean_absolute_error: 0.2879\n",
      "Epoch 107/1000\n",
      "6231/6250 [============================>.] - ETA: 0s - loss: 0.2276 - mean_absolute_error: 0.2276\n",
      "Epoch 00107: val_loss did not improve from 0.27940\n",
      "6250/6250 [==============================] - 5s 728us/step - loss: 0.2274 - mean_absolute_error: 0.2274 - val_loss: 0.2862 - val_mean_absolute_error: 0.2862\n",
      "Epoch 108/1000\n",
      "6248/6250 [============================>.] - ETA: 0s - loss: 0.2289 - mean_absolute_error: 0.2289\n",
      "Epoch 00108: val_loss did not improve from 0.27940\n",
      "6250/6250 [==============================] - 4s 689us/step - loss: 0.2288 - mean_absolute_error: 0.2288 - val_loss: 0.2853 - val_mean_absolute_error: 0.2853\n",
      "Epoch 109/1000\n",
      "6167/6250 [============================>.] - ETA: 0s - loss: 0.2271 - mean_absolute_error: 0.2271\n",
      "Epoch 00109: val_loss improved from 0.27940 to 0.27903, saving model to model_dl.h5\n",
      "6250/6250 [==============================] - 4s 688us/step - loss: 0.2276 - mean_absolute_error: 0.2276 - val_loss: 0.2790 - val_mean_absolute_error: 0.2790\n",
      "Epoch 110/1000\n",
      "6192/6250 [============================>.] - ETA: 0s - loss: 0.2272 - mean_absolute_error: 0.2272\n",
      "Epoch 00110: val_loss did not improve from 0.27903\n",
      "6250/6250 [==============================] - 4s 686us/step - loss: 0.2270 - mean_absolute_error: 0.2270 - val_loss: 0.2842 - val_mean_absolute_error: 0.2842\n",
      "Epoch 111/1000\n",
      "6189/6250 [============================>.] - ETA: 0s - loss: 0.2274 - mean_absolute_error: 0.2274\n",
      "Epoch 00111: val_loss did not improve from 0.27903\n",
      "6250/6250 [==============================] - 5s 729us/step - loss: 0.2272 - mean_absolute_error: 0.2272 - val_loss: 0.2826 - val_mean_absolute_error: 0.2826\n",
      "Epoch 112/1000\n",
      "6191/6250 [============================>.] - ETA: 0s - loss: 0.2276 - mean_absolute_error: 0.2276\n",
      "Epoch 00112: val_loss did not improve from 0.27903\n",
      "6250/6250 [==============================] - 4s 689us/step - loss: 0.2276 - mean_absolute_error: 0.2276 - val_loss: 0.2824 - val_mean_absolute_error: 0.2824\n",
      "Epoch 113/1000\n",
      "6209/6250 [============================>.] - ETA: 0s - loss: 0.2264 - mean_absolute_error: 0.2264\n",
      "Epoch 00113: val_loss did not improve from 0.27903\n",
      "6250/6250 [==============================] - 4s 686us/step - loss: 0.2264 - mean_absolute_error: 0.2264 - val_loss: 0.2840 - val_mean_absolute_error: 0.2840\n",
      "Epoch 114/1000\n",
      "6212/6250 [============================>.] - ETA: 0s - loss: 0.2273 - mean_absolute_error: 0.2273\n",
      "Epoch 00114: val_loss did not improve from 0.27903\n",
      "6250/6250 [==============================] - 4s 683us/step - loss: 0.2272 - mean_absolute_error: 0.2272 - val_loss: 0.2809 - val_mean_absolute_error: 0.2809\n",
      "Epoch 115/1000\n",
      "6226/6250 [============================>.] - ETA: 0s - loss: 0.2268 - mean_absolute_error: 0.2268\n",
      "Epoch 00115: val_loss did not improve from 0.27903\n",
      "6250/6250 [==============================] - 5s 738us/step - loss: 0.2267 - mean_absolute_error: 0.2267 - val_loss: 0.2835 - val_mean_absolute_error: 0.2835\n",
      "Epoch 116/1000\n",
      "6186/6250 [============================>.] - ETA: 0s - loss: 0.2270 - mean_absolute_error: 0.2270\n",
      "Epoch 00116: val_loss did not improve from 0.27903\n",
      "6250/6250 [==============================] - 4s 685us/step - loss: 0.2263 - mean_absolute_error: 0.2263 - val_loss: 0.2807 - val_mean_absolute_error: 0.2807\n",
      "Epoch 117/1000\n",
      "6236/6250 [============================>.] - ETA: 0s - loss: 0.2257 - mean_absolute_error: 0.2257\n",
      "Epoch 00117: val_loss improved from 0.27903 to 0.27815, saving model to model_dl.h5\n",
      "6250/6250 [==============================] - 4s 685us/step - loss: 0.2260 - mean_absolute_error: 0.2260 - val_loss: 0.2781 - val_mean_absolute_error: 0.2781\n",
      "Epoch 118/1000\n",
      "6238/6250 [============================>.] - ETA: 0s - loss: 0.2255 - mean_absolute_error: 0.2255\n",
      "Epoch 00118: val_loss did not improve from 0.27815\n",
      "6250/6250 [==============================] - 5s 724us/step - loss: 0.2253 - mean_absolute_error: 0.2253 - val_loss: 0.2786 - val_mean_absolute_error: 0.2786\n",
      "Epoch 119/1000\n",
      "6192/6250 [============================>.] - ETA: 0s - loss: 0.2254 - mean_absolute_error: 0.2254\n",
      "Epoch 00119: val_loss did not improve from 0.27815\n",
      "6250/6250 [==============================] - 4s 696us/step - loss: 0.2259 - mean_absolute_error: 0.2259 - val_loss: 0.2809 - val_mean_absolute_error: 0.2809\n",
      "Epoch 120/1000\n",
      "6173/6250 [============================>.] - ETA: 0s - loss: 0.2260 - mean_absolute_error: 0.2260\n",
      "Epoch 00120: val_loss did not improve from 0.27815\n",
      "6250/6250 [==============================] - 4s 678us/step - loss: 0.2260 - mean_absolute_error: 0.2260 - val_loss: 0.2784 - val_mean_absolute_error: 0.2784\n",
      "Epoch 121/1000\n",
      "6230/6250 [============================>.] - ETA: 0s - loss: 0.2251 - mean_absolute_error: 0.2251\n",
      "Epoch 00121: val_loss improved from 0.27815 to 0.27760, saving model to model_dl.h5\n",
      "6250/6250 [==============================] - 4s 685us/step - loss: 0.2254 - mean_absolute_error: 0.2254 - val_loss: 0.2776 - val_mean_absolute_error: 0.2776\n",
      "Epoch 122/1000\n",
      "6213/6250 [============================>.] - ETA: 0s - loss: 0.2250 - mean_absolute_error: 0.2250\n",
      "Epoch 00122: val_loss did not improve from 0.27760\n",
      "6250/6250 [==============================] - 5s 729us/step - loss: 0.2251 - mean_absolute_error: 0.2251 - val_loss: 0.2809 - val_mean_absolute_error: 0.2809\n",
      "Epoch 123/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6238/6250 [============================>.] - ETA: 0s - loss: 0.2254 - mean_absolute_error: 0.2254\n",
      "Epoch 00123: val_loss did not improve from 0.27760\n",
      "6250/6250 [==============================] - 4s 680us/step - loss: 0.2254 - mean_absolute_error: 0.2254 - val_loss: 0.2821 - val_mean_absolute_error: 0.2821\n",
      "Epoch 124/1000\n",
      "6227/6250 [============================>.] - ETA: 0s - loss: 0.2247 - mean_absolute_error: 0.2247\n",
      "Epoch 00124: val_loss did not improve from 0.27760\n",
      "6250/6250 [==============================] - 4s 680us/step - loss: 0.2245 - mean_absolute_error: 0.2245 - val_loss: 0.2790 - val_mean_absolute_error: 0.2790\n",
      "Epoch 125/1000\n",
      "6206/6250 [============================>.] - ETA: 0s - loss: 0.2245 - mean_absolute_error: 0.2245\n",
      "Epoch 00125: val_loss improved from 0.27760 to 0.27715, saving model to model_dl.h5\n",
      "6250/6250 [==============================] - 4s 690us/step - loss: 0.2244 - mean_absolute_error: 0.2244 - val_loss: 0.2772 - val_mean_absolute_error: 0.2772\n",
      "Epoch 126/1000\n",
      "6248/6250 [============================>.] - ETA: 0s - loss: 0.2253 - mean_absolute_error: 0.2253\n",
      "Epoch 00126: val_loss improved from 0.27715 to 0.27654, saving model to model_dl.h5\n",
      "6250/6250 [==============================] - 5s 733us/step - loss: 0.2252 - mean_absolute_error: 0.2252 - val_loss: 0.2765 - val_mean_absolute_error: 0.2765\n",
      "Epoch 127/1000\n",
      "6222/6250 [============================>.] - ETA: 0s - loss: 0.2248 - mean_absolute_error: 0.2248\n",
      "Epoch 00127: val_loss improved from 0.27654 to 0.27383, saving model to model_dl.h5\n",
      "6250/6250 [==============================] - 4s 681us/step - loss: 0.2248 - mean_absolute_error: 0.2248 - val_loss: 0.2738 - val_mean_absolute_error: 0.2738\n",
      "Epoch 128/1000\n",
      "6201/6250 [============================>.] - ETA: 0s - loss: 0.2237 - mean_absolute_error: 0.2237\n",
      "Epoch 00128: val_loss did not improve from 0.27383\n",
      "6250/6250 [==============================] - 4s 683us/step - loss: 0.2242 - mean_absolute_error: 0.2242 - val_loss: 0.2790 - val_mean_absolute_error: 0.2790\n",
      "Epoch 129/1000\n",
      "6205/6250 [============================>.] - ETA: 0s - loss: 0.2244 - mean_absolute_error: 0.2244\n",
      "Epoch 00129: val_loss did not improve from 0.27383\n",
      "6250/6250 [==============================] - 4s 719us/step - loss: 0.2242 - mean_absolute_error: 0.2242 - val_loss: 0.2791 - val_mean_absolute_error: 0.2791\n",
      "Epoch 130/1000\n",
      "6171/6250 [============================>.] - ETA: 0s - loss: 0.2240 - mean_absolute_error: 0.2240\n",
      "Epoch 00130: val_loss did not improve from 0.27383\n",
      "6250/6250 [==============================] - 4s 685us/step - loss: 0.2239 - mean_absolute_error: 0.2239 - val_loss: 0.2776 - val_mean_absolute_error: 0.2776\n",
      "Epoch 131/1000\n",
      "6248/6250 [============================>.] - ETA: 0s - loss: 0.2239 - mean_absolute_error: 0.2239\n",
      "Epoch 00131: val_loss did not improve from 0.27383\n",
      "6250/6250 [==============================] - 4s 710us/step - loss: 0.2238 - mean_absolute_error: 0.2238 - val_loss: 0.2788 - val_mean_absolute_error: 0.2788\n",
      "Epoch 132/1000\n",
      "6197/6250 [============================>.] - ETA: 0s - loss: 0.2225 - mean_absolute_error: 0.2225\n",
      "Epoch 00132: val_loss did not improve from 0.27383\n",
      "6250/6250 [==============================] - 4s 682us/step - loss: 0.2232 - mean_absolute_error: 0.2232 - val_loss: 0.2803 - val_mean_absolute_error: 0.2803\n",
      "Epoch 133/1000\n",
      "6187/6250 [============================>.] - ETA: 0s - loss: 0.2231 - mean_absolute_error: 0.2231\n",
      "Epoch 00133: val_loss did not improve from 0.27383\n",
      "6250/6250 [==============================] - 5s 731us/step - loss: 0.2236 - mean_absolute_error: 0.2236 - val_loss: 0.2798 - val_mean_absolute_error: 0.2798\n",
      "Epoch 134/1000\n",
      "6245/6250 [============================>.] - ETA: 0s - loss: 0.2233 - mean_absolute_error: 0.2233\n",
      "Epoch 00134: val_loss did not improve from 0.27383\n",
      "6250/6250 [==============================] - 4s 677us/step - loss: 0.2231 - mean_absolute_error: 0.2231 - val_loss: 0.2762 - val_mean_absolute_error: 0.2762\n",
      "Epoch 135/1000\n",
      "6210/6250 [============================>.] - ETA: 0s - loss: 0.2229 - mean_absolute_error: 0.2229\n",
      "Epoch 00135: val_loss did not improve from 0.27383\n",
      "6250/6250 [==============================] - 4s 681us/step - loss: 0.2229 - mean_absolute_error: 0.2229 - val_loss: 0.2786 - val_mean_absolute_error: 0.2786\n",
      "Epoch 136/1000\n",
      "6236/6250 [============================>.] - ETA: 0s - loss: 0.2240 - mean_absolute_error: 0.2240\n",
      "Epoch 00136: val_loss did not improve from 0.27383\n",
      "6250/6250 [==============================] - 4s 681us/step - loss: 0.2239 - mean_absolute_error: 0.2239 - val_loss: 0.2814 - val_mean_absolute_error: 0.2814\n",
      "Epoch 137/1000\n",
      "6200/6250 [============================>.] - ETA: 0s - loss: 0.2219 - mean_absolute_error: 0.2219\n",
      "Epoch 00137: ReduceLROnPlateau reducing learning rate to 1e-05.\n",
      "\n",
      "Epoch 00137: val_loss did not improve from 0.27383\n",
      "6250/6250 [==============================] - 5s 776us/step - loss: 0.2221 - mean_absolute_error: 0.2221 - val_loss: 0.2835 - val_mean_absolute_error: 0.2835\n",
      "Epoch 138/1000\n",
      "6176/6250 [============================>.] - ETA: 0s - loss: 0.2232 - mean_absolute_error: 0.2232\n",
      "Epoch 00138: val_loss did not improve from 0.27383\n",
      "6250/6250 [==============================] - 4s 675us/step - loss: 0.2235 - mean_absolute_error: 0.2235 - val_loss: 0.2775 - val_mean_absolute_error: 0.2775\n",
      "Epoch 139/1000\n",
      "6175/6250 [============================>.] - ETA: 0s - loss: 0.2225 - mean_absolute_error: 0.2225\n",
      "Epoch 00139: val_loss did not improve from 0.27383\n",
      "6250/6250 [==============================] - 4s 684us/step - loss: 0.2226 - mean_absolute_error: 0.2226 - val_loss: 0.2762 - val_mean_absolute_error: 0.2762\n",
      "Epoch 140/1000\n",
      "6201/6250 [============================>.] - ETA: 0s - loss: 0.2226 - mean_absolute_error: 0.2226\n",
      "Epoch 00140: val_loss did not improve from 0.27383\n",
      "6250/6250 [==============================] - 4s 719us/step - loss: 0.2226 - mean_absolute_error: 0.2226 - val_loss: 0.2802 - val_mean_absolute_error: 0.2802\n",
      "Epoch 141/1000\n",
      "6241/6250 [============================>.] - ETA: 0s - loss: 0.2235 - mean_absolute_error: 0.2235\n",
      "Epoch 00141: val_loss did not improve from 0.27383\n",
      "6250/6250 [==============================] - 4s 686us/step - loss: 0.2236 - mean_absolute_error: 0.2236 - val_loss: 0.2776 - val_mean_absolute_error: 0.2776\n",
      "Epoch 142/1000\n",
      "6243/6250 [============================>.] - ETA: 0s - loss: 0.2227 - mean_absolute_error: 0.2227\n",
      "Epoch 00142: val_loss did not improve from 0.27383\n",
      "6250/6250 [==============================] - 4s 683us/step - loss: 0.2227 - mean_absolute_error: 0.2227 - val_loss: 0.2781 - val_mean_absolute_error: 0.2781\n",
      "Epoch 143/1000\n",
      "6211/6250 [============================>.] - ETA: 0s - loss: 0.2217 - mean_absolute_error: 0.2217\n",
      "Epoch 00143: val_loss did not improve from 0.27383\n",
      "6250/6250 [==============================] - 4s 685us/step - loss: 0.2220 - mean_absolute_error: 0.2220 - val_loss: 0.2816 - val_mean_absolute_error: 0.2816\n",
      "Epoch 144/1000\n",
      "6181/6250 [============================>.] - ETA: 0s - loss: 0.2220 - mean_absolute_error: 0.2220\n",
      "Epoch 00144: val_loss did not improve from 0.27383\n",
      "6250/6250 [==============================] - 5s 729us/step - loss: 0.2221 - mean_absolute_error: 0.2221 - val_loss: 0.2802 - val_mean_absolute_error: 0.2802\n",
      "Epoch 145/1000\n",
      "6175/6250 [============================>.] - ETA: 0s - loss: 0.2221 - mean_absolute_error: 0.2221\n",
      "Epoch 00145: val_loss did not improve from 0.27383\n",
      "6250/6250 [==============================] - 4s 676us/step - loss: 0.2220 - mean_absolute_error: 0.2220 - val_loss: 0.2794 - val_mean_absolute_error: 0.2794\n",
      "Epoch 146/1000\n",
      "6177/6250 [============================>.] - ETA: 0s - loss: 0.2225 - mean_absolute_error: 0.2225\n",
      "Epoch 00146: val_loss did not improve from 0.27383\n",
      "6250/6250 [==============================] - 4s 676us/step - loss: 0.2225 - mean_absolute_error: 0.2225 - val_loss: 0.2786 - val_mean_absolute_error: 0.2786\n",
      "Epoch 147/1000\n",
      "6171/6250 [============================>.] - ETA: 0s - loss: 0.2212 - mean_absolute_error: 0.2212\n",
      "Epoch 00147: val_loss did not improve from 0.27383\n",
      "6250/6250 [==============================] - 4s 679us/step - loss: 0.2216 - mean_absolute_error: 0.2216 - val_loss: 0.2824 - val_mean_absolute_error: 0.2824\n",
      "Epoch 148/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6247/6250 [============================>.] - ETA: 0s - loss: 0.2221 - mean_absolute_error: 0.2221\n",
      "Epoch 00148: val_loss did not improve from 0.27383\n",
      "6250/6250 [==============================] - 5s 734us/step - loss: 0.2221 - mean_absolute_error: 0.2221 - val_loss: 0.2805 - val_mean_absolute_error: 0.2805\n",
      "Epoch 149/1000\n",
      "6246/6250 [============================>.] - ETA: 0s - loss: 0.2203 - mean_absolute_error: 0.2203\n",
      "Epoch 00149: val_loss did not improve from 0.27383\n",
      "6250/6250 [==============================] - 4s 678us/step - loss: 0.2204 - mean_absolute_error: 0.2204 - val_loss: 0.2819 - val_mean_absolute_error: 0.2819\n",
      "Epoch 150/1000\n",
      "6249/6250 [============================>.] - ETA: 0s - loss: 0.2220 - mean_absolute_error: 0.2220\n",
      "Epoch 00150: val_loss did not improve from 0.27383\n",
      "6250/6250 [==============================] - 4s 681us/step - loss: 0.2220 - mean_absolute_error: 0.2220 - val_loss: 0.2764 - val_mean_absolute_error: 0.2764\n",
      "Epoch 151/1000\n",
      "6197/6250 [============================>.] - ETA: 0s - loss: 0.2201 - mean_absolute_error: 0.2201\n",
      "Epoch 00151: val_loss did not improve from 0.27383\n",
      "6250/6250 [==============================] - 4s 709us/step - loss: 0.2207 - mean_absolute_error: 0.2207 - val_loss: 0.2762 - val_mean_absolute_error: 0.2762\n",
      "Epoch 152/1000\n",
      "6189/6250 [============================>.] - ETA: 0s - loss: 0.2211 - mean_absolute_error: 0.2211\n",
      "Epoch 00152: val_loss did not improve from 0.27383\n",
      "6250/6250 [==============================] - 4s 693us/step - loss: 0.2211 - mean_absolute_error: 0.2211 - val_loss: 0.2739 - val_mean_absolute_error: 0.2739\n",
      "Epoch 153/1000\n",
      "6174/6250 [============================>.] - ETA: 0s - loss: 0.2206 - mean_absolute_error: 0.2206\n",
      "Epoch 00153: val_loss did not improve from 0.27383\n",
      "6250/6250 [==============================] - 4s 678us/step - loss: 0.2199 - mean_absolute_error: 0.2199 - val_loss: 0.2746 - val_mean_absolute_error: 0.2746\n",
      "Epoch 154/1000\n",
      "6224/6250 [============================>.] - ETA: 0s - loss: 0.2210 - mean_absolute_error: 0.2210\n",
      "Epoch 00154: val_loss did not improve from 0.27383\n",
      "6250/6250 [==============================] - 4s 679us/step - loss: 0.2211 - mean_absolute_error: 0.2211 - val_loss: 0.2774 - val_mean_absolute_error: 0.2774\n",
      "Epoch 155/1000\n",
      "6168/6250 [============================>.] - ETA: 0s - loss: 0.2201 - mean_absolute_error: 0.2201\n",
      "Epoch 00155: val_loss did not improve from 0.27383\n",
      "6250/6250 [==============================] - 5s 729us/step - loss: 0.2198 - mean_absolute_error: 0.2198 - val_loss: 0.2804 - val_mean_absolute_error: 0.2804\n",
      "Epoch 156/1000\n",
      "6176/6250 [============================>.] - ETA: 0s - loss: 0.2204 - mean_absolute_error: 0.2204\n",
      "Epoch 00156: val_loss did not improve from 0.27383\n",
      "6250/6250 [==============================] - 4s 685us/step - loss: 0.2210 - mean_absolute_error: 0.2210 - val_loss: 0.2760 - val_mean_absolute_error: 0.2760\n",
      "Epoch 157/1000\n",
      "6237/6250 [============================>.] - ETA: 0s - loss: 0.2208 - mean_absolute_error: 0.2208\n",
      "Epoch 00157: val_loss did not improve from 0.27383\n",
      "6250/6250 [==============================] - 4s 681us/step - loss: 0.2205 - mean_absolute_error: 0.2205 - val_loss: 0.2761 - val_mean_absolute_error: 0.2761\n",
      "Epoch 158/1000\n",
      "6217/6250 [============================>.] - ETA: 0s - loss: 0.2204 - mean_absolute_error: 0.2204\n",
      "Epoch 00158: val_loss did not improve from 0.27383\n",
      "6250/6250 [==============================] - 4s 700us/step - loss: 0.2207 - mean_absolute_error: 0.2207 - val_loss: 0.2788 - val_mean_absolute_error: 0.2788\n",
      "Epoch 159/1000\n",
      "6223/6250 [============================>.] - ETA: 0s - loss: 0.2205 - mean_absolute_error: 0.2205\n",
      "Epoch 00159: val_loss did not improve from 0.27383\n",
      "6250/6250 [==============================] - 5s 752us/step - loss: 0.2204 - mean_absolute_error: 0.2204 - val_loss: 0.2830 - val_mean_absolute_error: 0.2830\n",
      "Epoch 160/1000\n",
      "6209/6250 [============================>.] - ETA: 0s - loss: 0.2203 - mean_absolute_error: 0.2203\n",
      "Epoch 00160: val_loss did not improve from 0.27383\n",
      "6250/6250 [==============================] - 4s 675us/step - loss: 0.2199 - mean_absolute_error: 0.2199 - val_loss: 0.2743 - val_mean_absolute_error: 0.2743\n",
      "Epoch 161/1000\n",
      "6218/6250 [============================>.] - ETA: 0s - loss: 0.2205 - mean_absolute_error: 0.2205\n",
      "Epoch 00161: val_loss did not improve from 0.27383\n",
      "6250/6250 [==============================] - 4s 680us/step - loss: 0.2201 - mean_absolute_error: 0.2201 - val_loss: 0.2743 - val_mean_absolute_error: 0.2743\n",
      "Epoch 162/1000\n",
      "6243/6250 [============================>.] - ETA: 0s - loss: 0.2195 - mean_absolute_error: 0.2195\n",
      "Epoch 00162: val_loss improved from 0.27383 to 0.27282, saving model to model_dl.h5\n",
      "6250/6250 [==============================] - 4s 704us/step - loss: 0.2196 - mean_absolute_error: 0.2196 - val_loss: 0.2728 - val_mean_absolute_error: 0.2728\n",
      "Epoch 163/1000\n",
      "6246/6250 [============================>.] - ETA: 0s - loss: 0.2191 - mean_absolute_error: 0.2191\n",
      "Epoch 00163: val_loss improved from 0.27282 to 0.27231, saving model to model_dl.h5\n",
      "6250/6250 [==============================] - 4s 700us/step - loss: 0.2191 - mean_absolute_error: 0.2191 - val_loss: 0.2723 - val_mean_absolute_error: 0.2723\n",
      "Epoch 164/1000\n",
      "6241/6250 [============================>.] - ETA: 0s - loss: 0.2197 - mean_absolute_error: 0.2197\n",
      "Epoch 00164: val_loss did not improve from 0.27231\n",
      "6250/6250 [==============================] - 4s 678us/step - loss: 0.2197 - mean_absolute_error: 0.2197 - val_loss: 0.2735 - val_mean_absolute_error: 0.2735\n",
      "Epoch 165/1000\n",
      "6239/6250 [============================>.] - ETA: 0s - loss: 0.2181 - mean_absolute_error: 0.2181\n",
      "Epoch 00165: val_loss did not improve from 0.27231\n",
      "6250/6250 [==============================] - 4s 679us/step - loss: 0.2180 - mean_absolute_error: 0.2180 - val_loss: 0.2764 - val_mean_absolute_error: 0.2764\n",
      "Epoch 166/1000\n",
      "6247/6250 [============================>.] - ETA: 0s - loss: 0.2181 - mean_absolute_error: 0.2181\n",
      "Epoch 00166: val_loss improved from 0.27231 to 0.27186, saving model to model_dl.h5\n",
      "6250/6250 [==============================] - 5s 730us/step - loss: 0.2181 - mean_absolute_error: 0.2181 - val_loss: 0.2719 - val_mean_absolute_error: 0.2719\n",
      "Epoch 167/1000\n",
      "6244/6250 [============================>.] - ETA: 0s - loss: 0.2187 - mean_absolute_error: 0.2187\n",
      "Epoch 00167: val_loss improved from 0.27186 to 0.27140, saving model to model_dl.h5\n",
      "6250/6250 [==============================] - 4s 693us/step - loss: 0.2188 - mean_absolute_error: 0.2188 - val_loss: 0.2714 - val_mean_absolute_error: 0.2714\n",
      "Epoch 168/1000\n",
      "6172/6250 [============================>.] - ETA: 0s - loss: 0.2193 - mean_absolute_error: 0.2193\n",
      "Epoch 00168: val_loss did not improve from 0.27140\n",
      "6250/6250 [==============================] - 4s 687us/step - loss: 0.2192 - mean_absolute_error: 0.2192 - val_loss: 0.2782 - val_mean_absolute_error: 0.2782\n",
      "Epoch 169/1000\n",
      "6185/6250 [============================>.] - ETA: 0s - loss: 0.2167 - mean_absolute_error: 0.2167\n",
      "Epoch 00169: val_loss did not improve from 0.27140\n",
      "6250/6250 [==============================] - 4s 677us/step - loss: 0.2180 - mean_absolute_error: 0.2180 - val_loss: 0.2753 - val_mean_absolute_error: 0.2753\n",
      "Epoch 170/1000\n",
      "6244/6250 [============================>.] - ETA: 0s - loss: 0.2189 - mean_absolute_error: 0.2189\n",
      "Epoch 00170: val_loss did not improve from 0.27140\n",
      "6250/6250 [==============================] - 5s 754us/step - loss: 0.2189 - mean_absolute_error: 0.2189 - val_loss: 0.2751 - val_mean_absolute_error: 0.2751\n",
      "Epoch 171/1000\n",
      "6181/6250 [============================>.] - ETA: 0s - loss: 0.2185 - mean_absolute_error: 0.2185\n",
      "Epoch 00171: val_loss did not improve from 0.27140\n",
      "6250/6250 [==============================] - 4s 678us/step - loss: 0.2183 - mean_absolute_error: 0.2183 - val_loss: 0.2739 - val_mean_absolute_error: 0.2739\n",
      "Epoch 172/1000\n",
      "6190/6250 [============================>.] - ETA: 0s - loss: 0.2178 - mean_absolute_error: 0.2178\n",
      "Epoch 00172: val_loss did not improve from 0.27140\n",
      "6250/6250 [==============================] - 4s 678us/step - loss: 0.2181 - mean_absolute_error: 0.2181 - val_loss: 0.2715 - val_mean_absolute_error: 0.2715\n",
      "Epoch 173/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6244/6250 [============================>.] - ETA: 0s - loss: 0.2180 - mean_absolute_error: 0.2180\n",
      "Epoch 00173: val_loss did not improve from 0.27140\n",
      "6250/6250 [==============================] - 4s 700us/step - loss: 0.2186 - mean_absolute_error: 0.2186 - val_loss: 0.2738 - val_mean_absolute_error: 0.2738\n",
      "Epoch 174/1000\n",
      "6239/6250 [============================>.] - ETA: 0s - loss: 0.2183 - mean_absolute_error: 0.2183\n",
      "Epoch 00174: val_loss did not improve from 0.27140\n",
      "6250/6250 [==============================] - 4s 699us/step - loss: 0.2182 - mean_absolute_error: 0.2182 - val_loss: 0.2761 - val_mean_absolute_error: 0.2761\n",
      "Epoch 175/1000\n",
      "6202/6250 [============================>.] - ETA: 0s - loss: 0.2165 - mean_absolute_error: 0.2165\n",
      "Epoch 00175: val_loss did not improve from 0.27140\n",
      "6250/6250 [==============================] - 4s 682us/step - loss: 0.2173 - mean_absolute_error: 0.2173 - val_loss: 0.2743 - val_mean_absolute_error: 0.2743\n",
      "Epoch 176/1000\n",
      "6232/6250 [============================>.] - ETA: 0s - loss: 0.2184 - mean_absolute_error: 0.2184\n",
      "Epoch 00176: val_loss did not improve from 0.27140\n",
      "6250/6250 [==============================] - 4s 678us/step - loss: 0.2183 - mean_absolute_error: 0.2183 - val_loss: 0.2736 - val_mean_absolute_error: 0.2736\n",
      "Epoch 177/1000\n",
      "6203/6250 [============================>.] - ETA: 0s - loss: 0.2165 - mean_absolute_error: 0.2165\n",
      "Epoch 00177: val_loss did not improve from 0.27140\n",
      "6250/6250 [==============================] - 5s 724us/step - loss: 0.2172 - mean_absolute_error: 0.2172 - val_loss: 0.2728 - val_mean_absolute_error: 0.2728\n",
      "Epoch 178/1000\n",
      "6216/6250 [============================>.] - ETA: 0s - loss: 0.2162 - mean_absolute_error: 0.2162\n",
      "Epoch 00178: val_loss improved from 0.27140 to 0.27090, saving model to model_dl.h5\n",
      "6250/6250 [==============================] - 4s 682us/step - loss: 0.2163 - mean_absolute_error: 0.2163 - val_loss: 0.2709 - val_mean_absolute_error: 0.2709\n",
      "Epoch 179/1000\n",
      "6224/6250 [============================>.] - ETA: 0s - loss: 0.2165 - mean_absolute_error: 0.2165\n",
      "Epoch 00179: val_loss did not improve from 0.27090\n",
      "6250/6250 [==============================] - 4s 680us/step - loss: 0.2171 - mean_absolute_error: 0.2171 - val_loss: 0.2721 - val_mean_absolute_error: 0.2721\n",
      "Epoch 180/1000\n",
      "6249/6250 [============================>.] - ETA: 0s - loss: 0.2160 - mean_absolute_error: 0.2160\n",
      "Epoch 00180: val_loss improved from 0.27090 to 0.26982, saving model to model_dl.h5\n",
      "6250/6250 [==============================] - 4s 681us/step - loss: 0.2162 - mean_absolute_error: 0.2162 - val_loss: 0.2698 - val_mean_absolute_error: 0.2698\n",
      "Epoch 181/1000\n",
      "6188/6250 [============================>.] - ETA: 0s - loss: 0.2159 - mean_absolute_error: 0.2159\n",
      "Epoch 00181: val_loss did not improve from 0.26982\n",
      "6250/6250 [==============================] - 5s 855us/step - loss: 0.2162 - mean_absolute_error: 0.2162 - val_loss: 0.2748 - val_mean_absolute_error: 0.2748\n",
      "Epoch 182/1000\n",
      "6234/6250 [============================>.] - ETA: 0s - loss: 0.2165 - mean_absolute_error: 0.2165\n",
      "Epoch 00182: val_loss did not improve from 0.26982\n",
      "6250/6250 [==============================] - 4s 710us/step - loss: 0.2163 - mean_absolute_error: 0.2163 - val_loss: 0.2704 - val_mean_absolute_error: 0.2704\n",
      "Epoch 183/1000\n",
      "6203/6250 [============================>.] - ETA: 0s - loss: 0.2167 - mean_absolute_error: 0.2167\n",
      "Epoch 00183: val_loss did not improve from 0.26982\n",
      "6250/6250 [==============================] - 4s 682us/step - loss: 0.2167 - mean_absolute_error: 0.2167 - val_loss: 0.2709 - val_mean_absolute_error: 0.2709\n",
      "Epoch 184/1000\n",
      "6178/6250 [============================>.] - ETA: 0s - loss: 0.2177 - mean_absolute_error: 0.2177\n",
      "Epoch 00184: val_loss did not improve from 0.26982\n",
      "6250/6250 [==============================] - 5s 722us/step - loss: 0.2173 - mean_absolute_error: 0.2173 - val_loss: 0.2713 - val_mean_absolute_error: 0.2713\n",
      "Epoch 185/1000\n",
      "6232/6250 [============================>.] - ETA: 0s - loss: 0.2163 - mean_absolute_error: 0.2163\n",
      "Epoch 00185: val_loss did not improve from 0.26982\n",
      "6250/6250 [==============================] - 4s 680us/step - loss: 0.2161 - mean_absolute_error: 0.2161 - val_loss: 0.2734 - val_mean_absolute_error: 0.2734\n",
      "Epoch 186/1000\n",
      "6241/6250 [============================>.] - ETA: 0s - loss: 0.2161 - mean_absolute_error: 0.2161\n",
      "Epoch 00186: val_loss improved from 0.26982 to 0.26784, saving model to model_dl.h5\n",
      "6250/6250 [==============================] - 4s 684us/step - loss: 0.2162 - mean_absolute_error: 0.2162 - val_loss: 0.2678 - val_mean_absolute_error: 0.2678\n",
      "Epoch 187/1000\n",
      "6238/6250 [============================>.] - ETA: 0s - loss: 0.2153 - mean_absolute_error: 0.2153\n",
      "Epoch 00187: val_loss did not improve from 0.26784\n",
      "6250/6250 [==============================] - 4s 686us/step - loss: 0.2154 - mean_absolute_error: 0.2154 - val_loss: 0.2689 - val_mean_absolute_error: 0.2689\n",
      "Epoch 188/1000\n",
      "6211/6250 [============================>.] - ETA: 0s - loss: 0.2157 - mean_absolute_error: 0.2157\n",
      "Epoch 00188: val_loss did not improve from 0.26784\n",
      "6250/6250 [==============================] - 5s 730us/step - loss: 0.2156 - mean_absolute_error: 0.2156 - val_loss: 0.2700 - val_mean_absolute_error: 0.2700\n",
      "Epoch 189/1000\n",
      "6175/6250 [============================>.] - ETA: 0s - loss: 0.2152 - mean_absolute_error: 0.2152\n",
      "Epoch 00189: val_loss did not improve from 0.26784\n",
      "6250/6250 [==============================] - 4s 678us/step - loss: 0.2156 - mean_absolute_error: 0.2156 - val_loss: 0.2742 - val_mean_absolute_error: 0.2742\n",
      "Epoch 190/1000\n",
      "6174/6250 [============================>.] - ETA: 0s - loss: 0.2165 - mean_absolute_error: 0.2165\n",
      "Epoch 00190: val_loss did not improve from 0.26784\n",
      "6250/6250 [==============================] - 4s 678us/step - loss: 0.2163 - mean_absolute_error: 0.2163 - val_loss: 0.2702 - val_mean_absolute_error: 0.2702\n",
      "Epoch 191/1000\n",
      "6174/6250 [============================>.] - ETA: 0s - loss: 0.2156 - mean_absolute_error: 0.2156\n",
      "Epoch 00191: val_loss improved from 0.26784 to 0.26644, saving model to model_dl.h5\n",
      "6250/6250 [==============================] - 4s 681us/step - loss: 0.2159 - mean_absolute_error: 0.2159 - val_loss: 0.2664 - val_mean_absolute_error: 0.2664\n",
      "Epoch 192/1000\n",
      "6201/6250 [============================>.] - ETA: 0s - loss: 0.2155 - mean_absolute_error: 0.2155\n",
      "Epoch 00192: val_loss improved from 0.26644 to 0.26607, saving model to model_dl.h5\n",
      "6250/6250 [==============================] - 5s 734us/step - loss: 0.2151 - mean_absolute_error: 0.2151 - val_loss: 0.2661 - val_mean_absolute_error: 0.2661\n",
      "Epoch 193/1000\n",
      "6206/6250 [============================>.] - ETA: 0s - loss: 0.2156 - mean_absolute_error: 0.2156\n",
      "Epoch 00193: val_loss did not improve from 0.26607\n",
      "6250/6250 [==============================] - 4s 678us/step - loss: 0.2156 - mean_absolute_error: 0.2156 - val_loss: 0.2661 - val_mean_absolute_error: 0.2661\n",
      "Epoch 194/1000\n",
      "6194/6250 [============================>.] - ETA: 0s - loss: 0.2154 - mean_absolute_error: 0.2154\n",
      "Epoch 00194: val_loss did not improve from 0.26607\n",
      "6250/6250 [==============================] - 4s 686us/step - loss: 0.2156 - mean_absolute_error: 0.2156 - val_loss: 0.2693 - val_mean_absolute_error: 0.2693\n",
      "Epoch 195/1000\n",
      "6201/6250 [============================>.] - ETA: 0s - loss: 0.2145 - mean_absolute_error: 0.2145\n",
      "Epoch 00195: val_loss did not improve from 0.26607\n",
      "6250/6250 [==============================] - 4s 719us/step - loss: 0.2149 - mean_absolute_error: 0.2149 - val_loss: 0.2750 - val_mean_absolute_error: 0.2750\n",
      "Epoch 196/1000\n",
      "6219/6250 [============================>.] - ETA: 0s - loss: 0.2145 - mean_absolute_error: 0.2145\n",
      "Epoch 00196: val_loss did not improve from 0.26607\n",
      "6250/6250 [==============================] - 4s 684us/step - loss: 0.2147 - mean_absolute_error: 0.2147 - val_loss: 0.2752 - val_mean_absolute_error: 0.2752\n",
      "Epoch 197/1000\n",
      "6198/6250 [============================>.] - ETA: 0s - loss: 0.2134 - mean_absolute_error: 0.2134\n",
      "Epoch 00197: val_loss did not improve from 0.26607\n",
      "6250/6250 [==============================] - 4s 675us/step - loss: 0.2137 - mean_absolute_error: 0.2137 - val_loss: 0.2750 - val_mean_absolute_error: 0.2750\n",
      "Epoch 198/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6205/6250 [============================>.] - ETA: 0s - loss: 0.2156 - mean_absolute_error: 0.2156\n",
      "Epoch 00198: val_loss did not improve from 0.26607\n",
      "6250/6250 [==============================] - 4s 684us/step - loss: 0.2151 - mean_absolute_error: 0.2151 - val_loss: 0.2710 - val_mean_absolute_error: 0.2710\n",
      "Epoch 199/1000\n",
      "6217/6250 [============================>.] - ETA: 0s - loss: 0.2151 - mean_absolute_error: 0.2151\n",
      "Epoch 00199: val_loss did not improve from 0.26607\n",
      "6250/6250 [==============================] - 5s 722us/step - loss: 0.2146 - mean_absolute_error: 0.2146 - val_loss: 0.2685 - val_mean_absolute_error: 0.2685\n",
      "Epoch 200/1000\n",
      "6238/6250 [============================>.] - ETA: 0s - loss: 0.2137 - mean_absolute_error: 0.2137\n",
      "Epoch 00200: val_loss did not improve from 0.26607\n",
      "6250/6250 [==============================] - 4s 679us/step - loss: 0.2137 - mean_absolute_error: 0.2137 - val_loss: 0.2738 - val_mean_absolute_error: 0.2738\n",
      "Epoch 201/1000\n",
      "6183/6250 [============================>.] - ETA: 0s - loss: 0.2140 - mean_absolute_error: 0.2140\n",
      "Epoch 00201: val_loss did not improve from 0.26607\n",
      "6250/6250 [==============================] - 4s 675us/step - loss: 0.2143 - mean_absolute_error: 0.2143 - val_loss: 0.2759 - val_mean_absolute_error: 0.2759\n",
      "Epoch 202/1000\n",
      "6236/6250 [============================>.] - ETA: 0s - loss: 0.2139 - mean_absolute_error: 0.2139\n",
      "Epoch 00202: val_loss did not improve from 0.26607\n",
      "6250/6250 [==============================] - 4s 679us/step - loss: 0.2137 - mean_absolute_error: 0.2137 - val_loss: 0.2697 - val_mean_absolute_error: 0.2697\n",
      "Epoch 203/1000\n",
      "6192/6250 [============================>.] - ETA: 0s - loss: 0.2138 - mean_absolute_error: 0.2138\n",
      "Epoch 00203: val_loss did not improve from 0.26607\n",
      "6250/6250 [==============================] - 5s 728us/step - loss: 0.2144 - mean_absolute_error: 0.2144 - val_loss: 0.2694 - val_mean_absolute_error: 0.2694\n",
      "Epoch 204/1000\n",
      "6173/6250 [============================>.] - ETA: 0s - loss: 0.2137 - mean_absolute_error: 0.2137\n",
      "Epoch 00204: val_loss did not improve from 0.26607\n",
      "6250/6250 [==============================] - 4s 676us/step - loss: 0.2136 - mean_absolute_error: 0.2136 - val_loss: 0.2672 - val_mean_absolute_error: 0.2672\n",
      "Epoch 205/1000\n",
      "6169/6250 [============================>.] - ETA: 0s - loss: 0.2129 - mean_absolute_error: 0.2129\n",
      "Epoch 00205: val_loss improved from 0.26607 to 0.26563, saving model to model_dl.h5\n",
      "6250/6250 [==============================] - 4s 683us/step - loss: 0.2133 - mean_absolute_error: 0.2133 - val_loss: 0.2656 - val_mean_absolute_error: 0.2656\n",
      "Epoch 206/1000\n",
      "6228/6250 [============================>.] - ETA: 0s - loss: 0.2141 - mean_absolute_error: 0.2141\n",
      "Epoch 00206: val_loss did not improve from 0.26563\n",
      "6250/6250 [==============================] - 5s 765us/step - loss: 0.2138 - mean_absolute_error: 0.2138 - val_loss: 0.2687 - val_mean_absolute_error: 0.2687\n",
      "Epoch 207/1000\n",
      "6232/6250 [============================>.] - ETA: 0s - loss: 0.2126 - mean_absolute_error: 0.2126\n",
      "Epoch 00207: val_loss did not improve from 0.26563\n",
      "6250/6250 [==============================] - 4s 690us/step - loss: 0.2132 - mean_absolute_error: 0.2132 - val_loss: 0.2708 - val_mean_absolute_error: 0.2708\n",
      "Epoch 208/1000\n",
      "6215/6250 [============================>.] - ETA: 0s - loss: 0.2142 - mean_absolute_error: 0.2142\n",
      "Epoch 00208: val_loss did not improve from 0.26563\n",
      "6250/6250 [==============================] - 4s 675us/step - loss: 0.2138 - mean_absolute_error: 0.2138 - val_loss: 0.2670 - val_mean_absolute_error: 0.2670\n",
      "Epoch 209/1000\n",
      "6210/6250 [============================>.] - ETA: 0s - loss: 0.2132 - mean_absolute_error: 0.2132\n",
      "Epoch 00209: val_loss did not improve from 0.26563\n",
      "6250/6250 [==============================] - 4s 675us/step - loss: 0.2132 - mean_absolute_error: 0.2132 - val_loss: 0.2684 - val_mean_absolute_error: 0.2684\n",
      "Epoch 210/1000\n",
      "6226/6250 [============================>.] - ETA: 0s - loss: 0.2130 - mean_absolute_error: 0.2130\n",
      "Epoch 00210: val_loss did not improve from 0.26563\n",
      "6250/6250 [==============================] - 5s 724us/step - loss: 0.2128 - mean_absolute_error: 0.2128 - val_loss: 0.2692 - val_mean_absolute_error: 0.2692\n",
      "Epoch 211/1000\n",
      "6240/6250 [============================>.] - ETA: 0s - loss: 0.2124 - mean_absolute_error: 0.2124\n",
      "Epoch 00211: val_loss did not improve from 0.26563\n",
      "6250/6250 [==============================] - 4s 680us/step - loss: 0.2126 - mean_absolute_error: 0.2126 - val_loss: 0.2688 - val_mean_absolute_error: 0.2688\n",
      "Epoch 212/1000\n",
      "6228/6250 [============================>.] - ETA: 0s - loss: 0.2132 - mean_absolute_error: 0.2132\n",
      "Epoch 00212: val_loss did not improve from 0.26563\n",
      "6250/6250 [==============================] - 4s 714us/step - loss: 0.2130 - mean_absolute_error: 0.2130 - val_loss: 0.2660 - val_mean_absolute_error: 0.2660\n",
      "Epoch 213/1000\n",
      "6190/6250 [============================>.] - ETA: 0s - loss: 0.2120 - mean_absolute_error: 0.2120\n",
      "Epoch 00213: val_loss did not improve from 0.26563\n",
      "6250/6250 [==============================] - 4s 679us/step - loss: 0.2117 - mean_absolute_error: 0.2117 - val_loss: 0.2718 - val_mean_absolute_error: 0.2718\n",
      "Epoch 214/1000\n",
      "6187/6250 [============================>.] - ETA: 0s - loss: 0.2132 - mean_absolute_error: 0.2132\n",
      "Epoch 00214: val_loss did not improve from 0.26563\n",
      "6250/6250 [==============================] - 5s 724us/step - loss: 0.2134 - mean_absolute_error: 0.2134 - val_loss: 0.2692 - val_mean_absolute_error: 0.2692\n",
      "Epoch 215/1000\n",
      "6166/6250 [============================>.] - ETA: 0s - loss: 0.2121 - mean_absolute_error: 0.2121\n",
      "Epoch 00215: val_loss improved from 0.26563 to 0.26526, saving model to model_dl.h5\n",
      "6250/6250 [==============================] - 4s 680us/step - loss: 0.2120 - mean_absolute_error: 0.2120 - val_loss: 0.2653 - val_mean_absolute_error: 0.2653\n",
      "Epoch 216/1000\n",
      "6167/6250 [============================>.] - ETA: 0s - loss: 0.2120 - mean_absolute_error: 0.2120\n",
      "Epoch 00216: val_loss did not improve from 0.26526\n",
      "6250/6250 [==============================] - 4s 676us/step - loss: 0.2127 - mean_absolute_error: 0.2127 - val_loss: 0.2660 - val_mean_absolute_error: 0.2660\n",
      "Epoch 217/1000\n",
      "6190/6250 [============================>.] - ETA: 0s - loss: 0.2120 - mean_absolute_error: 0.2120\n",
      "Epoch 00217: val_loss did not improve from 0.26526\n",
      "6250/6250 [==============================] - 4s 703us/step - loss: 0.2114 - mean_absolute_error: 0.2114 - val_loss: 0.2717 - val_mean_absolute_error: 0.2717\n",
      "Epoch 218/1000\n",
      "6164/6250 [============================>.] - ETA: 0s - loss: 0.2122 - mean_absolute_error: 0.2122\n",
      "Epoch 00218: val_loss did not improve from 0.26526\n",
      "6250/6250 [==============================] - 4s 696us/step - loss: 0.2118 - mean_absolute_error: 0.2118 - val_loss: 0.2674 - val_mean_absolute_error: 0.2674\n",
      "Epoch 219/1000\n",
      "6233/6250 [============================>.] - ETA: 0s - loss: 0.2112 - mean_absolute_error: 0.2112\n",
      "Epoch 00219: val_loss improved from 0.26526 to 0.26417, saving model to model_dl.h5\n",
      "6250/6250 [==============================] - 4s 685us/step - loss: 0.2113 - mean_absolute_error: 0.2113 - val_loss: 0.2642 - val_mean_absolute_error: 0.2642\n",
      "Epoch 220/1000\n",
      "6185/6250 [============================>.] - ETA: 0s - loss: 0.2115 - mean_absolute_error: 0.2115\n",
      "Epoch 00220: val_loss did not improve from 0.26417\n",
      "6250/6250 [==============================] - 4s 678us/step - loss: 0.2112 - mean_absolute_error: 0.2112 - val_loss: 0.2660 - val_mean_absolute_error: 0.2660\n",
      "Epoch 221/1000\n",
      "6174/6250 [============================>.] - ETA: 0s - loss: 0.2121 - mean_absolute_error: 0.2121\n",
      "Epoch 00221: val_loss did not improve from 0.26417\n",
      "6250/6250 [==============================] - 5s 725us/step - loss: 0.2114 - mean_absolute_error: 0.2114 - val_loss: 0.2668 - val_mean_absolute_error: 0.2668\n",
      "Epoch 222/1000\n",
      "6231/6250 [============================>.] - ETA: 0s - loss: 0.2116 - mean_absolute_error: 0.2116\n",
      "Epoch 00222: val_loss did not improve from 0.26417\n",
      "6250/6250 [==============================] - 4s 688us/step - loss: 0.2114 - mean_absolute_error: 0.2114 - val_loss: 0.2717 - val_mean_absolute_error: 0.2717\n",
      "Epoch 223/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6169/6250 [============================>.] - ETA: 0s - loss: 0.2109 - mean_absolute_error: 0.2109\n",
      "Epoch 00223: val_loss did not improve from 0.26417\n",
      "6250/6250 [==============================] - 4s 677us/step - loss: 0.2110 - mean_absolute_error: 0.2110 - val_loss: 0.2734 - val_mean_absolute_error: 0.2734\n",
      "Epoch 224/1000\n",
      "6209/6250 [============================>.] - ETA: 0s - loss: 0.2119 - mean_absolute_error: 0.2119\n",
      "Epoch 00224: val_loss did not improve from 0.26417\n",
      "6250/6250 [==============================] - 4s 684us/step - loss: 0.2116 - mean_absolute_error: 0.2116 - val_loss: 0.2719 - val_mean_absolute_error: 0.2719\n",
      "Epoch 225/1000\n",
      "6175/6250 [============================>.] - ETA: 0s - loss: 0.2122 - mean_absolute_error: 0.2122\n",
      "Epoch 00225: val_loss did not improve from 0.26417\n",
      "6250/6250 [==============================] - 5s 727us/step - loss: 0.2119 - mean_absolute_error: 0.2119 - val_loss: 0.2660 - val_mean_absolute_error: 0.2660\n",
      "Epoch 226/1000\n",
      "6236/6250 [============================>.] - ETA: 0s - loss: 0.2109 - mean_absolute_error: 0.2109\n",
      "Epoch 00226: val_loss did not improve from 0.26417\n",
      "6250/6250 [==============================] - 4s 682us/step - loss: 0.2108 - mean_absolute_error: 0.2108 - val_loss: 0.2644 - val_mean_absolute_error: 0.2644\n",
      "Epoch 227/1000\n",
      "6165/6250 [============================>.] - ETA: 0s - loss: 0.2111 - mean_absolute_error: 0.2111\n",
      "Epoch 00227: val_loss did not improve from 0.26417\n",
      "6250/6250 [==============================] - 4s 675us/step - loss: 0.2105 - mean_absolute_error: 0.2105 - val_loss: 0.2657 - val_mean_absolute_error: 0.2657\n",
      "Epoch 228/1000\n",
      "6214/6250 [============================>.] - ETA: 0s - loss: 0.2104 - mean_absolute_error: 0.2104\n",
      "Epoch 00228: val_loss did not improve from 0.26417\n",
      "6250/6250 [==============================] - 4s 699us/step - loss: 0.2106 - mean_absolute_error: 0.2106 - val_loss: 0.2646 - val_mean_absolute_error: 0.2646\n",
      "Epoch 229/1000\n",
      "6184/6250 [============================>.] - ETA: 0s - loss: 0.2098 - mean_absolute_error: 0.2098\n",
      "Epoch 00229: val_loss did not improve from 0.26417\n",
      "6250/6250 [==============================] - 5s 723us/step - loss: 0.2101 - mean_absolute_error: 0.2101 - val_loss: 0.2730 - val_mean_absolute_error: 0.2730\n",
      "Epoch 230/1000\n",
      "6210/6250 [============================>.] - ETA: 0s - loss: 0.2106 - mean_absolute_error: 0.2106\n",
      "Epoch 00230: val_loss did not improve from 0.26417\n",
      "6250/6250 [==============================] - 4s 674us/step - loss: 0.2105 - mean_absolute_error: 0.2105 - val_loss: 0.2678 - val_mean_absolute_error: 0.2678\n",
      "Epoch 231/1000\n",
      "6187/6250 [============================>.] - ETA: 0s - loss: 0.2091 - mean_absolute_error: 0.2091\n",
      "Epoch 00231: val_loss improved from 0.26417 to 0.26309, saving model to model_dl.h5\n",
      "6250/6250 [==============================] - 4s 685us/step - loss: 0.2105 - mean_absolute_error: 0.2105 - val_loss: 0.2631 - val_mean_absolute_error: 0.2631\n",
      "Epoch 232/1000\n",
      "6235/6250 [============================>.] - ETA: 0s - loss: 0.2100 - mean_absolute_error: 0.2100\n",
      "Epoch 00232: val_loss did not improve from 0.26309\n",
      "6250/6250 [==============================] - 4s 719us/step - loss: 0.2101 - mean_absolute_error: 0.2101 - val_loss: 0.2659 - val_mean_absolute_error: 0.2659\n",
      "Epoch 233/1000\n",
      "6210/6250 [============================>.] - ETA: 0s - loss: 0.2103 - mean_absolute_error: 0.2103\n",
      "Epoch 00233: val_loss did not improve from 0.26309\n",
      "6250/6250 [==============================] - 4s 681us/step - loss: 0.2098 - mean_absolute_error: 0.2098 - val_loss: 0.2659 - val_mean_absolute_error: 0.2659\n",
      "Epoch 234/1000\n",
      "6187/6250 [============================>.] - ETA: 0s - loss: 0.2096 - mean_absolute_error: 0.2096\n",
      "Epoch 00234: val_loss did not improve from 0.26309\n",
      "6250/6250 [==============================] - 4s 675us/step - loss: 0.2094 - mean_absolute_error: 0.2094 - val_loss: 0.2688 - val_mean_absolute_error: 0.2688\n",
      "Epoch 235/1000\n",
      "6167/6250 [============================>.] - ETA: 0s - loss: 0.2105 - mean_absolute_error: 0.2105\n",
      "Epoch 00235: val_loss did not improve from 0.26309\n",
      "6250/6250 [==============================] - 4s 678us/step - loss: 0.2106 - mean_absolute_error: 0.2106 - val_loss: 0.2650 - val_mean_absolute_error: 0.2650\n",
      "Epoch 236/1000\n",
      "6221/6250 [============================>.] - ETA: 0s - loss: 0.2105 - mean_absolute_error: 0.2105\n",
      "Epoch 00236: val_loss did not improve from 0.26309\n",
      "6250/6250 [==============================] - 5s 725us/step - loss: 0.2103 - mean_absolute_error: 0.2103 - val_loss: 0.2648 - val_mean_absolute_error: 0.2648\n",
      "Epoch 237/1000\n",
      "6168/6250 [============================>.] - ETA: 0s - loss: 0.2105 - mean_absolute_error: 0.2105\n",
      "Epoch 00237: val_loss improved from 0.26309 to 0.26144, saving model to model_dl.h5\n",
      "6250/6250 [==============================] - 4s 680us/step - loss: 0.2101 - mean_absolute_error: 0.2101 - val_loss: 0.2614 - val_mean_absolute_error: 0.2614\n",
      "Epoch 238/1000\n",
      "6195/6250 [============================>.] - ETA: 0s - loss: 0.2099 - mean_absolute_error: 0.2099\n",
      "Epoch 00238: val_loss did not improve from 0.26144\n",
      "6250/6250 [==============================] - 4s 679us/step - loss: 0.2096 - mean_absolute_error: 0.2096 - val_loss: 0.2629 - val_mean_absolute_error: 0.2629\n",
      "Epoch 239/1000\n",
      "6249/6250 [============================>.] - ETA: 0s - loss: 0.2089 - mean_absolute_error: 0.2089\n",
      "Epoch 00239: val_loss did not improve from 0.26144\n",
      "6250/6250 [==============================] - 4s 680us/step - loss: 0.2092 - mean_absolute_error: 0.2092 - val_loss: 0.2681 - val_mean_absolute_error: 0.2681\n",
      "Epoch 240/1000\n",
      "6217/6250 [============================>.] - ETA: 0s - loss: 0.2095 - mean_absolute_error: 0.2095\n",
      "Epoch 00240: val_loss did not improve from 0.26144\n",
      "6250/6250 [==============================] - 5s 725us/step - loss: 0.2091 - mean_absolute_error: 0.2091 - val_loss: 0.2648 - val_mean_absolute_error: 0.2648\n",
      "Epoch 241/1000\n",
      "6246/6250 [============================>.] - ETA: 0s - loss: 0.2089 - mean_absolute_error: 0.2089\n",
      "Epoch 00241: val_loss did not improve from 0.26144\n",
      "6250/6250 [==============================] - 4s 678us/step - loss: 0.2088 - mean_absolute_error: 0.2088 - val_loss: 0.2619 - val_mean_absolute_error: 0.2619\n",
      "Epoch 242/1000\n",
      "6178/6250 [============================>.] - ETA: 0s - loss: 0.2089 - mean_absolute_error: 0.2089\n",
      "Epoch 00242: val_loss did not improve from 0.26144\n",
      "6250/6250 [==============================] - 4s 678us/step - loss: 0.2087 - mean_absolute_error: 0.2087 - val_loss: 0.2646 - val_mean_absolute_error: 0.2646\n",
      "Epoch 243/1000\n",
      "6241/6250 [============================>.] - ETA: 0s - loss: 0.2089 - mean_absolute_error: 0.2089\n",
      "Epoch 00243: val_loss did not improve from 0.26144\n",
      "6250/6250 [==============================] - 4s 713us/step - loss: 0.2090 - mean_absolute_error: 0.2090 - val_loss: 0.2637 - val_mean_absolute_error: 0.2637\n",
      "Epoch 244/1000\n",
      "6199/6250 [============================>.] - ETA: 0s - loss: 0.2081 - mean_absolute_error: 0.2081\n",
      "Epoch 00244: val_loss did not improve from 0.26144\n",
      "6250/6250 [==============================] - 4s 684us/step - loss: 0.2087 - mean_absolute_error: 0.2087 - val_loss: 0.2685 - val_mean_absolute_error: 0.2685\n",
      "Epoch 245/1000\n",
      "6208/6250 [============================>.] - ETA: 0s - loss: 0.2081 - mean_absolute_error: 0.2081\n",
      "Epoch 00245: val_loss did not improve from 0.26144\n",
      "6250/6250 [==============================] - 4s 678us/step - loss: 0.2087 - mean_absolute_error: 0.2087 - val_loss: 0.2684 - val_mean_absolute_error: 0.2684\n",
      "Epoch 246/1000\n",
      "6170/6250 [============================>.] - ETA: 0s - loss: 0.2087 - mean_absolute_error: 0.2087\n",
      "Epoch 00246: val_loss did not improve from 0.26144\n",
      "6250/6250 [==============================] - 4s 679us/step - loss: 0.2087 - mean_absolute_error: 0.2087 - val_loss: 0.2667 - val_mean_absolute_error: 0.2667\n",
      "Epoch 247/1000\n",
      "6175/6250 [============================>.] - ETA: 0s - loss: 0.2087 - mean_absolute_error: 0.2087\n",
      "Epoch 00247: val_loss did not improve from 0.26144\n",
      "6250/6250 [==============================] - 5s 729us/step - loss: 0.2090 - mean_absolute_error: 0.2090 - val_loss: 0.2647 - val_mean_absolute_error: 0.2647\n",
      "Epoch 248/1000\n",
      "6239/6250 [============================>.] - ETA: 0s - loss: 0.2087 - mean_absolute_error: 0.2087\n",
      "Epoch 00248: val_loss improved from 0.26144 to 0.26140, saving model to model_dl.h5\n",
      "6250/6250 [==============================] - 4s 687us/step - loss: 0.2085 - mean_absolute_error: 0.2085 - val_loss: 0.2614 - val_mean_absolute_error: 0.2614\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 249/1000\n",
      "6163/6250 [============================>.] - ETA: 0s - loss: 0.2070 - mean_absolute_error: 0.2070\n",
      "Epoch 00249: val_loss did not improve from 0.26140\n",
      "6250/6250 [==============================] - 4s 677us/step - loss: 0.2072 - mean_absolute_error: 0.2072 - val_loss: 0.2663 - val_mean_absolute_error: 0.2663\n",
      "Epoch 250/1000\n",
      "6246/6250 [============================>.] - ETA: 0s - loss: 0.2072 - mean_absolute_error: 0.2072\n",
      "Epoch 00250: val_loss improved from 0.26140 to 0.25966, saving model to model_dl.h5\n",
      "6250/6250 [==============================] - 4s 683us/step - loss: 0.2071 - mean_absolute_error: 0.2071 - val_loss: 0.2597 - val_mean_absolute_error: 0.2597\n",
      "Epoch 251/1000\n",
      "6231/6250 [============================>.] - ETA: 0s - loss: 0.2067 - mean_absolute_error: 0.2067\n",
      "Epoch 00251: val_loss did not improve from 0.25966\n",
      "6250/6250 [==============================] - 5s 724us/step - loss: 0.2068 - mean_absolute_error: 0.2068 - val_loss: 0.2687 - val_mean_absolute_error: 0.2687\n",
      "Epoch 252/1000\n",
      "6204/6250 [============================>.] - ETA: 0s - loss: 0.2082 - mean_absolute_error: 0.2082\n",
      "Epoch 00252: val_loss did not improve from 0.25966\n",
      "6250/6250 [==============================] - 4s 675us/step - loss: 0.2083 - mean_absolute_error: 0.2083 - val_loss: 0.2608 - val_mean_absolute_error: 0.2608\n",
      "Epoch 253/1000\n",
      "6222/6250 [============================>.] - ETA: 0s - loss: 0.2076 - mean_absolute_error: 0.2076\n",
      "Epoch 00253: val_loss did not improve from 0.25966\n",
      "6250/6250 [==============================] - 4s 681us/step - loss: 0.2076 - mean_absolute_error: 0.2076 - val_loss: 0.2630 - val_mean_absolute_error: 0.2630\n",
      "Epoch 254/1000\n",
      "6221/6250 [============================>.] - ETA: 0s - loss: 0.2075 - mean_absolute_error: 0.2075\n",
      "Epoch 00254: val_loss did not improve from 0.25966\n",
      "6250/6250 [==============================] - 4s 697us/step - loss: 0.2070 - mean_absolute_error: 0.2070 - val_loss: 0.2689 - val_mean_absolute_error: 0.2689\n",
      "Epoch 255/1000\n",
      "6189/6250 [============================>.] - ETA: 0s - loss: 0.2066 - mean_absolute_error: 0.2066\n",
      "Epoch 00255: val_loss did not improve from 0.25966\n",
      "6250/6250 [==============================] - 4s 700us/step - loss: 0.2069 - mean_absolute_error: 0.2069 - val_loss: 0.2626 - val_mean_absolute_error: 0.2626\n",
      "Epoch 256/1000\n",
      "6179/6250 [============================>.] - ETA: 0s - loss: 0.2075 - mean_absolute_error: 0.2075\n",
      "Epoch 00256: val_loss did not improve from 0.25966\n",
      "6250/6250 [==============================] - 4s 675us/step - loss: 0.2077 - mean_absolute_error: 0.2077 - val_loss: 0.2602 - val_mean_absolute_error: 0.2602\n",
      "Epoch 257/1000\n",
      "6204/6250 [============================>.] - ETA: 0s - loss: 0.2073 - mean_absolute_error: 0.2073\n",
      "Epoch 00257: val_loss did not improve from 0.25966\n",
      "6250/6250 [==============================] - 4s 675us/step - loss: 0.2070 - mean_absolute_error: 0.2070 - val_loss: 0.2638 - val_mean_absolute_error: 0.2638\n",
      "Epoch 258/1000\n",
      "6206/6250 [============================>.] - ETA: 0s - loss: 0.2070 - mean_absolute_error: 0.2070\n",
      "Epoch 00258: val_loss did not improve from 0.25966\n",
      "6250/6250 [==============================] - 5s 727us/step - loss: 0.2070 - mean_absolute_error: 0.2070 - val_loss: 0.2660 - val_mean_absolute_error: 0.2660\n",
      "Epoch 259/1000\n",
      "6180/6250 [============================>.] - ETA: 0s - loss: 0.2059 - mean_absolute_error: 0.2059\n",
      "Epoch 00259: val_loss did not improve from 0.25966\n",
      "6250/6250 [==============================] - 4s 680us/step - loss: 0.2065 - mean_absolute_error: 0.2065 - val_loss: 0.2624 - val_mean_absolute_error: 0.2624\n",
      "Epoch 260/1000\n",
      "6180/6250 [============================>.] - ETA: 0s - loss: 0.2070 - mean_absolute_error: 0.2070\n",
      "Epoch 00260: val_loss did not improve from 0.25966\n",
      "6250/6250 [==============================] - 4s 679us/step - loss: 0.2072 - mean_absolute_error: 0.2072 - val_loss: 0.2643 - val_mean_absolute_error: 0.2643\n",
      "Epoch 261/1000\n",
      "6174/6250 [============================>.] - ETA: 0s - loss: 0.2068 - mean_absolute_error: 0.2068\n",
      "Epoch 00261: val_loss did not improve from 0.25966\n",
      "6250/6250 [==============================] - 4s 677us/step - loss: 0.2065 - mean_absolute_error: 0.2065 - val_loss: 0.2619 - val_mean_absolute_error: 0.2619\n",
      "Epoch 262/1000\n",
      "6196/6250 [============================>.] - ETA: 0s - loss: 0.2068 - mean_absolute_error: 0.2068\n",
      "Epoch 00262: val_loss did not improve from 0.25966\n",
      "6250/6250 [==============================] - 5s 728us/step - loss: 0.2066 - mean_absolute_error: 0.2066 - val_loss: 0.2615 - val_mean_absolute_error: 0.2615\n",
      "Epoch 263/1000\n",
      "6181/6250 [============================>.] - ETA: 0s - loss: 0.2072 - mean_absolute_error: 0.2072\n",
      "Epoch 00263: val_loss did not improve from 0.25966\n",
      "6250/6250 [==============================] - 4s 675us/step - loss: 0.2068 - mean_absolute_error: 0.2068 - val_loss: 0.2605 - val_mean_absolute_error: 0.2605\n",
      "Epoch 264/1000\n",
      "6173/6250 [============================>.] - ETA: 0s - loss: 0.2071 - mean_absolute_error: 0.2071\n",
      "Epoch 00264: val_loss improved from 0.25966 to 0.25956, saving model to model_dl.h5\n",
      "6250/6250 [==============================] - 4s 679us/step - loss: 0.2069 - mean_absolute_error: 0.2069 - val_loss: 0.2596 - val_mean_absolute_error: 0.2596\n",
      "Epoch 265/1000\n",
      "6169/6250 [============================>.] - ETA: 0s - loss: 0.2057 - mean_absolute_error: 0.2057\n",
      "Epoch 00265: val_loss did not improve from 0.25956\n",
      "6250/6250 [==============================] - 4s 687us/step - loss: 0.2060 - mean_absolute_error: 0.2060 - val_loss: 0.2609 - val_mean_absolute_error: 0.2609\n",
      "Epoch 266/1000\n",
      "6186/6250 [============================>.] - ETA: 0s - loss: 0.2054 - mean_absolute_error: 0.2054\n",
      "Epoch 00266: val_loss did not improve from 0.25956\n",
      "6250/6250 [==============================] - 4s 712us/step - loss: 0.2059 - mean_absolute_error: 0.2059 - val_loss: 0.2669 - val_mean_absolute_error: 0.2669\n",
      "Epoch 267/1000\n",
      "6227/6250 [============================>.] - ETA: 0s - loss: 0.2064 - mean_absolute_error: 0.2064\n",
      "Epoch 00267: val_loss did not improve from 0.25956\n",
      "6250/6250 [==============================] - 4s 681us/step - loss: 0.2061 - mean_absolute_error: 0.2061 - val_loss: 0.2615 - val_mean_absolute_error: 0.2615\n",
      "Epoch 268/1000\n",
      "6243/6250 [============================>.] - ETA: 0s - loss: 0.2057 - mean_absolute_error: 0.2057\n",
      "Epoch 00268: val_loss did not improve from 0.25956\n",
      "6250/6250 [==============================] - 4s 679us/step - loss: 0.2058 - mean_absolute_error: 0.2058 - val_loss: 0.2617 - val_mean_absolute_error: 0.2617\n",
      "Epoch 269/1000\n",
      "6217/6250 [============================>.] - ETA: 0s - loss: 0.2055 - mean_absolute_error: 0.2055\n",
      "Epoch 00269: val_loss improved from 0.25956 to 0.25948, saving model to model_dl.h5\n",
      "6250/6250 [==============================] - 4s 720us/step - loss: 0.2059 - mean_absolute_error: 0.2059 - val_loss: 0.2595 - val_mean_absolute_error: 0.2595\n",
      "Epoch 270/1000\n",
      "6176/6250 [============================>.] - ETA: 0s - loss: 0.2051 - mean_absolute_error: 0.2051\n",
      "Epoch 00270: val_loss did not improve from 0.25948\n",
      "6250/6250 [==============================] - 4s 686us/step - loss: 0.2052 - mean_absolute_error: 0.2052 - val_loss: 0.2613 - val_mean_absolute_error: 0.2613\n",
      "Epoch 271/1000\n",
      "6207/6250 [============================>.] - ETA: 0s - loss: 0.2049 - mean_absolute_error: 0.2049\n",
      "Epoch 00271: val_loss improved from 0.25948 to 0.25837, saving model to model_dl.h5\n",
      "6250/6250 [==============================] - 4s 683us/step - loss: 0.2048 - mean_absolute_error: 0.2048 - val_loss: 0.2584 - val_mean_absolute_error: 0.2584\n",
      "Epoch 272/1000\n",
      "6175/6250 [============================>.] - ETA: 0s - loss: 0.2059 - mean_absolute_error: 0.2059\n",
      "Epoch 00272: val_loss did not improve from 0.25837\n",
      "6250/6250 [==============================] - 4s 681us/step - loss: 0.2058 - mean_absolute_error: 0.2058 - val_loss: 0.2606 - val_mean_absolute_error: 0.2606\n",
      "Epoch 273/1000\n",
      "6199/6250 [============================>.] - ETA: 0s - loss: 0.2043 - mean_absolute_error: 0.2043\n",
      "Epoch 00273: val_loss did not improve from 0.25837\n",
      "6250/6250 [==============================] - 5s 727us/step - loss: 0.2050 - mean_absolute_error: 0.2050 - val_loss: 0.2608 - val_mean_absolute_error: 0.2608\n",
      "Epoch 274/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6248/6250 [============================>.] - ETA: 0s - loss: 0.2043 - mean_absolute_error: 0.2043\n",
      "Epoch 00274: val_loss did not improve from 0.25837\n",
      "6250/6250 [==============================] - 4s 677us/step - loss: 0.2043 - mean_absolute_error: 0.2043 - val_loss: 0.2605 - val_mean_absolute_error: 0.2605\n",
      "Epoch 275/1000\n",
      "6178/6250 [============================>.] - ETA: 0s - loss: 0.2046 - mean_absolute_error: 0.2046\n",
      "Epoch 00275: val_loss did not improve from 0.25837\n",
      "6250/6250 [==============================] - 4s 703us/step - loss: 0.2045 - mean_absolute_error: 0.2045 - val_loss: 0.2601 - val_mean_absolute_error: 0.2601\n",
      "Epoch 276/1000\n",
      "6227/6250 [============================>.] - ETA: 0s - loss: 0.2047 - mean_absolute_error: 0.2047\n",
      "Epoch 00276: val_loss improved from 0.25837 to 0.25701, saving model to model_dl.h5\n",
      "6250/6250 [==============================] - 4s 695us/step - loss: 0.2049 - mean_absolute_error: 0.2049 - val_loss: 0.2570 - val_mean_absolute_error: 0.2570\n",
      "Epoch 277/1000\n",
      "6226/6250 [============================>.] - ETA: 0s - loss: 0.2050 - mean_absolute_error: 0.2050\n",
      "Epoch 00277: val_loss did not improve from 0.25701\n",
      "6250/6250 [==============================] - 5s 729us/step - loss: 0.2054 - mean_absolute_error: 0.2054 - val_loss: 0.2613 - val_mean_absolute_error: 0.2613\n",
      "Epoch 278/1000\n",
      "6168/6250 [============================>.] - ETA: 0s - loss: 0.2062 - mean_absolute_error: 0.2062\n",
      "Epoch 00278: val_loss did not improve from 0.25701\n",
      "6250/6250 [==============================] - 4s 675us/step - loss: 0.2055 - mean_absolute_error: 0.2055 - val_loss: 0.2645 - val_mean_absolute_error: 0.2645\n",
      "Epoch 279/1000\n",
      "6226/6250 [============================>.] - ETA: 0s - loss: 0.2053 - mean_absolute_error: 0.2053\n",
      "Epoch 00279: val_loss did not improve from 0.25701\n",
      "6250/6250 [==============================] - 4s 683us/step - loss: 0.2052 - mean_absolute_error: 0.2052 - val_loss: 0.2600 - val_mean_absolute_error: 0.2600\n",
      "Epoch 280/1000\n",
      "6249/6250 [============================>.] - ETA: 0s - loss: 0.2036 - mean_absolute_error: 0.2036\n",
      "Epoch 00280: val_loss did not improve from 0.25701\n",
      "6250/6250 [==============================] - 4s 718us/step - loss: 0.2036 - mean_absolute_error: 0.2036 - val_loss: 0.2590 - val_mean_absolute_error: 0.2590\n",
      "Epoch 281/1000\n",
      "6230/6250 [============================>.] - ETA: 0s - loss: 0.2040 - mean_absolute_error: 0.2040\n",
      "Epoch 00281: val_loss did not improve from 0.25701\n",
      "6250/6250 [==============================] - 4s 690us/step - loss: 0.2041 - mean_absolute_error: 0.2041 - val_loss: 0.2596 - val_mean_absolute_error: 0.2596\n",
      "Epoch 282/1000\n",
      "6184/6250 [============================>.] - ETA: 0s - loss: 0.2034 - mean_absolute_error: 0.2034\n",
      "Epoch 00282: val_loss did not improve from 0.25701\n",
      "6250/6250 [==============================] - 4s 676us/step - loss: 0.2040 - mean_absolute_error: 0.2040 - val_loss: 0.2598 - val_mean_absolute_error: 0.2598\n",
      "Epoch 283/1000\n",
      "6247/6250 [============================>.] - ETA: 0s - loss: 0.2041 - mean_absolute_error: 0.2041\n",
      "Epoch 00283: val_loss did not improve from 0.25701\n",
      "6250/6250 [==============================] - 4s 680us/step - loss: 0.2041 - mean_absolute_error: 0.2041 - val_loss: 0.2617 - val_mean_absolute_error: 0.2617\n",
      "Epoch 284/1000\n",
      "6211/6250 [============================>.] - ETA: 0s - loss: 0.2042 - mean_absolute_error: 0.2042\n",
      "Epoch 00284: val_loss did not improve from 0.25701\n",
      "6250/6250 [==============================] - 5s 741us/step - loss: 0.2045 - mean_absolute_error: 0.2045 - val_loss: 0.2644 - val_mean_absolute_error: 0.2644\n",
      "Epoch 285/1000\n",
      "6244/6250 [============================>.] - ETA: 0s - loss: 0.2049 - mean_absolute_error: 0.2049\n",
      "Epoch 00285: val_loss did not improve from 0.25701\n",
      "6250/6250 [==============================] - 4s 697us/step - loss: 0.2050 - mean_absolute_error: 0.2050 - val_loss: 0.2613 - val_mean_absolute_error: 0.2613\n",
      "Epoch 286/1000\n",
      "6202/6250 [============================>.] - ETA: 0s - loss: 0.2042 - mean_absolute_error: 0.2042\n",
      "Epoch 00286: val_loss did not improve from 0.25701\n",
      "6250/6250 [==============================] - 4s 683us/step - loss: 0.2039 - mean_absolute_error: 0.2039 - val_loss: 0.2610 - val_mean_absolute_error: 0.2610\n",
      "Epoch 287/1000\n",
      "6213/6250 [============================>.] - ETA: 0s - loss: 0.2040 - mean_absolute_error: 0.2040\n",
      "Epoch 00287: val_loss did not improve from 0.25701\n",
      "6250/6250 [==============================] - 4s 678us/step - loss: 0.2039 - mean_absolute_error: 0.2039 - val_loss: 0.2604 - val_mean_absolute_error: 0.2604\n",
      "Epoch 288/1000\n",
      "6186/6250 [============================>.] - ETA: 0s - loss: 0.2043 - mean_absolute_error: 0.2043\n",
      "Epoch 00288: val_loss did not improve from 0.25701\n",
      "6250/6250 [==============================] - 5s 731us/step - loss: 0.2041 - mean_absolute_error: 0.2041 - val_loss: 0.2598 - val_mean_absolute_error: 0.2598\n",
      "Epoch 289/1000\n",
      "6227/6250 [============================>.] - ETA: 0s - loss: 0.2045 - mean_absolute_error: 0.2045\n",
      "Epoch 00289: val_loss improved from 0.25701 to 0.25592, saving model to model_dl.h5\n",
      "6250/6250 [==============================] - 4s 676us/step - loss: 0.2045 - mean_absolute_error: 0.2045 - val_loss: 0.2559 - val_mean_absolute_error: 0.2559\n",
      "Epoch 290/1000\n",
      "6188/6250 [============================>.] - ETA: 0s - loss: 0.2043 - mean_absolute_error: 0.2043\n",
      "Epoch 00290: val_loss did not improve from 0.25592\n",
      "6250/6250 [==============================] - 4s 676us/step - loss: 0.2039 - mean_absolute_error: 0.2039 - val_loss: 0.2602 - val_mean_absolute_error: 0.2602\n",
      "Epoch 291/1000\n",
      "6225/6250 [============================>.] - ETA: 0s - loss: 0.2031 - mean_absolute_error: 0.2031\n",
      "Epoch 00291: val_loss did not improve from 0.25592\n",
      "6250/6250 [==============================] - 4s 719us/step - loss: 0.2031 - mean_absolute_error: 0.2031 - val_loss: 0.2637 - val_mean_absolute_error: 0.2637\n",
      "Epoch 292/1000\n",
      "6170/6250 [============================>.] - ETA: 0s - loss: 0.2026 - mean_absolute_error: 0.2026\n",
      "Epoch 00292: val_loss did not improve from 0.25592\n",
      "6250/6250 [==============================] - 4s 688us/step - loss: 0.2021 - mean_absolute_error: 0.2021 - val_loss: 0.2605 - val_mean_absolute_error: 0.2605\n",
      "Epoch 293/1000\n",
      "6227/6250 [============================>.] - ETA: 0s - loss: 0.2026 - mean_absolute_error: 0.2026\n",
      "Epoch 00293: val_loss did not improve from 0.25592\n",
      "6250/6250 [==============================] - 4s 681us/step - loss: 0.2026 - mean_absolute_error: 0.2026 - val_loss: 0.2575 - val_mean_absolute_error: 0.2575\n",
      "Epoch 294/1000\n",
      "6215/6250 [============================>.] - ETA: 0s - loss: 0.2037 - mean_absolute_error: 0.2037\n",
      "Epoch 00294: val_loss did not improve from 0.25592\n",
      "6250/6250 [==============================] - 4s 685us/step - loss: 0.2036 - mean_absolute_error: 0.2036 - val_loss: 0.2596 - val_mean_absolute_error: 0.2596\n",
      "Epoch 295/1000\n",
      "6243/6250 [============================>.] - ETA: 0s - loss: 0.2028 - mean_absolute_error: 0.2028\n",
      "Epoch 00295: val_loss did not improve from 0.25592\n",
      "6250/6250 [==============================] - 5s 734us/step - loss: 0.2027 - mean_absolute_error: 0.2027 - val_loss: 0.2597 - val_mean_absolute_error: 0.2597\n",
      "Epoch 296/1000\n",
      "6177/6250 [============================>.] - ETA: 0s - loss: 0.2027 - mean_absolute_error: 0.2027\n",
      "Epoch 00296: val_loss did not improve from 0.25592\n",
      "6250/6250 [==============================] - 4s 678us/step - loss: 0.2034 - mean_absolute_error: 0.2034 - val_loss: 0.2608 - val_mean_absolute_error: 0.2608\n",
      "Epoch 297/1000\n",
      "6165/6250 [============================>.] - ETA: 0s - loss: 0.2028 - mean_absolute_error: 0.2028\n",
      "Epoch 00297: val_loss did not improve from 0.25592\n",
      "6250/6250 [==============================] - 4s 679us/step - loss: 0.2025 - mean_absolute_error: 0.2025 - val_loss: 0.2580 - val_mean_absolute_error: 0.2580\n",
      "Epoch 298/1000\n",
      "6201/6250 [============================>.] - ETA: 0s - loss: 0.2025 - mean_absolute_error: 0.2025\n",
      "Epoch 00298: val_loss did not improve from 0.25592\n",
      "6250/6250 [==============================] - 4s 685us/step - loss: 0.2026 - mean_absolute_error: 0.2026 - val_loss: 0.2579 - val_mean_absolute_error: 0.2579\n",
      "Epoch 299/1000\n",
      "6195/6250 [============================>.] - ETA: 0s - loss: 0.2035 - mean_absolute_error: 0.2035\n",
      "Epoch 00299: val_loss did not improve from 0.25592\n",
      "6250/6250 [==============================] - 5s 730us/step - loss: 0.2029 - mean_absolute_error: 0.2029 - val_loss: 0.2566 - val_mean_absolute_error: 0.2566\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 300/1000\n",
      "6177/6250 [============================>.] - ETA: 0s - loss: 0.2021 - mean_absolute_error: 0.2021\n",
      "Epoch 00300: val_loss did not improve from 0.25592\n",
      "6250/6250 [==============================] - 4s 675us/step - loss: 0.2024 - mean_absolute_error: 0.2024 - val_loss: 0.2569 - val_mean_absolute_error: 0.2569\n",
      "Epoch 301/1000\n",
      "6241/6250 [============================>.] - ETA: 0s - loss: 0.2024 - mean_absolute_error: 0.2024\n",
      "Epoch 00301: val_loss did not improve from 0.25592\n",
      "6250/6250 [==============================] - 4s 680us/step - loss: 0.2022 - mean_absolute_error: 0.2022 - val_loss: 0.2572 - val_mean_absolute_error: 0.2572\n",
      "Epoch 302/1000\n",
      "6187/6250 [============================>.] - ETA: 0s - loss: 0.2032 - mean_absolute_error: 0.2032\n",
      "Epoch 00302: val_loss did not improve from 0.25592\n",
      "6250/6250 [==============================] - 4s 709us/step - loss: 0.2026 - mean_absolute_error: 0.2026 - val_loss: 0.2592 - val_mean_absolute_error: 0.2592\n",
      "Epoch 303/1000\n",
      "6183/6250 [============================>.] - ETA: 0s - loss: 0.2028 - mean_absolute_error: 0.2028\n",
      "Epoch 00303: val_loss did not improve from 0.25592\n",
      "6250/6250 [==============================] - 4s 694us/step - loss: 0.2027 - mean_absolute_error: 0.2027 - val_loss: 0.2599 - val_mean_absolute_error: 0.2599\n",
      "Epoch 304/1000\n",
      "6204/6250 [============================>.] - ETA: 0s - loss: 0.2020 - mean_absolute_error: 0.2020\n",
      "Epoch 00304: val_loss did not improve from 0.25592\n",
      "6250/6250 [==============================] - 4s 676us/step - loss: 0.2022 - mean_absolute_error: 0.2022 - val_loss: 0.2566 - val_mean_absolute_error: 0.2566\n",
      "Epoch 305/1000\n",
      "6224/6250 [============================>.] - ETA: 0s - loss: 0.2027 - mean_absolute_error: 0.2027\n",
      "Epoch 00305: val_loss did not improve from 0.25592\n",
      "6250/6250 [==============================] - 4s 683us/step - loss: 0.2022 - mean_absolute_error: 0.2022 - val_loss: 0.2599 - val_mean_absolute_error: 0.2599\n",
      "Epoch 306/1000\n",
      "6176/6250 [============================>.] - ETA: 0s - loss: 0.2021 - mean_absolute_error: 0.2021\n",
      "Epoch 00306: val_loss improved from 0.25592 to 0.25578, saving model to model_dl.h5\n",
      "6250/6250 [==============================] - 5s 730us/step - loss: 0.2016 - mean_absolute_error: 0.2016 - val_loss: 0.2558 - val_mean_absolute_error: 0.2558\n",
      "Epoch 307/1000\n",
      "6229/6250 [============================>.] - ETA: 0s - loss: 0.2017 - mean_absolute_error: 0.2017\n",
      "Epoch 00307: val_loss did not improve from 0.25578\n",
      "6250/6250 [==============================] - 4s 679us/step - loss: 0.2018 - mean_absolute_error: 0.2018 - val_loss: 0.2605 - val_mean_absolute_error: 0.2605\n",
      "Epoch 308/1000\n",
      "6224/6250 [============================>.] - ETA: 0s - loss: 0.2015 - mean_absolute_error: 0.2015\n",
      "Epoch 00308: val_loss improved from 0.25578 to 0.25555, saving model to model_dl.h5\n",
      "6250/6250 [==============================] - 4s 686us/step - loss: 0.2019 - mean_absolute_error: 0.2019 - val_loss: 0.2556 - val_mean_absolute_error: 0.2556\n",
      "Epoch 309/1000\n",
      "6206/6250 [============================>.] - ETA: 0s - loss: 0.2007 - mean_absolute_error: 0.2007\n",
      "Epoch 00309: val_loss did not improve from 0.25555\n",
      "6250/6250 [==============================] - 4s 684us/step - loss: 0.2008 - mean_absolute_error: 0.2008 - val_loss: 0.2592 - val_mean_absolute_error: 0.2592\n",
      "Epoch 310/1000\n",
      "6168/6250 [============================>.] - ETA: 0s - loss: 0.2009 - mean_absolute_error: 0.2009\n",
      "Epoch 00310: val_loss did not improve from 0.25555\n",
      "6250/6250 [==============================] - 5s 731us/step - loss: 0.2019 - mean_absolute_error: 0.2019 - val_loss: 0.2602 - val_mean_absolute_error: 0.2602\n",
      "Epoch 311/1000\n",
      "6238/6250 [============================>.] - ETA: 0s - loss: 0.2008 - mean_absolute_error: 0.2008\n",
      "Epoch 00311: val_loss improved from 0.25555 to 0.25521, saving model to model_dl.h5\n",
      "6250/6250 [==============================] - 4s 689us/step - loss: 0.2010 - mean_absolute_error: 0.2010 - val_loss: 0.2552 - val_mean_absolute_error: 0.2552\n",
      "Epoch 312/1000\n",
      "6170/6250 [============================>.] - ETA: 0s - loss: 0.2016 - mean_absolute_error: 0.2016\n",
      "Epoch 00312: val_loss did not improve from 0.25521\n",
      "6250/6250 [==============================] - 4s 680us/step - loss: 0.2008 - mean_absolute_error: 0.2008 - val_loss: 0.2600 - val_mean_absolute_error: 0.2600\n",
      "Epoch 313/1000\n",
      "6250/6250 [==============================] - ETA: 0s - loss: 0.2012 - mean_absolute_error: 0.2012\n",
      "Epoch 00313: val_loss did not improve from 0.25521\n",
      "6250/6250 [==============================] - 4s 704us/step - loss: 0.2012 - mean_absolute_error: 0.2012 - val_loss: 0.2588 - val_mean_absolute_error: 0.2588\n",
      "Epoch 314/1000\n",
      "6180/6250 [============================>.] - ETA: 0s - loss: 0.2012 - mean_absolute_error: 0.2012\n",
      "Epoch 00314: val_loss did not improve from 0.25521\n",
      "6250/6250 [==============================] - 4s 704us/step - loss: 0.2011 - mean_absolute_error: 0.2011 - val_loss: 0.2603 - val_mean_absolute_error: 0.2603\n",
      "Epoch 315/1000\n",
      "6239/6250 [============================>.] - ETA: 0s - loss: 0.2006 - mean_absolute_error: 0.2006\n",
      "Epoch 00315: val_loss did not improve from 0.25521\n",
      "6250/6250 [==============================] - 4s 681us/step - loss: 0.2008 - mean_absolute_error: 0.2008 - val_loss: 0.2567 - val_mean_absolute_error: 0.2567\n",
      "Epoch 316/1000\n",
      "6218/6250 [============================>.] - ETA: 0s - loss: 0.2003 - mean_absolute_error: 0.2003\n",
      "Epoch 00316: val_loss did not improve from 0.25521\n",
      "6250/6250 [==============================] - 4s 682us/step - loss: 0.2005 - mean_absolute_error: 0.2005 - val_loss: 0.2592 - val_mean_absolute_error: 0.2592\n",
      "Epoch 317/1000\n",
      "6182/6250 [============================>.] - ETA: 0s - loss: 0.2008 - mean_absolute_error: 0.2008\n",
      "Epoch 00317: val_loss improved from 0.25521 to 0.25310, saving model to model_dl.h5\n",
      "6250/6250 [==============================] - 5s 727us/step - loss: 0.2005 - mean_absolute_error: 0.2005 - val_loss: 0.2531 - val_mean_absolute_error: 0.2531\n",
      "Epoch 318/1000\n",
      "6217/6250 [============================>.] - ETA: 0s - loss: 0.2004 - mean_absolute_error: 0.2004\n",
      "Epoch 00318: val_loss did not improve from 0.25310\n",
      "6250/6250 [==============================] - 4s 686us/step - loss: 0.2000 - mean_absolute_error: 0.2000 - val_loss: 0.2542 - val_mean_absolute_error: 0.2542\n",
      "Epoch 319/1000\n",
      "6233/6250 [============================>.] - ETA: 0s - loss: 0.2003 - mean_absolute_error: 0.2003\n",
      "Epoch 00319: val_loss did not improve from 0.25310\n",
      "6250/6250 [==============================] - 4s 681us/step - loss: 0.2004 - mean_absolute_error: 0.2004 - val_loss: 0.2577 - val_mean_absolute_error: 0.2577\n",
      "Epoch 320/1000\n",
      "6180/6250 [============================>.] - ETA: 0s - loss: 0.2004 - mean_absolute_error: 0.2004\n",
      "Epoch 00320: val_loss did not improve from 0.25310\n",
      "6250/6250 [==============================] - 4s 687us/step - loss: 0.1997 - mean_absolute_error: 0.1997 - val_loss: 0.2577 - val_mean_absolute_error: 0.2577\n",
      "Epoch 321/1000\n",
      "6246/6250 [============================>.] - ETA: 0s - loss: 0.1998 - mean_absolute_error: 0.1998\n",
      "Epoch 00321: val_loss improved from 0.25310 to 0.25235, saving model to model_dl.h5\n",
      "6250/6250 [==============================] - 5s 735us/step - loss: 0.1997 - mean_absolute_error: 0.1997 - val_loss: 0.2523 - val_mean_absolute_error: 0.2523\n",
      "Epoch 322/1000\n",
      "6223/6250 [============================>.] - ETA: 0s - loss: 0.1988 - mean_absolute_error: 0.1988\n",
      "Epoch 00322: val_loss did not improve from 0.25235\n",
      "6250/6250 [==============================] - 4s 686us/step - loss: 0.1989 - mean_absolute_error: 0.1989 - val_loss: 0.2628 - val_mean_absolute_error: 0.2628\n",
      "Epoch 323/1000\n",
      "6232/6250 [============================>.] - ETA: 0s - loss: 0.1990 - mean_absolute_error: 0.1990\n",
      "Epoch 00323: val_loss did not improve from 0.25235\n",
      "6250/6250 [==============================] - 4s 681us/step - loss: 0.1994 - mean_absolute_error: 0.1994 - val_loss: 0.2573 - val_mean_absolute_error: 0.2573\n",
      "Epoch 324/1000\n",
      "6200/6250 [============================>.] - ETA: 0s - loss: 0.1994 - mean_absolute_error: 0.1994\n",
      "Epoch 00324: val_loss did not improve from 0.25235\n",
      "6250/6250 [==============================] - 4s 700us/step - loss: 0.1993 - mean_absolute_error: 0.1993 - val_loss: 0.2571 - val_mean_absolute_error: 0.2571\n",
      "Epoch 325/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6192/6250 [============================>.] - ETA: 0s - loss: 0.1997 - mean_absolute_error: 0.1997\n",
      "Epoch 00325: val_loss did not improve from 0.25235\n",
      "6250/6250 [==============================] - 4s 710us/step - loss: 0.2001 - mean_absolute_error: 0.2001 - val_loss: 0.2577 - val_mean_absolute_error: 0.2577\n",
      "Epoch 326/1000\n",
      "6214/6250 [============================>.] - ETA: 0s - loss: 0.2007 - mean_absolute_error: 0.2007\n",
      "Epoch 00326: val_loss did not improve from 0.25235\n",
      "6250/6250 [==============================] - 4s 678us/step - loss: 0.2000 - mean_absolute_error: 0.2000 - val_loss: 0.2586 - val_mean_absolute_error: 0.2586\n",
      "Epoch 327/1000\n",
      "6230/6250 [============================>.] - ETA: 0s - loss: 0.1984 - mean_absolute_error: 0.1984\n",
      "Epoch 00327: val_loss did not improve from 0.25235\n",
      "6250/6250 [==============================] - 4s 682us/step - loss: 0.1984 - mean_absolute_error: 0.1984 - val_loss: 0.2555 - val_mean_absolute_error: 0.2555\n",
      "Epoch 328/1000\n",
      "6175/6250 [============================>.] - ETA: 0s - loss: 0.1989 - mean_absolute_error: 0.1989\n",
      "Epoch 00328: val_loss did not improve from 0.25235\n",
      "6250/6250 [==============================] - 5s 724us/step - loss: 0.1990 - mean_absolute_error: 0.1990 - val_loss: 0.2550 - val_mean_absolute_error: 0.2550\n",
      "Epoch 329/1000\n",
      "6164/6250 [============================>.] - ETA: 0s - loss: 0.2000 - mean_absolute_error: 0.2000\n",
      "Epoch 00329: val_loss did not improve from 0.25235\n",
      "6250/6250 [==============================] - 4s 685us/step - loss: 0.1995 - mean_absolute_error: 0.1995 - val_loss: 0.2555 - val_mean_absolute_error: 0.2555\n",
      "Epoch 330/1000\n",
      "6236/6250 [============================>.] - ETA: 0s - loss: 0.1995 - mean_absolute_error: 0.1995\n",
      "Epoch 00330: val_loss did not improve from 0.25235\n",
      "6250/6250 [==============================] - 4s 679us/step - loss: 0.1995 - mean_absolute_error: 0.1995 - val_loss: 0.2549 - val_mean_absolute_error: 0.2549\n",
      "Epoch 331/1000\n",
      "6201/6250 [============================>.] - ETA: 0s - loss: 0.1987 - mean_absolute_error: 0.1987\n",
      "Epoch 00331: val_loss did not improve from 0.25235\n",
      "6250/6250 [==============================] - 4s 684us/step - loss: 0.1987 - mean_absolute_error: 0.1987 - val_loss: 0.2570 - val_mean_absolute_error: 0.2570\n",
      "Epoch 332/1000\n",
      "6250/6250 [==============================] - ETA: 0s - loss: 0.1988 - mean_absolute_error: 0.1988\n",
      "Epoch 00332: val_loss did not improve from 0.25235\n",
      "6250/6250 [==============================] - 5s 735us/step - loss: 0.1988 - mean_absolute_error: 0.1988 - val_loss: 0.2615 - val_mean_absolute_error: 0.2615\n",
      "Epoch 333/1000\n",
      "6237/6250 [============================>.] - ETA: 0s - loss: 0.1993 - mean_absolute_error: 0.1993\n",
      "Epoch 00333: val_loss did not improve from 0.25235\n",
      "6250/6250 [==============================] - 4s 682us/step - loss: 0.1990 - mean_absolute_error: 0.1990 - val_loss: 0.2548 - val_mean_absolute_error: 0.2548\n",
      "Epoch 334/1000\n",
      "6225/6250 [============================>.] - ETA: 0s - loss: 0.1978 - mean_absolute_error: 0.1978\n",
      "Epoch 00334: val_loss did not improve from 0.25235\n",
      "6250/6250 [==============================] - 4s 680us/step - loss: 0.1980 - mean_absolute_error: 0.1980 - val_loss: 0.2609 - val_mean_absolute_error: 0.2609\n",
      "Epoch 335/1000\n",
      "6220/6250 [============================>.] - ETA: 0s - loss: 0.1986 - mean_absolute_error: 0.1986\n",
      "Epoch 00335: val_loss did not improve from 0.25235\n",
      "6250/6250 [==============================] - 4s 697us/step - loss: 0.1988 - mean_absolute_error: 0.1988 - val_loss: 0.2539 - val_mean_absolute_error: 0.2539\n",
      "Epoch 336/1000\n",
      "6170/6250 [============================>.] - ETA: 0s - loss: 0.1992 - mean_absolute_error: 0.1992\n",
      "Epoch 00336: val_loss improved from 0.25235 to 0.25173, saving model to model_dl.h5\n",
      "6250/6250 [==============================] - 5s 725us/step - loss: 0.1989 - mean_absolute_error: 0.1989 - val_loss: 0.2517 - val_mean_absolute_error: 0.2517\n",
      "Epoch 337/1000\n",
      "6239/6250 [============================>.] - ETA: 0s - loss: 0.1983 - mean_absolute_error: 0.1983\n",
      "Epoch 00337: val_loss did not improve from 0.25173\n",
      "6250/6250 [==============================] - 4s 679us/step - loss: 0.1982 - mean_absolute_error: 0.1982 - val_loss: 0.2556 - val_mean_absolute_error: 0.2556\n",
      "Epoch 338/1000\n",
      "6203/6250 [============================>.] - ETA: 0s - loss: 0.1981 - mean_absolute_error: 0.1981\n",
      "Epoch 00338: val_loss did not improve from 0.25173\n",
      "6250/6250 [==============================] - 4s 686us/step - loss: 0.1982 - mean_absolute_error: 0.1982 - val_loss: 0.2555 - val_mean_absolute_error: 0.2555\n",
      "Epoch 339/1000\n",
      "6199/6250 [============================>.] - ETA: 0s - loss: 0.1987 - mean_absolute_error: 0.1987\n",
      "Epoch 00339: val_loss improved from 0.25173 to 0.25029, saving model to model_dl.h5\n",
      "6250/6250 [==============================] - 5s 725us/step - loss: 0.1988 - mean_absolute_error: 0.1988 - val_loss: 0.2503 - val_mean_absolute_error: 0.2503\n",
      "Epoch 340/1000\n",
      "6245/6250 [============================>.] - ETA: 0s - loss: 0.1972 - mean_absolute_error: 0.1972\n",
      "Epoch 00340: val_loss did not improve from 0.25029\n",
      "6250/6250 [==============================] - 4s 690us/step - loss: 0.1971 - mean_absolute_error: 0.1971 - val_loss: 0.2540 - val_mean_absolute_error: 0.2540\n",
      "Epoch 341/1000\n",
      "6201/6250 [============================>.] - ETA: 0s - loss: 0.1972 - mean_absolute_error: 0.1972\n",
      "Epoch 00341: val_loss did not improve from 0.25029\n",
      "6250/6250 [==============================] - 4s 685us/step - loss: 0.1975 - mean_absolute_error: 0.1975 - val_loss: 0.2593 - val_mean_absolute_error: 0.2593\n",
      "Epoch 342/1000\n",
      "6190/6250 [============================>.] - ETA: 0s - loss: 0.1974 - mean_absolute_error: 0.1974\n",
      "Epoch 00342: val_loss did not improve from 0.25029\n",
      "6250/6250 [==============================] - 4s 686us/step - loss: 0.1972 - mean_absolute_error: 0.1972 - val_loss: 0.2595 - val_mean_absolute_error: 0.2595\n",
      "Epoch 343/1000\n",
      "6174/6250 [============================>.] - ETA: 0s - loss: 0.1978 - mean_absolute_error: 0.1978\n",
      "Epoch 00343: val_loss improved from 0.25029 to 0.25022, saving model to model_dl.h5\n",
      "6250/6250 [==============================] - 5s 733us/step - loss: 0.1980 - mean_absolute_error: 0.1980 - val_loss: 0.2502 - val_mean_absolute_error: 0.2502\n",
      "Epoch 344/1000\n",
      "6226/6250 [============================>.] - ETA: 0s - loss: 0.1979 - mean_absolute_error: 0.1979\n",
      "Epoch 00344: val_loss did not improve from 0.25022\n",
      "6250/6250 [==============================] - 4s 683us/step - loss: 0.1974 - mean_absolute_error: 0.1974 - val_loss: 0.2577 - val_mean_absolute_error: 0.2577\n",
      "Epoch 345/1000\n",
      "6229/6250 [============================>.] - ETA: 0s - loss: 0.1976 - mean_absolute_error: 0.1976\n",
      "Epoch 00345: val_loss did not improve from 0.25022\n",
      "6250/6250 [==============================] - 4s 683us/step - loss: 0.1977 - mean_absolute_error: 0.1977 - val_loss: 0.2547 - val_mean_absolute_error: 0.2547\n",
      "Epoch 346/1000\n",
      "6162/6250 [============================>.] - ETA: 0s - loss: 0.1981 - mean_absolute_error: 0.1981\n",
      "Epoch 00346: val_loss did not improve from 0.25022\n",
      "6250/6250 [==============================] - 4s 690us/step - loss: 0.1976 - mean_absolute_error: 0.1976 - val_loss: 0.2536 - val_mean_absolute_error: 0.2536\n",
      "Epoch 347/1000\n",
      "6187/6250 [============================>.] - ETA: 0s - loss: 0.1976 - mean_absolute_error: 0.1976\n",
      "Epoch 00347: val_loss improved from 0.25022 to 0.24958, saving model to model_dl.h5\n",
      "6250/6250 [==============================] - 5s 723us/step - loss: 0.1976 - mean_absolute_error: 0.1976 - val_loss: 0.2496 - val_mean_absolute_error: 0.2496\n",
      "Epoch 348/1000\n",
      "6225/6250 [============================>.] - ETA: 0s - loss: 0.1970 - mean_absolute_error: 0.1970\n",
      "Epoch 00348: val_loss did not improve from 0.24958\n",
      "6250/6250 [==============================] - 4s 681us/step - loss: 0.1971 - mean_absolute_error: 0.1971 - val_loss: 0.2530 - val_mean_absolute_error: 0.2530\n",
      "Epoch 349/1000\n",
      "6217/6250 [============================>.] - ETA: 0s - loss: 0.1958 - mean_absolute_error: 0.1958\n",
      "Epoch 00349: val_loss did not improve from 0.24958\n",
      "6250/6250 [==============================] - 4s 685us/step - loss: 0.1966 - mean_absolute_error: 0.1966 - val_loss: 0.2569 - val_mean_absolute_error: 0.2569\n",
      "Epoch 350/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6234/6250 [============================>.] - ETA: 0s - loss: 0.1979 - mean_absolute_error: 0.1979\n",
      "Epoch 00350: val_loss did not improve from 0.24958\n",
      "6250/6250 [==============================] - 5s 729us/step - loss: 0.1977 - mean_absolute_error: 0.1977 - val_loss: 0.2515 - val_mean_absolute_error: 0.2515\n",
      "Epoch 351/1000\n",
      "6229/6250 [============================>.] - ETA: 0s - loss: 0.1972 - mean_absolute_error: 0.1972\n",
      "Epoch 00351: val_loss did not improve from 0.24958\n",
      "6250/6250 [==============================] - 4s 686us/step - loss: 0.1973 - mean_absolute_error: 0.1973 - val_loss: 0.2513 - val_mean_absolute_error: 0.2513\n",
      "Epoch 352/1000\n",
      "6209/6250 [============================>.] - ETA: 0s - loss: 0.1968 - mean_absolute_error: 0.1968\n",
      "Epoch 00352: val_loss did not improve from 0.24958\n",
      "6250/6250 [==============================] - 4s 680us/step - loss: 0.1967 - mean_absolute_error: 0.1967 - val_loss: 0.2521 - val_mean_absolute_error: 0.2521\n",
      "Epoch 353/1000\n",
      "6199/6250 [============================>.] - ETA: 0s - loss: 0.1963 - mean_absolute_error: 0.1963\n",
      "Epoch 00353: val_loss improved from 0.24958 to 0.24827, saving model to model_dl.h5\n",
      "6250/6250 [==============================] - 4s 682us/step - loss: 0.1963 - mean_absolute_error: 0.1963 - val_loss: 0.2483 - val_mean_absolute_error: 0.2483\n",
      "Epoch 354/1000\n",
      "6219/6250 [============================>.] - ETA: 0s - loss: 0.1963 - mean_absolute_error: 0.1963\n",
      "Epoch 00354: val_loss did not improve from 0.24827\n",
      "6250/6250 [==============================] - 5s 733us/step - loss: 0.1963 - mean_absolute_error: 0.1963 - val_loss: 0.2497 - val_mean_absolute_error: 0.2497\n",
      "Epoch 355/1000\n",
      "6219/6250 [============================>.] - ETA: 0s - loss: 0.1961 - mean_absolute_error: 0.1961\n",
      "Epoch 00355: val_loss did not improve from 0.24827\n",
      "6250/6250 [==============================] - 4s 682us/step - loss: 0.1962 - mean_absolute_error: 0.1962 - val_loss: 0.2547 - val_mean_absolute_error: 0.2547\n",
      "Epoch 356/1000\n",
      "6208/6250 [============================>.] - ETA: 0s - loss: 0.1974 - mean_absolute_error: 0.1974\n",
      "Epoch 00356: val_loss did not improve from 0.24827\n",
      "6250/6250 [==============================] - 4s 684us/step - loss: 0.1971 - mean_absolute_error: 0.1971 - val_loss: 0.2504 - val_mean_absolute_error: 0.2504\n",
      "Epoch 357/1000\n",
      "6184/6250 [============================>.] - ETA: 0s - loss: 0.1965 - mean_absolute_error: 0.1965\n",
      "Epoch 00357: val_loss did not improve from 0.24827\n",
      "6250/6250 [==============================] - 4s 694us/step - loss: 0.1962 - mean_absolute_error: 0.1962 - val_loss: 0.2562 - val_mean_absolute_error: 0.2562\n",
      "Epoch 358/1000\n",
      "6213/6250 [============================>.] - ETA: 0s - loss: 0.1963 - mean_absolute_error: 0.1963\n",
      "Epoch 00358: val_loss did not improve from 0.24827\n",
      "6250/6250 [==============================] - 5s 721us/step - loss: 0.1963 - mean_absolute_error: 0.1963 - val_loss: 0.2511 - val_mean_absolute_error: 0.2511\n",
      "Epoch 359/1000\n",
      "6230/6250 [============================>.] - ETA: 0s - loss: 0.1959 - mean_absolute_error: 0.1959\n",
      "Epoch 00359: val_loss did not improve from 0.24827\n",
      "6250/6250 [==============================] - 4s 680us/step - loss: 0.1962 - mean_absolute_error: 0.1962 - val_loss: 0.2519 - val_mean_absolute_error: 0.2519\n",
      "Epoch 360/1000\n",
      "6191/6250 [============================>.] - ETA: 0s - loss: 0.1950 - mean_absolute_error: 0.1950\n",
      "Epoch 00360: val_loss did not improve from 0.24827\n",
      "6250/6250 [==============================] - 4s 688us/step - loss: 0.1956 - mean_absolute_error: 0.1956 - val_loss: 0.2624 - val_mean_absolute_error: 0.2624\n",
      "Epoch 361/1000\n",
      "6216/6250 [============================>.] - ETA: 0s - loss: 0.1964 - mean_absolute_error: 0.1964\n",
      "Epoch 00361: val_loss did not improve from 0.24827\n",
      "6250/6250 [==============================] - 5s 724us/step - loss: 0.1962 - mean_absolute_error: 0.1962 - val_loss: 0.2517 - val_mean_absolute_error: 0.2517\n",
      "Epoch 362/1000\n",
      "6246/6250 [============================>.] - ETA: 0s - loss: 0.1963 - mean_absolute_error: 0.1963\n",
      "Epoch 00362: val_loss did not improve from 0.24827\n",
      "6250/6250 [==============================] - 4s 690us/step - loss: 0.1964 - mean_absolute_error: 0.1964 - val_loss: 0.2522 - val_mean_absolute_error: 0.2522\n",
      "Epoch 363/1000\n",
      "6211/6250 [============================>.] - ETA: 0s - loss: 0.1959 - mean_absolute_error: 0.1959\n",
      "Epoch 00363: val_loss did not improve from 0.24827\n",
      "6250/6250 [==============================] - 4s 685us/step - loss: 0.1964 - mean_absolute_error: 0.1964 - val_loss: 0.2509 - val_mean_absolute_error: 0.2509\n",
      "Epoch 364/1000\n",
      "6186/6250 [============================>.] - ETA: 0s - loss: 0.1952 - mean_absolute_error: 0.1952\n",
      "Epoch 00364: val_loss did not improve from 0.24827\n",
      "6250/6250 [==============================] - 4s 685us/step - loss: 0.1961 - mean_absolute_error: 0.1961 - val_loss: 0.2503 - val_mean_absolute_error: 0.2503\n",
      "Epoch 365/1000\n",
      "6240/6250 [============================>.] - ETA: 0s - loss: 0.1962 - mean_absolute_error: 0.1962\n",
      "Epoch 00365: val_loss did not improve from 0.24827\n",
      "6250/6250 [==============================] - 5s 736us/step - loss: 0.1960 - mean_absolute_error: 0.1960 - val_loss: 0.2574 - val_mean_absolute_error: 0.2574\n",
      "Epoch 366/1000\n",
      "6213/6250 [============================>.] - ETA: 0s - loss: 0.1947 - mean_absolute_error: 0.1947\n",
      "Epoch 00366: val_loss did not improve from 0.24827\n",
      "6250/6250 [==============================] - 4s 683us/step - loss: 0.1948 - mean_absolute_error: 0.1948 - val_loss: 0.2549 - val_mean_absolute_error: 0.2549\n",
      "Epoch 367/1000\n",
      "6243/6250 [============================>.] - ETA: 0s - loss: 0.1949 - mean_absolute_error: 0.1949\n",
      "Epoch 00367: val_loss improved from 0.24827 to 0.24704, saving model to model_dl.h5\n",
      "6250/6250 [==============================] - 4s 689us/step - loss: 0.1952 - mean_absolute_error: 0.1952 - val_loss: 0.2470 - val_mean_absolute_error: 0.2470\n",
      "Epoch 368/1000\n",
      "6247/6250 [============================>.] - ETA: 0s - loss: 0.1952 - mean_absolute_error: 0.1952\n",
      "Epoch 00368: val_loss did not improve from 0.24704\n",
      "6250/6250 [==============================] - 4s 712us/step - loss: 0.1951 - mean_absolute_error: 0.1951 - val_loss: 0.2492 - val_mean_absolute_error: 0.2492\n",
      "Epoch 369/1000\n",
      "6222/6250 [============================>.] - ETA: 0s - loss: 0.1951 - mean_absolute_error: 0.1951\n",
      "Epoch 00369: val_loss did not improve from 0.24704\n",
      "6250/6250 [==============================] - 4s 719us/step - loss: 0.1955 - mean_absolute_error: 0.1955 - val_loss: 0.2525 - val_mean_absolute_error: 0.2525\n",
      "Epoch 370/1000\n",
      "6177/6250 [============================>.] - ETA: 0s - loss: 0.1945 - mean_absolute_error: 0.1945\n",
      "Epoch 00370: val_loss did not improve from 0.24704\n",
      "6250/6250 [==============================] - 4s 686us/step - loss: 0.1945 - mean_absolute_error: 0.1945 - val_loss: 0.2640 - val_mean_absolute_error: 0.2640\n",
      "Epoch 371/1000\n",
      "6227/6250 [============================>.] - ETA: 0s - loss: 0.1947 - mean_absolute_error: 0.1947\n",
      "Epoch 00371: val_loss did not improve from 0.24704\n",
      "6250/6250 [==============================] - 4s 687us/step - loss: 0.1945 - mean_absolute_error: 0.1945 - val_loss: 0.2568 - val_mean_absolute_error: 0.2568\n",
      "Epoch 372/1000\n",
      "6242/6250 [============================>.] - ETA: 0s - loss: 0.1956 - mean_absolute_error: 0.1956\n",
      "Epoch 00372: val_loss did not improve from 0.24704\n",
      "6250/6250 [==============================] - 5s 730us/step - loss: 0.1955 - mean_absolute_error: 0.1955 - val_loss: 0.2491 - val_mean_absolute_error: 0.2491\n",
      "Epoch 373/1000\n",
      "6201/6250 [============================>.] - ETA: 0s - loss: 0.1942 - mean_absolute_error: 0.1942\n",
      "Epoch 00373: val_loss did not improve from 0.24704\n",
      "6250/6250 [==============================] - 4s 684us/step - loss: 0.1945 - mean_absolute_error: 0.1945 - val_loss: 0.2539 - val_mean_absolute_error: 0.2539\n",
      "Epoch 374/1000\n",
      "6220/6250 [============================>.] - ETA: 0s - loss: 0.1947 - mean_absolute_error: 0.1947\n",
      "Epoch 00374: val_loss did not improve from 0.24704\n",
      "6250/6250 [==============================] - 4s 682us/step - loss: 0.1951 - mean_absolute_error: 0.1951 - val_loss: 0.2505 - val_mean_absolute_error: 0.2505\n",
      "Epoch 375/1000\n",
      "6236/6250 [============================>.] - ETA: 0s - loss: 0.1945 - mean_absolute_error: 0.1945\n",
      "Epoch 00375: val_loss did not improve from 0.24704\n",
      "6250/6250 [==============================] - 4s 686us/step - loss: 0.1945 - mean_absolute_error: 0.1945 - val_loss: 0.2473 - val_mean_absolute_error: 0.2473\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 376/1000\n",
      "6202/6250 [============================>.] - ETA: 0s - loss: 0.1944 - mean_absolute_error: 0.1944\n",
      "Epoch 00376: val_loss did not improve from 0.24704\n",
      "6250/6250 [==============================] - 5s 736us/step - loss: 0.1942 - mean_absolute_error: 0.1942 - val_loss: 0.2543 - val_mean_absolute_error: 0.2543\n",
      "Epoch 377/1000\n",
      "6208/6250 [============================>.] - ETA: 0s - loss: 0.1939 - mean_absolute_error: 0.1939\n",
      "Epoch 00377: val_loss did not improve from 0.24704\n",
      "6250/6250 [==============================] - 4s 682us/step - loss: 0.1940 - mean_absolute_error: 0.1940 - val_loss: 0.2536 - val_mean_absolute_error: 0.2536\n",
      "Epoch 378/1000\n",
      "6205/6250 [============================>.] - ETA: 0s - loss: 0.1937 - mean_absolute_error: 0.1937\n",
      "Epoch 00378: val_loss did not improve from 0.24704\n",
      "6250/6250 [==============================] - 4s 680us/step - loss: 0.1939 - mean_absolute_error: 0.1939 - val_loss: 0.2473 - val_mean_absolute_error: 0.2473\n",
      "Epoch 379/1000\n",
      "6194/6250 [============================>.] - ETA: 0s - loss: 0.1949 - mean_absolute_error: 0.1949\n",
      "Epoch 00379: val_loss did not improve from 0.24704\n",
      "6250/6250 [==============================] - 4s 693us/step - loss: 0.1947 - mean_absolute_error: 0.1947 - val_loss: 0.2497 - val_mean_absolute_error: 0.2497\n",
      "Epoch 380/1000\n",
      "6164/6250 [============================>.] - ETA: 0s - loss: 0.1944 - mean_absolute_error: 0.1944\n",
      "Epoch 00380: val_loss did not improve from 0.24704\n",
      "6250/6250 [==============================] - 5s 723us/step - loss: 0.1942 - mean_absolute_error: 0.1942 - val_loss: 0.2503 - val_mean_absolute_error: 0.2503\n",
      "Epoch 381/1000\n",
      "6239/6250 [============================>.] - ETA: 0s - loss: 0.1943 - mean_absolute_error: 0.1943\n",
      "Epoch 00381: val_loss did not improve from 0.24704\n",
      "6250/6250 [==============================] - 4s 681us/step - loss: 0.1942 - mean_absolute_error: 0.1942 - val_loss: 0.2538 - val_mean_absolute_error: 0.2538\n",
      "Epoch 382/1000\n",
      "6204/6250 [============================>.] - ETA: 0s - loss: 0.1940 - mean_absolute_error: 0.1940\n",
      "Epoch 00382: val_loss did not improve from 0.24704\n",
      "6250/6250 [==============================] - 4s 684us/step - loss: 0.1941 - mean_absolute_error: 0.1941 - val_loss: 0.2503 - val_mean_absolute_error: 0.2503\n",
      "Epoch 383/1000\n",
      "6209/6250 [============================>.] - ETA: 0s - loss: 0.1940 - mean_absolute_error: 0.1940\n",
      "Epoch 00383: val_loss did not improve from 0.24704\n",
      "6250/6250 [==============================] - 5s 724us/step - loss: 0.1944 - mean_absolute_error: 0.1944 - val_loss: 0.2479 - val_mean_absolute_error: 0.2479\n",
      "Epoch 384/1000\n",
      "6205/6250 [============================>.] - ETA: 0s - loss: 0.1935 - mean_absolute_error: 0.1935\n",
      "Epoch 00384: val_loss did not improve from 0.24704\n",
      "6250/6250 [==============================] - 4s 692us/step - loss: 0.1935 - mean_absolute_error: 0.1935 - val_loss: 0.2532 - val_mean_absolute_error: 0.2532\n",
      "Epoch 385/1000\n",
      "6219/6250 [============================>.] - ETA: 0s - loss: 0.1942 - mean_absolute_error: 0.1942\n",
      "Epoch 00385: val_loss did not improve from 0.24704\n",
      "6250/6250 [==============================] - 4s 688us/step - loss: 0.1943 - mean_absolute_error: 0.1943 - val_loss: 0.2475 - val_mean_absolute_error: 0.2475\n",
      "Epoch 386/1000\n",
      "6196/6250 [============================>.] - ETA: 0s - loss: 0.1936 - mean_absolute_error: 0.1936\n",
      "Epoch 00386: val_loss did not improve from 0.24704\n",
      "6250/6250 [==============================] - 4s 683us/step - loss: 0.1934 - mean_absolute_error: 0.1934 - val_loss: 0.2496 - val_mean_absolute_error: 0.2496\n",
      "Epoch 387/1000\n",
      "6248/6250 [============================>.] - ETA: 0s - loss: 0.1933 - mean_absolute_error: 0.1933\n",
      "Epoch 00387: val_loss did not improve from 0.24704\n",
      "6250/6250 [==============================] - 5s 737us/step - loss: 0.1933 - mean_absolute_error: 0.1933 - val_loss: 0.2524 - val_mean_absolute_error: 0.2524\n",
      "Epoch 388/1000\n",
      "6206/6250 [============================>.] - ETA: 0s - loss: 0.1935 - mean_absolute_error: 0.1935\n",
      "Epoch 00388: val_loss did not improve from 0.24704\n",
      "6250/6250 [==============================] - 4s 683us/step - loss: 0.1928 - mean_absolute_error: 0.1928 - val_loss: 0.2504 - val_mean_absolute_error: 0.2504\n",
      "Epoch 389/1000\n",
      "6218/6250 [============================>.] - ETA: 0s - loss: 0.1922 - mean_absolute_error: 0.1922\n",
      "Epoch 00389: val_loss did not improve from 0.24704\n",
      "6250/6250 [==============================] - 4s 683us/step - loss: 0.1926 - mean_absolute_error: 0.1926 - val_loss: 0.2525 - val_mean_absolute_error: 0.2525\n",
      "Epoch 390/1000\n",
      "6227/6250 [============================>.] - ETA: 0s - loss: 0.1942 - mean_absolute_error: 0.1942\n",
      "Epoch 00390: val_loss improved from 0.24704 to 0.24498, saving model to model_dl.h5\n",
      "6250/6250 [==============================] - 4s 701us/step - loss: 0.1939 - mean_absolute_error: 0.1939 - val_loss: 0.2450 - val_mean_absolute_error: 0.2450\n",
      "Epoch 391/1000\n",
      "6250/6250 [==============================] - ETA: 0s - loss: 0.1924 - mean_absolute_error: 0.1924\n",
      "Epoch 00391: val_loss did not improve from 0.24498\n",
      "6250/6250 [==============================] - 5s 725us/step - loss: 0.1924 - mean_absolute_error: 0.1924 - val_loss: 0.2480 - val_mean_absolute_error: 0.2480\n",
      "Epoch 392/1000\n",
      "6211/6250 [============================>.] - ETA: 0s - loss: 0.1933 - mean_absolute_error: 0.1933\n",
      "Epoch 00392: val_loss did not improve from 0.24498\n",
      "6250/6250 [==============================] - 4s 683us/step - loss: 0.1931 - mean_absolute_error: 0.1931 - val_loss: 0.2511 - val_mean_absolute_error: 0.2511\n",
      "Epoch 393/1000\n",
      "6211/6250 [============================>.] - ETA: 0s - loss: 0.1916 - mean_absolute_error: 0.1916\n",
      "Epoch 00393: val_loss did not improve from 0.24498\n",
      "6250/6250 [==============================] - 4s 686us/step - loss: 0.1925 - mean_absolute_error: 0.1925 - val_loss: 0.2525 - val_mean_absolute_error: 0.2525\n",
      "Epoch 394/1000\n",
      "6193/6250 [============================>.] - ETA: 0s - loss: 0.1930 - mean_absolute_error: 0.1930\n",
      "Epoch 00394: val_loss did not improve from 0.24498\n",
      "6250/6250 [==============================] - 5s 725us/step - loss: 0.1932 - mean_absolute_error: 0.1932 - val_loss: 0.2478 - val_mean_absolute_error: 0.2478\n",
      "Epoch 395/1000\n",
      "6183/6250 [============================>.] - ETA: 0s - loss: 0.1922 - mean_absolute_error: 0.1922\n",
      "Epoch 00395: val_loss did not improve from 0.24498\n",
      "6250/6250 [==============================] - 4s 690us/step - loss: 0.1922 - mean_absolute_error: 0.1922 - val_loss: 0.2487 - val_mean_absolute_error: 0.2487\n",
      "Epoch 396/1000\n",
      "6239/6250 [============================>.] - ETA: 0s - loss: 0.1920 - mean_absolute_error: 0.1920\n",
      "Epoch 00396: val_loss improved from 0.24498 to 0.24435, saving model to model_dl.h5\n",
      "6250/6250 [==============================] - 4s 682us/step - loss: 0.1921 - mean_absolute_error: 0.1921 - val_loss: 0.2444 - val_mean_absolute_error: 0.2444\n",
      "Epoch 397/1000\n",
      "6198/6250 [============================>.] - ETA: 0s - loss: 0.1929 - mean_absolute_error: 0.1929\n",
      "Epoch 00397: val_loss did not improve from 0.24435\n",
      "6250/6250 [==============================] - 4s 684us/step - loss: 0.1923 - mean_absolute_error: 0.1923 - val_loss: 0.2469 - val_mean_absolute_error: 0.2469\n",
      "Epoch 398/1000\n",
      "6240/6250 [============================>.] - ETA: 0s - loss: 0.1912 - mean_absolute_error: 0.1912\n",
      "Epoch 00398: val_loss did not improve from 0.24435\n",
      "6250/6250 [==============================] - 5s 739us/step - loss: 0.1911 - mean_absolute_error: 0.1911 - val_loss: 0.2476 - val_mean_absolute_error: 0.2476\n",
      "Epoch 399/1000\n",
      "6225/6250 [============================>.] - ETA: 0s - loss: 0.1908 - mean_absolute_error: 0.1908\n",
      "Epoch 00399: val_loss did not improve from 0.24435\n",
      "6250/6250 [==============================] - 4s 684us/step - loss: 0.1916 - mean_absolute_error: 0.1916 - val_loss: 0.2507 - val_mean_absolute_error: 0.2507\n",
      "Epoch 400/1000\n",
      "6192/6250 [============================>.] - ETA: 0s - loss: 0.1915 - mean_absolute_error: 0.1915\n",
      "Epoch 00400: val_loss did not improve from 0.24435\n",
      "6250/6250 [==============================] - 4s 686us/step - loss: 0.1915 - mean_absolute_error: 0.1915 - val_loss: 0.2520 - val_mean_absolute_error: 0.2520\n",
      "Epoch 401/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6249/6250 [============================>.] - ETA: 0s - loss: 0.1915 - mean_absolute_error: 0.1915\n",
      "Epoch 00401: val_loss did not improve from 0.24435\n",
      "6250/6250 [==============================] - 4s 696us/step - loss: 0.1915 - mean_absolute_error: 0.1915 - val_loss: 0.2536 - val_mean_absolute_error: 0.2536\n",
      "Epoch 402/1000\n",
      "6238/6250 [============================>.] - ETA: 0s - loss: 0.1921 - mean_absolute_error: 0.1921\n",
      "Epoch 00402: val_loss did not improve from 0.24435\n",
      "6250/6250 [==============================] - 5s 724us/step - loss: 0.1921 - mean_absolute_error: 0.1921 - val_loss: 0.2472 - val_mean_absolute_error: 0.2472\n",
      "Epoch 403/1000\n",
      "6184/6250 [============================>.] - ETA: 0s - loss: 0.1905 - mean_absolute_error: 0.1905\n",
      "Epoch 00403: val_loss did not improve from 0.24435\n",
      "6250/6250 [==============================] - 4s 680us/step - loss: 0.1907 - mean_absolute_error: 0.1907 - val_loss: 0.2458 - val_mean_absolute_error: 0.2458\n",
      "Epoch 404/1000\n",
      "6165/6250 [============================>.] - ETA: 0s - loss: 0.1918 - mean_absolute_error: 0.1918\n",
      "Epoch 00404: val_loss did not improve from 0.24435\n",
      "6250/6250 [==============================] - 4s 686us/step - loss: 0.1917 - mean_absolute_error: 0.1917 - val_loss: 0.2479 - val_mean_absolute_error: 0.2479\n",
      "Epoch 405/1000\n",
      "6240/6250 [============================>.] - ETA: 0s - loss: 0.1924 - mean_absolute_error: 0.1924\n",
      "Epoch 00405: val_loss did not improve from 0.24435\n",
      "6250/6250 [==============================] - 5s 731us/step - loss: 0.1922 - mean_absolute_error: 0.1922 - val_loss: 0.2477 - val_mean_absolute_error: 0.2477\n",
      "Epoch 406/1000\n",
      "6245/6250 [============================>.] - ETA: 0s - loss: 0.1917 - mean_absolute_error: 0.1917\n",
      "Epoch 00406: val_loss did not improve from 0.24435\n",
      "6250/6250 [==============================] - 4s 688us/step - loss: 0.1917 - mean_absolute_error: 0.1917 - val_loss: 0.2487 - val_mean_absolute_error: 0.2487\n",
      "Epoch 407/1000\n",
      "6221/6250 [============================>.] - ETA: 0s - loss: 0.1914 - mean_absolute_error: 0.1914\n",
      "Epoch 00407: val_loss did not improve from 0.24435\n",
      "6250/6250 [==============================] - 4s 680us/step - loss: 0.1916 - mean_absolute_error: 0.1916 - val_loss: 0.2486 - val_mean_absolute_error: 0.2486\n",
      "Epoch 408/1000\n",
      "6197/6250 [============================>.] - ETA: 0s - loss: 0.1894 - mean_absolute_error: 0.1894\n",
      "Epoch 00408: val_loss did not improve from 0.24435\n",
      "6250/6250 [==============================] - 4s 684us/step - loss: 0.1913 - mean_absolute_error: 0.1913 - val_loss: 0.2496 - val_mean_absolute_error: 0.2496\n",
      "Epoch 409/1000\n",
      "6196/6250 [============================>.] - ETA: 0s - loss: 0.1904 - mean_absolute_error: 0.1904\n",
      "Epoch 00409: val_loss did not improve from 0.24435\n",
      "6250/6250 [==============================] - 5s 733us/step - loss: 0.1907 - mean_absolute_error: 0.1907 - val_loss: 0.2514 - val_mean_absolute_error: 0.2514\n",
      "Epoch 410/1000\n",
      "6214/6250 [============================>.] - ETA: 0s - loss: 0.1910 - mean_absolute_error: 0.1910\n",
      "Epoch 00410: val_loss did not improve from 0.24435\n",
      "6250/6250 [==============================] - 4s 684us/step - loss: 0.1910 - mean_absolute_error: 0.1910 - val_loss: 0.2450 - val_mean_absolute_error: 0.2450\n",
      "Epoch 411/1000\n",
      "6188/6250 [============================>.] - ETA: 0s - loss: 0.1902 - mean_absolute_error: 0.1902\n",
      "Epoch 00411: val_loss did not improve from 0.24435\n",
      "6250/6250 [==============================] - 4s 685us/step - loss: 0.1903 - mean_absolute_error: 0.1903 - val_loss: 0.2472 - val_mean_absolute_error: 0.2472\n",
      "Epoch 412/1000\n",
      "6202/6250 [============================>.] - ETA: 0s - loss: 0.1912 - mean_absolute_error: 0.1912\n",
      "Epoch 00412: val_loss did not improve from 0.24435\n",
      "6250/6250 [==============================] - 4s 694us/step - loss: 0.1910 - mean_absolute_error: 0.1910 - val_loss: 0.2499 - val_mean_absolute_error: 0.2499\n",
      "Epoch 413/1000\n",
      "6244/6250 [============================>.] - ETA: 0s - loss: 0.1906 - mean_absolute_error: 0.1906\n",
      "Epoch 00413: val_loss did not improve from 0.24435\n",
      "6250/6250 [==============================] - 5s 726us/step - loss: 0.1906 - mean_absolute_error: 0.1906 - val_loss: 0.2467 - val_mean_absolute_error: 0.2467\n",
      "Epoch 414/1000\n",
      "6213/6250 [============================>.] - ETA: 0s - loss: 0.1896 - mean_absolute_error: 0.1896\n",
      "Epoch 00414: val_loss did not improve from 0.24435\n",
      "6250/6250 [==============================] - 4s 683us/step - loss: 0.1903 - mean_absolute_error: 0.1903 - val_loss: 0.2523 - val_mean_absolute_error: 0.2523\n",
      "Epoch 415/1000\n",
      "6181/6250 [============================>.] - ETA: 0s - loss: 0.1898 - mean_absolute_error: 0.1898\n",
      "Epoch 00415: val_loss did not improve from 0.24435\n",
      "6250/6250 [==============================] - 4s 692us/step - loss: 0.1904 - mean_absolute_error: 0.1904 - val_loss: 0.2530 - val_mean_absolute_error: 0.2530\n",
      "Epoch 416/1000\n",
      "6184/6250 [============================>.] - ETA: 0s - loss: 0.1901 - mean_absolute_error: 0.1901\n",
      "Epoch 00416: val_loss did not improve from 0.24435\n",
      "6250/6250 [==============================] - 5s 729us/step - loss: 0.1908 - mean_absolute_error: 0.1908 - val_loss: 0.2478 - val_mean_absolute_error: 0.2478\n",
      "Epoch 417/1000\n",
      "6238/6250 [============================>.] - ETA: 0s - loss: 0.1903 - mean_absolute_error: 0.1903\n",
      "Epoch 00417: val_loss did not improve from 0.24435\n",
      "6250/6250 [==============================] - 4s 689us/step - loss: 0.1908 - mean_absolute_error: 0.1908 - val_loss: 0.2457 - val_mean_absolute_error: 0.2457\n",
      "Epoch 418/1000\n",
      "6184/6250 [============================>.] - ETA: 0s - loss: 0.1904 - mean_absolute_error: 0.1904\n",
      "Epoch 00418: val_loss did not improve from 0.24435\n",
      "6250/6250 [==============================] - 4s 685us/step - loss: 0.1899 - mean_absolute_error: 0.1899 - val_loss: 0.2500 - val_mean_absolute_error: 0.2500\n",
      "Epoch 419/1000\n",
      "6182/6250 [============================>.] - ETA: 0s - loss: 0.1897 - mean_absolute_error: 0.1897\n",
      "Epoch 00419: val_loss did not improve from 0.24435\n",
      "6250/6250 [==============================] - 4s 690us/step - loss: 0.1901 - mean_absolute_error: 0.1901 - val_loss: 0.2470 - val_mean_absolute_error: 0.2470\n",
      "Epoch 420/1000\n",
      "6204/6250 [============================>.] - ETA: 0s - loss: 0.1893 - mean_absolute_error: 0.1893\n",
      "Epoch 00420: val_loss did not improve from 0.24435\n",
      "6250/6250 [==============================] - 5s 738us/step - loss: 0.1896 - mean_absolute_error: 0.1896 - val_loss: 0.2495 - val_mean_absolute_error: 0.2495\n",
      "Epoch 421/1000\n",
      "6220/6250 [============================>.] - ETA: 0s - loss: 0.1911 - mean_absolute_error: 0.1911\n",
      "Epoch 00421: val_loss did not improve from 0.24435\n",
      "6250/6250 [==============================] - 4s 683us/step - loss: 0.1909 - mean_absolute_error: 0.1909 - val_loss: 0.2477 - val_mean_absolute_error: 0.2477\n",
      "Epoch 422/1000\n",
      "6234/6250 [============================>.] - ETA: 0s - loss: 0.1888 - mean_absolute_error: 0.1888\n",
      "Epoch 00422: val_loss did not improve from 0.24435\n",
      "6250/6250 [==============================] - 4s 682us/step - loss: 0.1887 - mean_absolute_error: 0.1887 - val_loss: 0.2471 - val_mean_absolute_error: 0.2471\n",
      "Epoch 423/1000\n",
      "6243/6250 [============================>.] - ETA: 0s - loss: 0.1894 - mean_absolute_error: 0.1894\n",
      "Epoch 00423: val_loss did not improve from 0.24435\n",
      "6250/6250 [==============================] - 4s 692us/step - loss: 0.1897 - mean_absolute_error: 0.1897 - val_loss: 0.2464 - val_mean_absolute_error: 0.2464\n",
      "Epoch 424/1000\n",
      "6223/6250 [============================>.] - ETA: 0s - loss: 0.1891 - mean_absolute_error: 0.1891\n",
      "Epoch 00424: val_loss did not improve from 0.24435\n",
      "6250/6250 [==============================] - 4s 717us/step - loss: 0.1893 - mean_absolute_error: 0.1893 - val_loss: 0.2491 - val_mean_absolute_error: 0.2491\n",
      "Epoch 425/1000\n",
      "6246/6250 [============================>.] - ETA: 0s - loss: 0.1902 - mean_absolute_error: 0.1902\n",
      "Epoch 00425: val_loss did not improve from 0.24435\n",
      "6250/6250 [==============================] - 4s 684us/step - loss: 0.1904 - mean_absolute_error: 0.1904 - val_loss: 0.2446 - val_mean_absolute_error: 0.2446\n",
      "Epoch 426/1000\n",
      "6183/6250 [============================>.] - ETA: 0s - loss: 0.1874 - mean_absolute_error: 0.1874\n",
      "Epoch 00426: val_loss improved from 0.24435 to 0.24378, saving model to model_dl.h5\n",
      "6250/6250 [==============================] - 4s 694us/step - loss: 0.1888 - mean_absolute_error: 0.1888 - val_loss: 0.2438 - val_mean_absolute_error: 0.2438\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 427/1000\n",
      "6237/6250 [============================>.] - ETA: 0s - loss: 0.1896 - mean_absolute_error: 0.1896\n",
      "Epoch 00427: val_loss improved from 0.24378 to 0.24291, saving model to model_dl.h5\n",
      "6250/6250 [==============================] - 5s 727us/step - loss: 0.1899 - mean_absolute_error: 0.1899 - val_loss: 0.2429 - val_mean_absolute_error: 0.2429\n",
      "Epoch 428/1000\n",
      "6192/6250 [============================>.] - ETA: 0s - loss: 0.1893 - mean_absolute_error: 0.1893\n",
      "Epoch 00428: val_loss did not improve from 0.24291\n",
      "6250/6250 [==============================] - 4s 694us/step - loss: 0.1889 - mean_absolute_error: 0.1889 - val_loss: 0.2489 - val_mean_absolute_error: 0.2489\n",
      "Epoch 429/1000\n",
      "6205/6250 [============================>.] - ETA: 0s - loss: 0.1897 - mean_absolute_error: 0.1897\n",
      "Epoch 00429: val_loss did not improve from 0.24291\n",
      "6250/6250 [==============================] - 4s 684us/step - loss: 0.1892 - mean_absolute_error: 0.1892 - val_loss: 0.2451 - val_mean_absolute_error: 0.2451\n",
      "Epoch 430/1000\n",
      "6201/6250 [============================>.] - ETA: 0s - loss: 0.1886 - mean_absolute_error: 0.1886\n",
      "Epoch 00430: val_loss did not improve from 0.24291\n",
      "6250/6250 [==============================] - 4s 684us/step - loss: 0.1889 - mean_absolute_error: 0.1889 - val_loss: 0.2442 - val_mean_absolute_error: 0.2442\n",
      "Epoch 431/1000\n",
      "6231/6250 [============================>.] - ETA: 0s - loss: 0.1895 - mean_absolute_error: 0.1895\n",
      "Epoch 00431: val_loss did not improve from 0.24291\n",
      "6250/6250 [==============================] - 5s 731us/step - loss: 0.1895 - mean_absolute_error: 0.1895 - val_loss: 0.2468 - val_mean_absolute_error: 0.2468\n",
      "Epoch 432/1000\n",
      "6189/6250 [============================>.] - ETA: 0s - loss: 0.1885 - mean_absolute_error: 0.1885\n",
      "Epoch 00432: val_loss did not improve from 0.24291\n",
      "6250/6250 [==============================] - 4s 685us/step - loss: 0.1885 - mean_absolute_error: 0.1885 - val_loss: 0.2461 - val_mean_absolute_error: 0.2461\n",
      "Epoch 433/1000\n",
      "6185/6250 [============================>.] - ETA: 0s - loss: 0.1880 - mean_absolute_error: 0.1880\n",
      "Epoch 00433: val_loss did not improve from 0.24291\n",
      "6250/6250 [==============================] - 4s 685us/step - loss: 0.1891 - mean_absolute_error: 0.1891 - val_loss: 0.2470 - val_mean_absolute_error: 0.2470\n",
      "Epoch 434/1000\n",
      "6165/6250 [============================>.] - ETA: 0s - loss: 0.1886 - mean_absolute_error: 0.1886\n",
      "Epoch 00434: val_loss did not improve from 0.24291\n",
      "6250/6250 [==============================] - 4s 701us/step - loss: 0.1887 - mean_absolute_error: 0.1887 - val_loss: 0.2461 - val_mean_absolute_error: 0.2461\n",
      "Epoch 435/1000\n",
      "6177/6250 [============================>.] - ETA: 0s - loss: 0.1888 - mean_absolute_error: 0.1888\n",
      "Epoch 00435: val_loss did not improve from 0.24291\n",
      "6250/6250 [==============================] - 5s 720us/step - loss: 0.1886 - mean_absolute_error: 0.1886 - val_loss: 0.2443 - val_mean_absolute_error: 0.2443\n",
      "Epoch 436/1000\n",
      "6204/6250 [============================>.] - ETA: 0s - loss: 0.1892 - mean_absolute_error: 0.1892\n",
      "Epoch 00436: val_loss did not improve from 0.24291\n",
      "6250/6250 [==============================] - 4s 684us/step - loss: 0.1888 - mean_absolute_error: 0.1888 - val_loss: 0.2479 - val_mean_absolute_error: 0.2479\n",
      "Epoch 437/1000\n",
      "6191/6250 [============================>.] - ETA: 0s - loss: 0.1879 - mean_absolute_error: 0.1879\n",
      "Epoch 00437: val_loss did not improve from 0.24291\n",
      "6250/6250 [==============================] - 4s 684us/step - loss: 0.1882 - mean_absolute_error: 0.1882 - val_loss: 0.2491 - val_mean_absolute_error: 0.2491\n",
      "Epoch 438/1000\n",
      "6245/6250 [============================>.] - ETA: 0s - loss: 0.1879 - mean_absolute_error: 0.1879\n",
      "Epoch 00438: val_loss did not improve from 0.24291\n",
      "6250/6250 [==============================] - 5s 734us/step - loss: 0.1879 - mean_absolute_error: 0.1879 - val_loss: 0.2487 - val_mean_absolute_error: 0.2487\n",
      "Epoch 439/1000\n",
      "6226/6250 [============================>.] - ETA: 0s - loss: 0.1882 - mean_absolute_error: 0.1882\n",
      "Epoch 00439: val_loss did not improve from 0.24291\n",
      "6250/6250 [==============================] - 4s 692us/step - loss: 0.1880 - mean_absolute_error: 0.1880 - val_loss: 0.2459 - val_mean_absolute_error: 0.2459\n",
      "Epoch 440/1000\n",
      "6180/6250 [============================>.] - ETA: 0s - loss: 0.1865 - mean_absolute_error: 0.1865\n",
      "Epoch 00440: val_loss did not improve from 0.24291\n",
      "6250/6250 [==============================] - 4s 687us/step - loss: 0.1870 - mean_absolute_error: 0.1870 - val_loss: 0.2485 - val_mean_absolute_error: 0.2485\n",
      "Epoch 441/1000\n",
      "6189/6250 [============================>.] - ETA: 0s - loss: 0.1890 - mean_absolute_error: 0.1890\n",
      "Epoch 00441: val_loss did not improve from 0.24291\n",
      "6250/6250 [==============================] - 4s 686us/step - loss: 0.1884 - mean_absolute_error: 0.1884 - val_loss: 0.2448 - val_mean_absolute_error: 0.2448\n",
      "Epoch 442/1000\n",
      "6198/6250 [============================>.] - ETA: 0s - loss: 0.1879 - mean_absolute_error: 0.1879\n",
      "Epoch 00442: val_loss did not improve from 0.24291\n",
      "6250/6250 [==============================] - 5s 742us/step - loss: 0.1877 - mean_absolute_error: 0.1877 - val_loss: 0.2471 - val_mean_absolute_error: 0.2471\n",
      "Epoch 443/1000\n",
      "6198/6250 [============================>.] - ETA: 0s - loss: 0.1884 - mean_absolute_error: 0.1884\n",
      "Epoch 00443: val_loss did not improve from 0.24291\n",
      "6250/6250 [==============================] - 4s 686us/step - loss: 0.1877 - mean_absolute_error: 0.1877 - val_loss: 0.2441 - val_mean_absolute_error: 0.2441\n",
      "Epoch 444/1000\n",
      "6215/6250 [============================>.] - ETA: 0s - loss: 0.1880 - mean_absolute_error: 0.1880\n",
      "Epoch 00444: val_loss did not improve from 0.24291\n",
      "6250/6250 [==============================] - 4s 683us/step - loss: 0.1875 - mean_absolute_error: 0.1875 - val_loss: 0.2524 - val_mean_absolute_error: 0.2524\n",
      "Epoch 445/1000\n",
      "6207/6250 [============================>.] - ETA: 0s - loss: 0.1881 - mean_absolute_error: 0.1881\n",
      "Epoch 00445: val_loss did not improve from 0.24291\n",
      "6250/6250 [==============================] - 4s 698us/step - loss: 0.1880 - mean_absolute_error: 0.1880 - val_loss: 0.2465 - val_mean_absolute_error: 0.2465\n",
      "Epoch 446/1000\n",
      "6187/6250 [============================>.] - ETA: 0s - loss: 0.1875 - mean_absolute_error: 0.1875\n",
      "Epoch 00446: val_loss did not improve from 0.24291\n",
      "6250/6250 [==============================] - 5s 723us/step - loss: 0.1875 - mean_absolute_error: 0.1875 - val_loss: 0.2433 - val_mean_absolute_error: 0.2433\n",
      "Epoch 447/1000\n",
      "6204/6250 [============================>.] - ETA: 0s - loss: 0.1877 - mean_absolute_error: 0.1877\n",
      "Epoch 00447: val_loss did not improve from 0.24291\n",
      "6250/6250 [==============================] - 4s 684us/step - loss: 0.1877 - mean_absolute_error: 0.1877 - val_loss: 0.2446 - val_mean_absolute_error: 0.2446\n",
      "Epoch 448/1000\n",
      "6247/6250 [============================>.] - ETA: 0s - loss: 0.1878 - mean_absolute_error: 0.1878\n",
      "Epoch 00448: val_loss did not improve from 0.24291\n",
      "6250/6250 [==============================] - 4s 691us/step - loss: 0.1878 - mean_absolute_error: 0.1878 - val_loss: 0.2504 - val_mean_absolute_error: 0.2504\n",
      "Epoch 449/1000\n",
      "6186/6250 [============================>.] - ETA: 0s - loss: 0.1867 - mean_absolute_error: 0.1867\n",
      "Epoch 00449: val_loss improved from 0.24291 to 0.24285, saving model to model_dl.h5\n",
      "6250/6250 [==============================] - 5s 734us/step - loss: 0.1873 - mean_absolute_error: 0.1873 - val_loss: 0.2429 - val_mean_absolute_error: 0.2429\n",
      "Epoch 450/1000\n",
      "6229/6250 [============================>.] - ETA: 0s - loss: 0.1873 - mean_absolute_error: 0.1873\n",
      "Epoch 00450: val_loss did not improve from 0.24285\n",
      "6250/6250 [==============================] - 4s 691us/step - loss: 0.1872 - mean_absolute_error: 0.1872 - val_loss: 0.2466 - val_mean_absolute_error: 0.2466\n",
      "Epoch 451/1000\n",
      "6197/6250 [============================>.] - ETA: 0s - loss: 0.1874 - mean_absolute_error: 0.1874\n",
      "Epoch 00451: val_loss did not improve from 0.24285\n",
      "6250/6250 [==============================] - 4s 687us/step - loss: 0.1876 - mean_absolute_error: 0.1876 - val_loss: 0.2442 - val_mean_absolute_error: 0.2442\n",
      "Epoch 452/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6170/6250 [============================>.] - ETA: 0s - loss: 0.1860 - mean_absolute_error: 0.1860\n",
      "Epoch 00452: val_loss did not improve from 0.24285\n",
      "6250/6250 [==============================] - 4s 688us/step - loss: 0.1867 - mean_absolute_error: 0.1867 - val_loss: 0.2465 - val_mean_absolute_error: 0.2465\n",
      "Epoch 453/1000\n",
      "6195/6250 [============================>.] - ETA: 0s - loss: 0.1860 - mean_absolute_error: 0.1860\n",
      "Epoch 00453: val_loss did not improve from 0.24285\n",
      "6250/6250 [==============================] - 5s 738us/step - loss: 0.1866 - mean_absolute_error: 0.1866 - val_loss: 0.2491 - val_mean_absolute_error: 0.2491\n",
      "Epoch 454/1000\n",
      "6183/6250 [============================>.] - ETA: 0s - loss: 0.1859 - mean_absolute_error: 0.1859\n",
      "Epoch 00454: val_loss did not improve from 0.24285\n",
      "6250/6250 [==============================] - 4s 683us/step - loss: 0.1861 - mean_absolute_error: 0.1861 - val_loss: 0.2433 - val_mean_absolute_error: 0.2433\n",
      "Epoch 455/1000\n",
      "6178/6250 [============================>.] - ETA: 0s - loss: 0.1865 - mean_absolute_error: 0.1865\n",
      "Epoch 00455: val_loss improved from 0.24285 to 0.24034, saving model to model_dl.h5\n",
      "6250/6250 [==============================] - 4s 688us/step - loss: 0.1870 - mean_absolute_error: 0.1870 - val_loss: 0.2403 - val_mean_absolute_error: 0.2403\n",
      "Epoch 456/1000\n",
      "6200/6250 [============================>.] - ETA: 0s - loss: 0.1863 - mean_absolute_error: 0.1863\n",
      "Epoch 00456: val_loss did not improve from 0.24034\n",
      "6250/6250 [==============================] - 4s 708us/step - loss: 0.1865 - mean_absolute_error: 0.1865 - val_loss: 0.2450 - val_mean_absolute_error: 0.2450\n",
      "Epoch 457/1000\n",
      "6248/6250 [============================>.] - ETA: 0s - loss: 0.1864 - mean_absolute_error: 0.1864\n",
      "Epoch 00457: val_loss did not improve from 0.24034\n",
      "6250/6250 [==============================] - 4s 716us/step - loss: 0.1866 - mean_absolute_error: 0.1866 - val_loss: 0.2405 - val_mean_absolute_error: 0.2405\n",
      "Epoch 458/1000\n",
      "6173/6250 [============================>.] - ETA: 0s - loss: 0.1859 - mean_absolute_error: 0.1859\n",
      "Epoch 00458: val_loss did not improve from 0.24034\n",
      "6250/6250 [==============================] - 4s 685us/step - loss: 0.1863 - mean_absolute_error: 0.1863 - val_loss: 0.2453 - val_mean_absolute_error: 0.2453\n",
      "Epoch 459/1000\n",
      "6236/6250 [============================>.] - ETA: 0s - loss: 0.1870 - mean_absolute_error: 0.1870\n",
      "Epoch 00459: val_loss did not improve from 0.24034\n",
      "6250/6250 [==============================] - 4s 690us/step - loss: 0.1870 - mean_absolute_error: 0.1870 - val_loss: 0.2450 - val_mean_absolute_error: 0.2450\n",
      "Epoch 460/1000\n",
      "6168/6250 [============================>.] - ETA: 0s - loss: 0.1867 - mean_absolute_error: 0.1867\n",
      "Epoch 00460: val_loss did not improve from 0.24034\n",
      "6250/6250 [==============================] - 5s 734us/step - loss: 0.1866 - mean_absolute_error: 0.1866 - val_loss: 0.2425 - val_mean_absolute_error: 0.2425\n",
      "Epoch 461/1000\n",
      "6174/6250 [============================>.] - ETA: 0s - loss: 0.1862 - mean_absolute_error: 0.1862\n",
      "Epoch 00461: val_loss improved from 0.24034 to 0.23639, saving model to model_dl.h5\n",
      "6250/6250 [==============================] - 4s 697us/step - loss: 0.1858 - mean_absolute_error: 0.1858 - val_loss: 0.2364 - val_mean_absolute_error: 0.2364\n",
      "Epoch 462/1000\n",
      "6210/6250 [============================>.] - ETA: 0s - loss: 0.1869 - mean_absolute_error: 0.1869\n",
      "Epoch 00462: val_loss did not improve from 0.23639\n",
      "6250/6250 [==============================] - 4s 684us/step - loss: 0.1871 - mean_absolute_error: 0.1871 - val_loss: 0.2418 - val_mean_absolute_error: 0.2418\n",
      "Epoch 463/1000\n",
      "6223/6250 [============================>.] - ETA: 0s - loss: 0.1861 - mean_absolute_error: 0.1861\n",
      "Epoch 00463: val_loss did not improve from 0.23639\n",
      "6250/6250 [==============================] - 4s 684us/step - loss: 0.1861 - mean_absolute_error: 0.1861 - val_loss: 0.2400 - val_mean_absolute_error: 0.2400\n",
      "Epoch 464/1000\n",
      "6246/6250 [============================>.] - ETA: 0s - loss: 0.1853 - mean_absolute_error: 0.1853\n",
      "Epoch 00464: val_loss did not improve from 0.23639\n",
      "6250/6250 [==============================] - 5s 736us/step - loss: 0.1853 - mean_absolute_error: 0.1853 - val_loss: 0.2427 - val_mean_absolute_error: 0.2427\n",
      "Epoch 465/1000\n",
      "6200/6250 [============================>.] - ETA: 0s - loss: 0.1853 - mean_absolute_error: 0.1853\n",
      "Epoch 00465: val_loss did not improve from 0.23639\n",
      "6250/6250 [==============================] - 4s 683us/step - loss: 0.1850 - mean_absolute_error: 0.1850 - val_loss: 0.2450 - val_mean_absolute_error: 0.2450\n",
      "Epoch 466/1000\n",
      "6185/6250 [============================>.] - ETA: 0s - loss: 0.1859 - mean_absolute_error: 0.1859\n",
      "Epoch 00466: val_loss did not improve from 0.23639\n",
      "6250/6250 [==============================] - 4s 687us/step - loss: 0.1860 - mean_absolute_error: 0.1860 - val_loss: 0.2411 - val_mean_absolute_error: 0.2411\n",
      "Epoch 467/1000\n",
      "6192/6250 [============================>.] - ETA: 0s - loss: 0.1851 - mean_absolute_error: 0.1851\n",
      "Epoch 00467: val_loss did not improve from 0.23639\n",
      "6250/6250 [==============================] - 4s 712us/step - loss: 0.1856 - mean_absolute_error: 0.1856 - val_loss: 0.2448 - val_mean_absolute_error: 0.2448\n",
      "Epoch 468/1000\n",
      "6165/6250 [============================>.] - ETA: 0s - loss: 0.1852 - mean_absolute_error: 0.1852\n",
      "Epoch 00468: val_loss did not improve from 0.23639\n",
      "6250/6250 [==============================] - 4s 705us/step - loss: 0.1852 - mean_absolute_error: 0.1852 - val_loss: 0.2457 - val_mean_absolute_error: 0.2457\n",
      "Epoch 469/1000\n",
      "6211/6250 [============================>.] - ETA: 0s - loss: 0.1853 - mean_absolute_error: 0.1853\n",
      "Epoch 00469: val_loss did not improve from 0.23639\n",
      "6250/6250 [==============================] - 4s 685us/step - loss: 0.1853 - mean_absolute_error: 0.1853 - val_loss: 0.2437 - val_mean_absolute_error: 0.2437\n",
      "Epoch 470/1000\n",
      "6183/6250 [============================>.] - ETA: 0s - loss: 0.1860 - mean_absolute_error: 0.1860\n",
      "Epoch 00470: val_loss did not improve from 0.23639\n",
      "6250/6250 [==============================] - 4s 689us/step - loss: 0.1860 - mean_absolute_error: 0.1860 - val_loss: 0.2421 - val_mean_absolute_error: 0.2421\n",
      "Epoch 471/1000\n",
      "6212/6250 [============================>.] - ETA: 0s - loss: 0.1839 - mean_absolute_error: 0.1839\n",
      "Epoch 00471: val_loss did not improve from 0.23639\n",
      "6250/6250 [==============================] - 5s 736us/step - loss: 0.1846 - mean_absolute_error: 0.1846 - val_loss: 0.2493 - val_mean_absolute_error: 0.2493\n",
      "Epoch 472/1000\n",
      "6191/6250 [============================>.] - ETA: 0s - loss: 0.1853 - mean_absolute_error: 0.1853\n",
      "Epoch 00472: val_loss did not improve from 0.23639\n",
      "6250/6250 [==============================] - 4s 687us/step - loss: 0.1847 - mean_absolute_error: 0.1847 - val_loss: 0.2402 - val_mean_absolute_error: 0.2402\n",
      "Epoch 473/1000\n",
      "6215/6250 [============================>.] - ETA: 0s - loss: 0.1852 - mean_absolute_error: 0.1852\n",
      "Epoch 00473: val_loss did not improve from 0.23639\n",
      "6250/6250 [==============================] - 4s 691us/step - loss: 0.1855 - mean_absolute_error: 0.1855 - val_loss: 0.2415 - val_mean_absolute_error: 0.2415\n",
      "Epoch 474/1000\n",
      "6168/6250 [============================>.] - ETA: 0s - loss: 0.1837 - mean_absolute_error: 0.1837\n",
      "Epoch 00474: val_loss did not improve from 0.23639\n",
      "6250/6250 [==============================] - 4s 687us/step - loss: 0.1847 - mean_absolute_error: 0.1847 - val_loss: 0.2438 - val_mean_absolute_error: 0.2438\n",
      "Epoch 475/1000\n",
      "6199/6250 [============================>.] - ETA: 0s - loss: 0.1847 - mean_absolute_error: 0.1847\n",
      "Epoch 00475: val_loss did not improve from 0.23639\n",
      "6250/6250 [==============================] - 6s 918us/step - loss: 0.1850 - mean_absolute_error: 0.1850 - val_loss: 0.2453 - val_mean_absolute_error: 0.2453\n",
      "Epoch 476/1000\n",
      "6192/6250 [============================>.] - ETA: 0s - loss: 0.1852 - mean_absolute_error: 0.1852\n",
      "Epoch 00476: val_loss did not improve from 0.23639\n",
      "6250/6250 [==============================] - 5s 753us/step - loss: 0.1853 - mean_absolute_error: 0.1853 - val_loss: 0.2400 - val_mean_absolute_error: 0.2400\n",
      "Epoch 477/1000\n",
      "6231/6250 [============================>.] - ETA: 0s - loss: 0.1852 - mean_absolute_error: 0.1852\n",
      "Epoch 00477: val_loss did not improve from 0.23639\n",
      "6250/6250 [==============================] - 4s 691us/step - loss: 0.1853 - mean_absolute_error: 0.1853 - val_loss: 0.2425 - val_mean_absolute_error: 0.2425\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 478/1000\n",
      "6192/6250 [============================>.] - ETA: 0s - loss: 0.1843 - mean_absolute_error: 0.1843\n",
      "Epoch 00478: val_loss did not improve from 0.23639\n",
      "6250/6250 [==============================] - 5s 735us/step - loss: 0.1846 - mean_absolute_error: 0.1846 - val_loss: 0.2387 - val_mean_absolute_error: 0.2387\n",
      "Epoch 479/1000\n",
      "6233/6250 [============================>.] - ETA: 0s - loss: 0.1851 - mean_absolute_error: 0.1851\n",
      "Epoch 00479: val_loss did not improve from 0.23639\n",
      "6250/6250 [==============================] - 4s 687us/step - loss: 0.1854 - mean_absolute_error: 0.1854 - val_loss: 0.2429 - val_mean_absolute_error: 0.2429\n",
      "Epoch 480/1000\n",
      "6244/6250 [============================>.] - ETA: 0s - loss: 0.1850 - mean_absolute_error: 0.1850\n",
      "Epoch 00480: val_loss did not improve from 0.23639\n",
      "6250/6250 [==============================] - 4s 689us/step - loss: 0.1849 - mean_absolute_error: 0.1849 - val_loss: 0.2380 - val_mean_absolute_error: 0.2380\n",
      "Epoch 481/1000\n",
      "6234/6250 [============================>.] - ETA: 0s - loss: 0.1851 - mean_absolute_error: 0.1851\n",
      "Epoch 00481: val_loss did not improve from 0.23639\n",
      "6250/6250 [==============================] - 4s 690us/step - loss: 0.1852 - mean_absolute_error: 0.1852 - val_loss: 0.2421 - val_mean_absolute_error: 0.2421\n",
      "Epoch 482/1000\n",
      "6221/6250 [============================>.] - ETA: 0s - loss: 0.1844 - mean_absolute_error: 0.1844\n",
      "Epoch 00482: val_loss did not improve from 0.23639\n",
      "6250/6250 [==============================] - 5s 734us/step - loss: 0.1842 - mean_absolute_error: 0.1842 - val_loss: 0.2387 - val_mean_absolute_error: 0.2387\n",
      "Epoch 483/1000\n",
      "6190/6250 [============================>.] - ETA: 0s - loss: 0.1843 - mean_absolute_error: 0.1843\n",
      "Epoch 00483: val_loss did not improve from 0.23639\n",
      "6250/6250 [==============================] - 4s 685us/step - loss: 0.1848 - mean_absolute_error: 0.1848 - val_loss: 0.2382 - val_mean_absolute_error: 0.2382\n",
      "Epoch 484/1000\n",
      "6226/6250 [============================>.] - ETA: 0s - loss: 0.1844 - mean_absolute_error: 0.1844\n",
      "Epoch 00484: val_loss did not improve from 0.23639\n",
      "6250/6250 [==============================] - 5s 727us/step - loss: 0.1845 - mean_absolute_error: 0.1845 - val_loss: 0.2388 - val_mean_absolute_error: 0.2388\n",
      "Epoch 485/1000\n",
      "6218/6250 [============================>.] - ETA: 0s - loss: 0.1845 - mean_absolute_error: 0.1845\n",
      "Epoch 00485: val_loss did not improve from 0.23639\n",
      "6250/6250 [==============================] - 4s 717us/step - loss: 0.1842 - mean_absolute_error: 0.1842 - val_loss: 0.2368 - val_mean_absolute_error: 0.2368\n",
      "Epoch 486/1000\n",
      "6191/6250 [============================>.] - ETA: 0s - loss: 0.1843 - mean_absolute_error: 0.1843\n",
      "Epoch 00486: val_loss did not improve from 0.23639\n",
      "6250/6250 [==============================] - 5s 720us/step - loss: 0.1843 - mean_absolute_error: 0.1843 - val_loss: 0.2402 - val_mean_absolute_error: 0.2402\n",
      "Epoch 487/1000\n",
      "6244/6250 [============================>.] - ETA: 0s - loss: 0.1838 - mean_absolute_error: 0.1838\n",
      "Epoch 00487: val_loss did not improve from 0.23639\n",
      "6250/6250 [==============================] - 5s 855us/step - loss: 0.1838 - mean_absolute_error: 0.1838 - val_loss: 0.2385 - val_mean_absolute_error: 0.2385\n",
      "Epoch 488/1000\n",
      "6198/6250 [============================>.] - ETA: 0s - loss: 0.1845 - mean_absolute_error: 0.1845\n",
      "Epoch 00488: val_loss did not improve from 0.23639\n",
      "6250/6250 [==============================] - 4s 695us/step - loss: 0.1840 - mean_absolute_error: 0.1840 - val_loss: 0.2418 - val_mean_absolute_error: 0.2418\n",
      "Epoch 489/1000\n",
      "6177/6250 [============================>.] - ETA: 0s - loss: 0.1838 - mean_absolute_error: 0.1838\n",
      "Epoch 00489: val_loss did not improve from 0.23639\n",
      "6250/6250 [==============================] - 5s 741us/step - loss: 0.1842 - mean_absolute_error: 0.1842 - val_loss: 0.2423 - val_mean_absolute_error: 0.2423\n",
      "Epoch 490/1000\n",
      "6178/6250 [============================>.] - ETA: 0s - loss: 0.1844 - mean_absolute_error: 0.1844\n",
      "Epoch 00490: val_loss did not improve from 0.23639\n",
      "6250/6250 [==============================] - 4s 690us/step - loss: 0.1843 - mean_absolute_error: 0.1843 - val_loss: 0.2387 - val_mean_absolute_error: 0.2387\n",
      "Epoch 491/1000\n",
      "6196/6250 [============================>.] - ETA: 0s - loss: 0.1853 - mean_absolute_error: 0.1853\n",
      "Epoch 00491: val_loss did not improve from 0.23639\n",
      "6250/6250 [==============================] - 4s 687us/step - loss: 0.1847 - mean_absolute_error: 0.1847 - val_loss: 0.2409 - val_mean_absolute_error: 0.2409\n",
      "Epoch 492/1000\n",
      "6245/6250 [============================>.] - ETA: 0s - loss: 0.1834 - mean_absolute_error: 0.1834\n",
      "Epoch 00492: val_loss did not improve from 0.23639\n",
      "6250/6250 [==============================] - 4s 706us/step - loss: 0.1833 - mean_absolute_error: 0.1833 - val_loss: 0.2416 - val_mean_absolute_error: 0.2416\n",
      "Epoch 493/1000\n",
      "6195/6250 [============================>.] - ETA: 0s - loss: 0.1838 - mean_absolute_error: 0.1838\n",
      "Epoch 00493: val_loss did not improve from 0.23639\n",
      "6250/6250 [==============================] - 4s 712us/step - loss: 0.1836 - mean_absolute_error: 0.1836 - val_loss: 0.2439 - val_mean_absolute_error: 0.2439\n",
      "Epoch 494/1000\n",
      "6197/6250 [============================>.] - ETA: 0s - loss: 0.1834 - mean_absolute_error: 0.1834\n",
      "Epoch 00494: val_loss did not improve from 0.23639\n",
      "6250/6250 [==============================] - 4s 689us/step - loss: 0.1830 - mean_absolute_error: 0.1830 - val_loss: 0.2435 - val_mean_absolute_error: 0.2435\n",
      "Epoch 495/1000\n",
      "6174/6250 [============================>.] - ETA: 0s - loss: 0.1830 - mean_absolute_error: 0.1830\n",
      "Epoch 00495: val_loss did not improve from 0.23639\n",
      "6250/6250 [==============================] - 4s 688us/step - loss: 0.1831 - mean_absolute_error: 0.1831 - val_loss: 0.2404 - val_mean_absolute_error: 0.2404\n",
      "Epoch 496/1000\n",
      "6185/6250 [============================>.] - ETA: 0s - loss: 0.1829 - mean_absolute_error: 0.1829\n",
      "Epoch 00496: val_loss did not improve from 0.23639\n",
      "6250/6250 [==============================] - 5s 740us/step - loss: 0.1830 - mean_absolute_error: 0.1830 - val_loss: 0.2483 - val_mean_absolute_error: 0.2483\n",
      "Epoch 497/1000\n",
      "6172/6250 [============================>.] - ETA: 0s - loss: 0.1823 - mean_absolute_error: 0.1823\n",
      "Epoch 00497: val_loss did not improve from 0.23639\n",
      "6250/6250 [==============================] - 4s 694us/step - loss: 0.1826 - mean_absolute_error: 0.1826 - val_loss: 0.2393 - val_mean_absolute_error: 0.2393\n",
      "Epoch 498/1000\n",
      "6170/6250 [============================>.] - ETA: 0s - loss: 0.1819 - mean_absolute_error: 0.1819\n",
      "Epoch 00498: val_loss did not improve from 0.23639\n",
      "6250/6250 [==============================] - 4s 687us/step - loss: 0.1818 - mean_absolute_error: 0.1818 - val_loss: 0.2479 - val_mean_absolute_error: 0.2479\n",
      "Epoch 499/1000\n",
      "6172/6250 [============================>.] - ETA: 0s - loss: 0.1833 - mean_absolute_error: 0.1833\n",
      "Epoch 00499: val_loss did not improve from 0.23639\n",
      "6250/6250 [==============================] - 4s 691us/step - loss: 0.1834 - mean_absolute_error: 0.1834 - val_loss: 0.2411 - val_mean_absolute_error: 0.2411\n",
      "Epoch 500/1000\n",
      "6198/6250 [============================>.] - ETA: 0s - loss: 0.1831 - mean_absolute_error: 0.1831\n",
      "Epoch 00500: val_loss did not improve from 0.23639\n",
      "6250/6250 [==============================] - 5s 742us/step - loss: 0.1831 - mean_absolute_error: 0.1831 - val_loss: 0.2449 - val_mean_absolute_error: 0.2449\n",
      "Epoch 501/1000\n",
      "6249/6250 [============================>.] - ETA: 0s - loss: 0.1830 - mean_absolute_error: 0.1830\n",
      "Epoch 00501: val_loss did not improve from 0.23639\n",
      "6250/6250 [==============================] - 4s 689us/step - loss: 0.1830 - mean_absolute_error: 0.1830 - val_loss: 0.2389 - val_mean_absolute_error: 0.2389\n",
      "Epoch 502/1000\n",
      "6240/6250 [============================>.] - ETA: 0s - loss: 0.1826 - mean_absolute_error: 0.1826\n",
      "Epoch 00502: val_loss did not improve from 0.23639\n",
      "6250/6250 [==============================] - 4s 691us/step - loss: 0.1825 - mean_absolute_error: 0.1825 - val_loss: 0.2426 - val_mean_absolute_error: 0.2426\n",
      "Epoch 503/1000\n",
      "6197/6250 [============================>.] - ETA: 0s - loss: 0.1815 - mean_absolute_error: 0.1815\n",
      "Epoch 00503: val_loss did not improve from 0.23639\n",
      "6250/6250 [==============================] - 4s 718us/step - loss: 0.1823 - mean_absolute_error: 0.1823 - val_loss: 0.2401 - val_mean_absolute_error: 0.2401\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 504/1000\n",
      "6242/6250 [============================>.] - ETA: 0s - loss: 0.1827 - mean_absolute_error: 0.1827\n",
      "Epoch 00504: val_loss did not improve from 0.23639\n",
      "6250/6250 [==============================] - 4s 718us/step - loss: 0.1826 - mean_absolute_error: 0.1826 - val_loss: 0.2400 - val_mean_absolute_error: 0.2400\n",
      "Epoch 505/1000\n",
      "6238/6250 [============================>.] - ETA: 0s - loss: 0.1816 - mean_absolute_error: 0.1816\n",
      "Epoch 00505: val_loss did not improve from 0.23639\n",
      "6250/6250 [==============================] - 5s 829us/step - loss: 0.1820 - mean_absolute_error: 0.1820 - val_loss: 0.2374 - val_mean_absolute_error: 0.2374\n",
      "Epoch 506/1000\n",
      "6198/6250 [============================>.] - ETA: 0s - loss: 0.1834 - mean_absolute_error: 0.1834\n",
      "Epoch 00506: val_loss did not improve from 0.23639\n",
      "6250/6250 [==============================] - 5s 790us/step - loss: 0.1830 - mean_absolute_error: 0.1830 - val_loss: 0.2409 - val_mean_absolute_error: 0.2409\n",
      "Epoch 507/1000\n",
      "6244/6250 [============================>.] - ETA: 0s - loss: 0.1823 - mean_absolute_error: 0.1823\n",
      "Epoch 00507: val_loss did not improve from 0.23639\n",
      "6250/6250 [==============================] - 6s 893us/step - loss: 0.1822 - mean_absolute_error: 0.1822 - val_loss: 0.2410 - val_mean_absolute_error: 0.2410\n",
      "Epoch 508/1000\n",
      "6170/6250 [============================>.] - ETA: 0s - loss: 0.1817 - mean_absolute_error: 0.1817\n",
      "Epoch 00508: val_loss did not improve from 0.23639\n",
      "6250/6250 [==============================] - 5s 756us/step - loss: 0.1821 - mean_absolute_error: 0.1821 - val_loss: 0.2409 - val_mean_absolute_error: 0.2409\n",
      "Epoch 509/1000\n",
      "6187/6250 [============================>.] - ETA: 0s - loss: 0.1823 - mean_absolute_error: 0.1823\n",
      "Epoch 00509: val_loss did not improve from 0.23639\n",
      "6250/6250 [==============================] - 5s 762us/step - loss: 0.1819 - mean_absolute_error: 0.1819 - val_loss: 0.2383 - val_mean_absolute_error: 0.2383\n",
      "Epoch 510/1000\n",
      "6203/6250 [============================>.] - ETA: 0s - loss: 0.1826 - mean_absolute_error: 0.1826\n",
      "Epoch 00510: val_loss did not improve from 0.23639\n",
      "6250/6250 [==============================] - 5s 843us/step - loss: 0.1824 - mean_absolute_error: 0.1824 - val_loss: 0.2413 - val_mean_absolute_error: 0.2413\n",
      "Epoch 511/1000\n",
      "6237/6250 [============================>.] - ETA: 0s - loss: 0.1813 - mean_absolute_error: 0.1813\n",
      "Epoch 00511: val_loss did not improve from 0.23639\n",
      "6250/6250 [==============================] - 5s 721us/step - loss: 0.1817 - mean_absolute_error: 0.1817 - val_loss: 0.2408 - val_mean_absolute_error: 0.2408\n",
      "Epoch 00511: early stopping\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    x=X_train, \n",
    "    y=y_train,\n",
    "    batch_size=32,\n",
    "    epochs=1000,\n",
    "    validation_data=(X_test, y_test),\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "707d55ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.1514 - mae: 0.1514 - val_loss: 0.2183 - val_mae: 0.2183\n",
      "Epoch 2/10000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.1514 - mae: 0.1514 - val_loss: 0.2183 - val_mae: 0.2183\n",
      "Epoch 3/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.1514 - mae: 0.1514 - val_loss: 0.2183 - val_mae: 0.2183\n",
      "Epoch 4/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.1514 - mae: 0.1514 - val_loss: 0.2183 - val_mae: 0.2183\n",
      "Epoch 5/10000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.1514 - mae: 0.1514 - val_loss: 0.2183 - val_mae: 0.2183\n",
      "Epoch 6/10000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.1514 - mae: 0.1514 - val_loss: 0.2183 - val_mae: 0.2183\n",
      "Epoch 7/10000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.1514 - mae: 0.1514 - val_loss: 0.2183 - val_mae: 0.2183\n",
      "Epoch 8/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.1514 - mae: 0.1514 - val_loss: 0.2183 - val_mae: 0.2183\n",
      "Epoch 9/10000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.1514 - mae: 0.1514 - val_loss: 0.2182 - val_mae: 0.2182\n",
      "Epoch 10/10000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1514 - mae: 0.1514 - val_loss: 0.2182 - val_mae: 0.2182\n",
      "Epoch 11/10000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.1514 - mae: 0.1514 - val_loss: 0.2182 - val_mae: 0.2182\n",
      "Epoch 12/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.1514 - mae: 0.1514 - val_loss: 0.2182 - val_mae: 0.2182\n",
      "Epoch 13/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.1514 - mae: 0.1514 - val_loss: 0.2182 - val_mae: 0.2182\n",
      "Epoch 14/10000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.1514 - mae: 0.1514 - val_loss: 0.2182 - val_mae: 0.2182\n",
      "Epoch 15/10000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.1514 - mae: 0.1514 - val_loss: 0.2182 - val_mae: 0.2182\n",
      "Epoch 16/10000\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.1514 - mae: 0.1514 - val_loss: 0.2182 - val_mae: 0.2182\n",
      "Epoch 17/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.1514 - mae: 0.1514 - val_loss: 0.2182 - val_mae: 0.2182\n",
      "Epoch 18/10000\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.1514 - mae: 0.1514 - val_loss: 0.2182 - val_mae: 0.2182\n",
      "Epoch 19/10000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.1514 - mae: 0.1514 - val_loss: 0.2182 - val_mae: 0.2182\n",
      "Epoch 20/10000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1514 - mae: 0.1514 - val_loss: 0.2182 - val_mae: 0.2182\n",
      "Epoch 21/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.1514 - mae: 0.1514 - val_loss: 0.2182 - val_mae: 0.2182\n",
      "Epoch 22/10000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.1514 - mae: 0.1514 - val_loss: 0.2182 - val_mae: 0.2182\n",
      "Epoch 23/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.1514 - mae: 0.1514 - val_loss: 0.2182 - val_mae: 0.2182\n",
      "Epoch 24/10000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.1514 - mae: 0.1514 - val_loss: 0.2182 - val_mae: 0.2182\n",
      "Epoch 25/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.1514 - mae: 0.1514 - val_loss: 0.2182 - val_mae: 0.2182\n",
      "Epoch 26/10000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.1514 - mae: 0.1514 - val_loss: 0.2182 - val_mae: 0.2182\n",
      "Epoch 27/10000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.1514 - mae: 0.1514 - val_loss: 0.2182 - val_mae: 0.2182\n",
      "Epoch 28/10000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.1514 - mae: 0.1514 - val_loss: 0.2182 - val_mae: 0.2182\n",
      "Epoch 29/10000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.1514 - mae: 0.1514 - val_loss: 0.2182 - val_mae: 0.2182\n",
      "Epoch 30/10000\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.1514 - mae: 0.1514 - val_loss: 0.2182 - val_mae: 0.2182\n",
      "Epoch 31/10000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.1514 - mae: 0.1514 - val_loss: 0.2182 - val_mae: 0.2182\n",
      "Epoch 32/10000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.1514 - mae: 0.1514 - val_loss: 0.2182 - val_mae: 0.2182\n",
      "Epoch 33/10000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.1514 - mae: 0.1514 - val_loss: 0.2182 - val_mae: 0.2182\n",
      "Epoch 34/10000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.1514 - mae: 0.1514 - val_loss: 0.2182 - val_mae: 0.2182\n",
      "Epoch 35/10000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.1514 - mae: 0.1514 - val_loss: 0.2182 - val_mae: 0.2182\n",
      "Epoch 36/10000\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.1514 - mae: 0.1514 - val_loss: 0.2182 - val_mae: 0.2182\n",
      "Epoch 37/10000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.1514 - mae: 0.1514 - val_loss: 0.2182 - val_mae: 0.2182\n",
      "Epoch 38/10000\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.1514 - mae: 0.1514 - val_loss: 0.2182 - val_mae: 0.2182\n",
      "Epoch 39/10000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1514 - mae: 0.1514 - val_loss: 0.2182 - val_mae: 0.2182\n",
      "Epoch 40/10000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.1514 - mae: 0.1514 - val_loss: 0.2182 - val_mae: 0.2182\n",
      "Epoch 41/10000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.1514 - mae: 0.1514 - val_loss: 0.2182 - val_mae: 0.2182\n",
      "Epoch 42/10000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.1514 - mae: 0.1514 - val_loss: 0.2182 - val_mae: 0.2182\n",
      "Epoch 43/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.1514 - mae: 0.1514 - val_loss: 0.2182 - val_mae: 0.2182\n",
      "Epoch 44/10000\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.1514 - mae: 0.1514 - val_loss: 0.2182 - val_mae: 0.2182\n",
      "Epoch 45/10000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.1514 - mae: 0.1514 - val_loss: 0.2182 - val_mae: 0.2182\n",
      "Epoch 46/10000\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1514 - mae: 0.1514 - val_loss: 0.2182 - val_mae: 0.2182\n",
      "Epoch 47/10000\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.1514 - mae: 0.1514 - val_loss: 0.2182 - val_mae: 0.2182\n",
      "Epoch 48/10000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.1514 - mae: 0.1514 - val_loss: 0.2182 - val_mae: 0.2182\n",
      "Epoch 49/10000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.1514 - mae: 0.1514 - val_loss: 0.2182 - val_mae: 0.2182\n",
      "Epoch 50/10000\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.1514 - mae: 0.1514 - val_loss: 0.2182 - val_mae: 0.2182\n",
      "Epoch 51/10000\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.1514 - mae: 0.1514 - val_loss: 0.2182 - val_mae: 0.2182\n",
      "Epoch 52/10000\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.1514 - mae: 0.1514 - val_loss: 0.2182 - val_mae: 0.2182\n",
      "Epoch 53/10000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.1514 - mae: 0.1514 - val_loss: 0.2182 - val_mae: 0.2182\n",
      "Epoch 54/10000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.1514 - mae: 0.1514 - val_loss: 0.2182 - val_mae: 0.2182\n",
      "Epoch 55/10000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.1514 - mae: 0.1514 - val_loss: 0.2182 - val_mae: 0.2182\n",
      "Epoch 56/10000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.1514 - mae: 0.1514 - val_loss: 0.2182 - val_mae: 0.2182\n",
      "Epoch 57/10000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.1514 - mae: 0.1514 - val_loss: 0.2182 - val_mae: 0.2182\n",
      "Epoch 58/10000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.1514 - mae: 0.1514 - val_loss: 0.2182 - val_mae: 0.2182\n",
      "Epoch 59/10000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.1514 - mae: 0.1514 - val_loss: 0.2182 - val_mae: 0.2182\n",
      "Epoch 60/10000\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.1514 - mae: 0.1514 - val_loss: 0.2182 - val_mae: 0.2182\n",
      "Epoch 61/10000\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.1514 - mae: 0.1514 - val_loss: 0.2182 - val_mae: 0.2182\n",
      "Epoch 62/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 51ms/step - loss: 0.1514 - mae: 0.1514 - val_loss: 0.2182 - val_mae: 0.2182\n",
      "Epoch 63/10000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.1514 - mae: 0.1514 - val_loss: 0.2182 - val_mae: 0.2182\n",
      "Epoch 64/10000\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.1514 - mae: 0.1514 - val_loss: 0.2182 - val_mae: 0.2182\n",
      "Epoch 65/10000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.1514 - mae: 0.1514 - val_loss: 0.2182 - val_mae: 0.2182\n",
      "Epoch 66/10000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.1514 - mae: 0.1514 - val_loss: 0.2182 - val_mae: 0.2182\n",
      "Epoch 67/10000\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.1514 - mae: 0.1514 - val_loss: 0.2182 - val_mae: 0.2182\n",
      "Epoch 68/10000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [67]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.conda\\envs\\tf-gpu-cuda8\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:108\u001b[0m, in \u001b[0;36menable_multi_worker.<locals>._method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_method_wrapper\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    107\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_in_multi_worker_mode():  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m--> 108\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    110\u001b[0m   \u001b[38;5;66;03m# Running inside `run_distribute_coordinator` already.\u001b[39;00m\n\u001b[0;32m    111\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m dc_context\u001b[38;5;241m.\u001b[39mget_current_worker_context():\n",
      "File \u001b[1;32m~\\.conda\\envs\\tf-gpu-cuda8\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1098\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1091\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trace\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1092\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraceContext\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   1093\u001b[0m     graph_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   1094\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   1095\u001b[0m     step_num\u001b[38;5;241m=\u001b[39mstep,\n\u001b[0;32m   1096\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size):\n\u001b[0;32m   1097\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1098\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1099\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1100\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\.conda\\envs\\tf-gpu-cuda8\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:780\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    778\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    779\u001b[0m   compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 780\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    782\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_tracing_count()\n\u001b[0;32m    783\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\.conda\\envs\\tf-gpu-cuda8\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:807\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    804\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    805\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    806\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 807\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stateless_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    808\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    809\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    810\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    811\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32m~\\.conda\\envs\\tf-gpu-cuda8\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2829\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2827\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m   2828\u001b[0m   graph_function, args, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2829\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_filtered_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.conda\\envs\\tf-gpu-cuda8\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1843\u001b[0m, in \u001b[0;36mConcreteFunction._filtered_call\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1827\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_filtered_call\u001b[39m(\u001b[38;5;28mself\u001b[39m, args, kwargs, cancellation_manager\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m   1828\u001b[0m   \u001b[38;5;124;03m\"\"\"Executes the function, filtering arguments from the Python function.\u001b[39;00m\n\u001b[0;32m   1829\u001b[0m \n\u001b[0;32m   1830\u001b[0m \u001b[38;5;124;03m  Objects aside from Tensors, CompositeTensors, and Variables are ignored.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1841\u001b[0m \u001b[38;5;124;03m    `args` and `kwargs`.\u001b[39;00m\n\u001b[0;32m   1842\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1843\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1844\u001b[0m \u001b[43m      \u001b[49m\u001b[43m[\u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mnest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflatten\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexpand_composites\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m   1845\u001b[0m \u001b[43m       \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTensor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1846\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mresource_variable_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mBaseResourceVariable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1847\u001b[0m \u001b[43m      \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1848\u001b[0m \u001b[43m      \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.conda\\envs\\tf-gpu-cuda8\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1923\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1918\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   1919\u001b[0m     pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_TapeSetPossibleGradientTypes(args))\n\u001b[0;32m   1920\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m _POSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1921\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1922\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1923\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1924\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1925\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1926\u001b[0m     args,\n\u001b[0;32m   1927\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1928\u001b[0m     executing_eagerly)\n\u001b[0;32m   1929\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\.conda\\envs\\tf-gpu-cuda8\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:545\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    543\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    544\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 545\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    546\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    547\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    548\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    549\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    550\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    551\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    552\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    553\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    554\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    557\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    558\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32m~\\.conda\\envs\\tf-gpu-cuda8\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:59\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     58\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 59\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     60\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     62\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    x=X_train, \n",
    "    y=y_train, \n",
    "    epochs=10000,\n",
    "    batch_size=1000000,\n",
    "    validation_data=(X_test, y_test)\n",
    ")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d729fdba",
   "metadata": {},
   "source": [
    "model.save(\"mse.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "944510f4",
   "metadata": {},
   "source": [
    "on demande au modèle de faire des prédictions pour les valeurs de X_test, de dimension (50000, 22).\n",
    "val_predictions aura une dimension de (50000, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "9059d134",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "842eae96",
   "metadata": {},
   "source": [
    "On affiche les dix premières valeurs de prédictions (val_predictions) et les valeurs réelles attendues (y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f9b976f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_test : \n",
      " [[238.12   56.771  45.008]\n",
      " [312.516  56.229  43.907]\n",
      " [  4.188  56.151  45.955]\n",
      " [288.417  55.477  44.926]\n",
      " [222.128  55.859  43.357]\n",
      " [139.528  56.78   49.055]\n",
      " [347.173  55.879  43.91 ]\n",
      " [  1.74   56.774  48.945]\n",
      " [274.916  57.279  47.987]\n",
      " [298.611  56.402  43.524]]\n",
      "=====================================\n",
      "y_pred : \n",
      " [[238.05734    56.715553   44.96208  ]\n",
      " [312.56778    56.220467   43.893627 ]\n",
      " [  4.2060814  56.125698   45.90312  ]\n",
      " [288.465      55.465034   44.905205 ]\n",
      " [222.24557    55.885387   43.280846 ]\n",
      " [139.66562    56.829796   49.102215 ]\n",
      " [346.9167     55.85209    43.916355 ]\n",
      " [  1.3074304  56.830135   49.065414 ]\n",
      " [274.77383    57.298454   48.03428  ]\n",
      " [298.5663     56.396877   43.535397 ]]\n"
     ]
    }
   ],
   "source": [
    "print(\"y_test : \\n\", y_test[:10])\n",
    "print(\"=====================================\")\n",
    "print(\"y_pred : \\n\", val_predictions[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c8e51a",
   "metadata": {},
   "source": [
    "On calcule l'erreur moyenne absolue en donnant à la fonction les valeurs prédites et réelles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e2d22376",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation MAE for Model: 0.2182454448306533\n"
     ]
    }
   ],
   "source": [
    "val_mae = mean_absolute_error(val_predictions, y_test)\n",
    "print(\"Validation MAE for Model: {}\".format(val_mae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "99273366",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation MSE for Model: 15.997438454209089\n"
     ]
    }
   ],
   "source": [
    "val_mse = mean_squared_error(y_test, val_predictions)\n",
    "print(\"Validation MSE for Model: {}\".format(val_mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "160c910b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 3)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b7e7625",
   "metadata": {},
   "source": [
    "On affiche trois graphiques pour chaque valeur d'Euler, en x les valeurs réelles et en y les valeurs prédites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "70820eda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    axe = plt.axes()\n",
    "    plt.rcParams.update({'font.size':15})\n",
    "    plt.style.use('seaborn-whitegrid')\n",
    "    plt.scatter(y_test[:, i], val_predictions[:, i], s=1)\n",
    "    plt.title('Euler ' + str(i+1))\n",
    "    axe.set(xlabel=\"Valeurs réelles\", ylabel=\"Valeurs prédites\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7428f79e",
   "metadata": {},
   "source": [
    "On affiche le nombre d'erreurs de 1 degré ou plus de notre modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ce997177",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "le pourcentage d'erreur est de 1.466, 733 / 50000\n"
     ]
    }
   ],
   "source": [
    "message = calculate_error(val_predictions, y_test, X_test)\n",
    "print(message)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e40a503",
   "metadata": {},
   "source": [
    "on mesure la qualité de prédiction de notre modèle avec l'écart quadratique moyen, mae et le coefficient de détermination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "dcb72744",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 :  0.9922143318808395\n",
      "MAE : 0.2182454448306533\n",
      "RMSE: 3.999679793959648\n"
     ]
    }
   ],
   "source": [
    "run_experiment(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c338f45",
   "metadata": {},
   "source": [
    "On importe d'autres données que le modèle n'a jamais vu pour le tester"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "f15adebe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_ligne_matrice = 250000\n",
      "Extraction des données à partir du fichier ....\n",
      "ok !\n",
      "nb_ligne_matrice = 250000\n",
      "Extraction des données à partir du fichier ....\n",
      "ok !\n",
      "nb_ligne_matrice = 250000\n",
      "Extraction des données à partir du fichier ....\n",
      "ok !\n"
     ]
    }
   ],
   "source": [
    "X_2 = get_data(\"datas/C_maps_2.txt\")\n",
    "y_2 = read_ctf(\"datas/exercise2.ctf\")\n",
    "X_4 = get_data(\"datas/C_maps_4.txt\")\n",
    "y_4 = read_ctf(\"datas/exercise4.ctf\")\n",
    "X_5 = get_data(\"datas/C_maps_5.txt\")\n",
    "y_5 = read_ctf(\"datas/exercise5.ctf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ff3765",
   "metadata": {},
   "source": [
    "on fait prédire nos nouvelles données et on affiche le mae du modèle sur ces nouvelles données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "d786d7da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation MAE for Model: 0.23478572050942423\n",
      "Validation MAE for Model: 0.21299297997762312\n",
      "Validation MAE for Model: 0.21725743676172501\n"
     ]
    }
   ],
   "source": [
    "# X_3_train, X_3_test, y_3_train, y_3_test = train_test_split(X_3, y_3, test_size=.2, random_state=1)\n",
    "val_predictions2 = model.predict(X_2)\n",
    "val_mae2 = mean_absolute_error(val_predictions3, y_2)\n",
    "print(\"Validation MAE for Model: {}\".format(val_mae3))\n",
    "\n",
    "# X_4_train, X_4_test, y_4_train, y_4_test = train_test_split(X_4, y_4, test_size=.2, random_state=1)\n",
    "val_predictions4 = model.predict(X_4)\n",
    "val_mae4 = mean_absolute_error(val_predictions4, y_4)\n",
    "print(\"Validation MAE for Model: {}\".format(val_mae4))\n",
    "\n",
    "# X_5_train, X_5_test, y_5_train, y_5_test = train_test_split(X_5, y_5, test_size=.2, random_state=1)\n",
    "val_predictions5 = model.predict(X_5)\n",
    "val_mae5 = mean_absolute_error(val_predictions5, y_5)\n",
    "print(\"Validation MAE for Model: {}\".format(val_mae5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9233639",
   "metadata": {},
   "source": [
    "on affiche dans un graphique les valeurs réelles et les valeurs prédites et on observe la courbe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "fa7080ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    axe = plt.axes()\n",
    "    plt.rcParams.update({'font.size':15})\n",
    "    plt.style.use('seaborn-whitegrid')\n",
    "    plt.scatter(y_4[:, i], val_predictions4[:, i], s=1)\n",
    "    plt.title('Euler ' + str(i+1))\n",
    "    axe.set(xlabel=\"valeurs réelles\", ylabel=\"valeurs prédites\")\n",
    "    plt.show()\n",
    "# plt.scatter(X_test, y_test, label=\"Données d'évaluation\", color=\"b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9436aed0",
   "metadata": {},
   "source": [
    "on affiche le nombre d'erreurs que fait notre modèle sur ces nouvelles données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "31a8855a",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [79]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m predictions2 \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_2)\n\u001b[1;32m----> 2\u001b[0m message2, erreur_y2, erreur_x2, nb_error_2 \u001b[38;5;241m=\u001b[39m \u001b[43mpourcentage_erreur\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpredictions3\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(message3)\n\u001b[0;32m      4\u001b[0m predictions4 \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_4)\n",
      "Input \u001b[1;32mIn [6]\u001b[0m, in \u001b[0;36mpourcentage_erreur\u001b[1;34m(y_pred, y_test, x_test)\u001b[0m\n\u001b[0;32m     16\u001b[0m             err \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     18\u001b[0m             erreur_y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mappend(erreur_y, [y_test[i]], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m---> 19\u001b[0m             erreur_x \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mappend\u001b[49m\u001b[43m(\u001b[49m\u001b[43merreur_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mx_test\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m     23\u001b[0m erreur_y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdelete(erreur_y, \u001b[38;5;241m0\u001b[39m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mappend\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32m~\\.conda\\envs\\tf-gpu-cuda8\\lib\\site-packages\\numpy\\lib\\function_base.py:5392\u001b[0m, in \u001b[0;36mappend\u001b[1;34m(arr, values, axis)\u001b[0m\n\u001b[0;32m   5390\u001b[0m     values \u001b[38;5;241m=\u001b[39m ravel(values)\n\u001b[0;32m   5391\u001b[0m     axis \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mndim\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 5392\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mconcatenate\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "predictions2 = model.predict(X_2)\n",
    "message2, erreur_y2, erreur_x2, nb_error_2 = pourcentage_erreur(predictions3, y_2, X_2)\n",
    "print(message3)\n",
    "predictions4 = model.predict(X_4)\n",
    "message4, erreur_y4, erreur_x4, nb_error_4 = pourcentage_erreur(predictions4, y_4, X_4)\n",
    "print(message4)\n",
    "predictions5 = model.predict(X_5)\n",
    "message5, erreur_y5, erreur_x5, nb_error_5 = pourcentage_erreur(predictions5, y_5, X_5)\n",
    "print(message5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ff4f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "erreur_y2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e45f0b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "erreur_x2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a6308a",
   "metadata": {},
   "source": [
    "On récupère les valeurs d'entrée et de sortie X ey y des trois jeux de données pour lesquelles le modèle prédit mal dans trois matrices et on les mélanges à 50% d'autres valeurs aléatoires pour avoir trois jeux de données composés de 50% d'erreurs et 50% d'autres valeurs aléatoires."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ea5f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_y3 = np.ones((1, 3), dtype=float)\n",
    "matrix_x3 = np.ones((1, 22), dtype=float)\n",
    "\n",
    "for i in range(nb_error_3):\n",
    "    nb = np.random.randint(0, X_3.shape[0] - 1)\n",
    "    matrix_y3 = np.append(matrix_y3, [y_3[nb]], axis=0)\n",
    "    matrix_x3 = np.append(matrix_x3, [X_3[nb]], axis=0)\n",
    "    \n",
    "matrix_y3 = np.delete(matrix_y3, 0, axis=0)\n",
    "matrix_x3 = np.delete(matrix_x3, 0, axis=0)\n",
    "# ==============================================\n",
    "matrix_y4 = np.ones((1, 3), dtype=float)\n",
    "matrix_x4 = np.ones((1, 22), dtype=float)\n",
    "\n",
    "for i in range(nb_error_4):\n",
    "    nb = np.random.randint(0, X_4.shape[0] - 1)\n",
    "    matrix_y4 = np.append(matrix_y4, [y_4[nb]], axis=0)\n",
    "    matrix_x4 = np.append(matrix_x4, [X_4[nb]], axis=0)\n",
    "    \n",
    "matrix_y4 = np.delete(matrix_y4, 0, axis=0)\n",
    "matrix_x4 = np.delete(matrix_x4, 0, axis=0)\n",
    "#=============================================\n",
    "matrix_y5 = np.ones((1, 3), dtype=float)\n",
    "matrix_x5 = np.ones((1, 22), dtype=float)\n",
    "\n",
    "for i in range(nb_error_5):\n",
    "    nb = np.random.randint(0, X_5.shape[0] - 1)\n",
    "    matrix_y5 = np.append(matrix_y5, [y_5[nb]], axis=0)\n",
    "    matrix_x5 = np.append(matrix_x5, [X_5[nb]], axis=0)\n",
    "    \n",
    "matrix_y5 = np.delete(matrix_y5, 0, axis=0)\n",
    "matrix_x5 = np.delete(matrix_x5, 0, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a669963",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_x3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb8205c",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_y3.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "188aa1c2",
   "metadata": {},
   "source": [
    "On regroupe les trois matrices précédentes dans une seule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d2821c",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_X3 = np.concatenate((matrix_x3, erreur_x3), axis=0)\n",
    "new_Y3 = np.concatenate((matrix_y3, erreur_y3), axis=0)\n",
    "\n",
    "new_X4 = np.concatenate((matrix_x4, erreur_x4), axis=0)\n",
    "new_Y4 = np.concatenate((matrix_y4, erreur_y4), axis=0)\n",
    "\n",
    "new_X5 = np.concatenate((matrix_x5, erreur_x5), axis=0)\n",
    "new_Y5 = np.concatenate((matrix_y5, erreur_y5), axis=0)\n",
    "\n",
    "new_X_ = np.concatenate((new_X3, new_X4), axis=0)\n",
    "new_Y_ = np.concatenate((new_Y3, new_Y4), axis=0)\n",
    "\n",
    "new_X = np.concatenate((new_X_, new_X5), axis=0)\n",
    "new_Y = np.concatenate((new_Y_, new_Y5), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234eea08",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e910a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f454b5c0",
   "metadata": {},
   "source": [
    "on sépare nos nouvelles données composé de 50% d'erreurs et 50% aléatoire en 80 % de données d'entraîenement et 20 % données de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d3f9bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(new_X, new_Y, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cca18d0f",
   "metadata": {},
   "source": [
    "on crée un nouveau modèle avec le meme nombre de couches que le précédent"
   ]
  },
  {
   "cell_type": "raw",
   "id": "38771b96",
   "metadata": {},
   "source": [
    "model_error = keras.Sequential()\n",
    "\n",
    "model_error.add(Input(shape=(22,)))\n",
    "\n",
    "model_error.add(layers.Dense(256, activation=\"relu\")),\n",
    "\n",
    "model_error.add(layers.Dense(128, activation=\"relu\")),\n",
    "\n",
    "model_error.add(layers.Dense(64, activation=\"relu\")),\n",
    "\n",
    "model_error.add(layers.Dense(32, activation=\"relu\")),\n",
    "\n",
    "model_error.add(layers.Dense(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db838c9",
   "metadata": {},
   "source": [
    "on donne au modèle nos nouvelles données composées de 50% d'erreurs et 50% d'aléatoires\n",
    "on peut jouer avec le batch_size , le nombre d'epochs etc\n",
    "augmenter le batch_size et réentrâiner plusieurs fois"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11aeae78",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=\"adam\", \n",
    "    loss=\"mae\", # mse\n",
    "    metrics=[tf.keras.metrics.MeanAbsoluteError()]\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    x=X_train2, \n",
    "    y=y_train2, \n",
    "    epochs=10000,\n",
    "    batch_size=32,\n",
    "    validation_data=(X_test2, y_test2)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b84ec10",
   "metadata": {},
   "source": [
    "ou bien on utilise le modèle précédent ou un autres"
   ]
  },
  {
   "cell_type": "raw",
   "id": "48e0055f",
   "metadata": {},
   "source": [
    "model_erreur = keras.models.load_model('nouveau.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd874ebc",
   "metadata": {},
   "source": [
    "on fait prédire à notre nouveau modèle toutes les données des trois fichiers (les modèles ne les ont jamais vu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3514b3de",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred3 = model.predict(X_3)\n",
    "pred4 = model.predict(X_4)\n",
    "pred5 = model.predict(X_5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ec5f74",
   "metadata": {},
   "source": [
    "on fait aussi prédire nos données composés de 50% d'erreurs et 50% aléatoires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5165ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(new_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f980f986",
   "metadata": {},
   "source": [
    "on affiche trois graphique pour visualiser la qulaité du modèle sur les données 50 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b379e67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    axe = plt.axes()\n",
    "    plt.rcParams.update({'font.size':15})\n",
    "    plt.style.use('seaborn-whitegrid')\n",
    "    plt.scatter(new_Y[:, i], pred[:, i], s=1)\n",
    "    plt.title('Euler ' + str(i+1))\n",
    "    axe.set(xlabel=\"valeurs réelles\", ylabel=\"valeurs prédites\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4199c56",
   "metadata": {},
   "source": [
    "on affiche aussi trois graphiques pour visulaiser les performances du modèles sur toutes les données d'un des fichiers importés"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb283d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    axe = plt.axes()\n",
    "    plt.rcParams.update({'font.size':15})\n",
    "    plt.style.use('seaborn-whitegrid')\n",
    "    plt.scatter(y_4[:, i], pred4[:, i], s=1)\n",
    "    plt.title('Euler ' + str(i+1))\n",
    "    axe.set(xlabel=\"valeurs réelles\", ylabel=\"valeurs prédites\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85fb9640",
   "metadata": {},
   "source": [
    "on calcule le nombre d'erreurs de 1 degré ou plus sur les données 50 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c18d587",
   "metadata": {},
   "outputs": [],
   "source": [
    "msg, erry, errx, err = pourcentage_erreur(pred, new_Y, new_X)\n",
    "print(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe2c157",
   "metadata": {},
   "source": [
    "on calcule le nombre d'erreurs de 1 degré ou plus sur les trois fichiers de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "200e3e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "message3, erreur_y3, erreur_x3, err3 = pourcentage_erreur(pred3, y_3, X_3)\n",
    "print(message3)\n",
    "\n",
    "message4, erreur_y4, erreur_x4, err4 = pourcentage_erreur(pred4, y_4, X_4)\n",
    "print(message4)\n",
    "\n",
    "message5, erreur_y5, erreur_x5, err5 = pourcentage_erreur(pred5, y_5, X_5)\n",
    "print(message5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16380e25",
   "metadata": {},
   "source": [
    "On va réentraîner notre modèle_erreur avec les les données d'un des fichiers après qu'il s'est entraîner avec des données 50% erreur 50% aléaatoire et qu'il a a baissé à 10% d'erreurs sur les données 50 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "873a5043",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer='adam',    # opti,\n",
    "    loss=\"mae\",    # \"mae\", # mse\n",
    "    metrics=[tf.keras.metrics.MeanAbsoluteError()]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d9e370",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    x=X_train, \n",
    "    y=y_train,\n",
    "    batch_size = 10000,\n",
    "    epochs=2000,\n",
    "    validation_data=(X_test, y_test)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43bfb094",
   "metadata": {},
   "source": [
    "On test mainetanant notre modèle sur les données des trois fichiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "312b36c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions3 = model.predict(X_3)\n",
    "message3, erreur_y3, erreur_x3, nb_error_3 = pourcentage_erreur(predictions3, y_3, X_3)\n",
    "print(message3)\n",
    "predictions4 = model.predict(X_4)\n",
    "message4, erreur_y4, erreur_x4, nb_error_4 = pourcentage_erreur(predictions4, y_4, X_4)\n",
    "print(message4)\n",
    "predictions5 = model.predict(X_5)\n",
    "message5, erreur_y5, erreur_x5, nb_error_5 = pourcentage_erreur(predictions5, y_5, X_5)\n",
    "print(message5)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "82fd333a",
   "metadata": {},
   "source": [
    "model_hasan.save(\"nouveau_hasan.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3bb1488",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
